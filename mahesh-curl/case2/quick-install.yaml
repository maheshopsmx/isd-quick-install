---
# Source: oes/charts/gitea/charts/memcached/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: isd-memcached
  namespace: opsmx-isd
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-5.9.0
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
---
# Source: oes/charts/minio/templates/post-install-prometheus-metrics-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: isd-minio-update-prometheus-secret
  labels:
    app: minio-update-prometheus-secret
    chart: minio-8.0.9
    release: isd
    heritage: Helm
---
# Source: oes/charts/minio/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "isd-minio"
  namespace: "opsmx-isd"
  labels:
    app: minio
    chart: minio-8.0.9
    release: "isd"
---
# Source: oes/charts/spinnaker/templates/rbac/halyard-sa.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: isd-spinnaker-halyard
  namespace: opsmx-isd
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: create-controller-secret
---
# Source: oes/charts/gitea/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
  namespace: opsmx-isd
type: Opaque
data:
  postgresql-postgres-password: "UE4ySW9Uc2ltMQ=="
  postgresql-password: "Z2l0ZWE="
---
# Source: oes/charts/gitea/templates/gitea/config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-gitea-inline-config
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  _generals_: ""
  cache: |-
    ADAPTER=memcache
    ENABLED=true
    HOST=isd-memcached.opsmx-isd.svc.cluster.local:11211
  database: |-
    DB_TYPE=postgres
    HOST=isd-postgresql.opsmx-isd.svc.cluster.local:5432
    NAME=gitea
    PASSWD=gitea
    USER=gitea
  metrics: ENABLED=false
  repository: ROOT=/data/git/gitea-repositories
  security: INSTALL_LOCK=true
  server: |-
    APP_DATA_PATH=/data
    DOMAIN=git.example.com
    ENABLE_PPROF=false
    HTTP_PORT=3000
    PROTOCOL=http
    ROOT_URL=http://git.example.com
    SSH_DOMAIN=git.example.com
    SSH_LISTEN_PORT=22
    SSH_PORT=22
---
# Source: oes/charts/gitea/templates/gitea/config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-gitea
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  config_environment.sh: |-
    #!/usr/bin/env bash
    set -euo pipefail

    function env2ini::log() {
      printf "${1}\n"
    }

    function env2ini::read_config_to_env() {
      local section="${1}"
      local line="${2}"

      if [[ -z "${line}" ]]; then
        # skip empty line
        return
      fi
      
      # 'xargs echo -n' trims all leading/trailing whitespaces and a trailing new line
      local setting="$(awk -F '=' '{print $1}' <<< "${line}" | xargs echo -n)"

      if [[ -z "${setting}" ]]; then
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      local value=''
      local regex="^${setting}(\s*)=(\s*)(.*)"
      if [[ $line =~ $regex ]]; then
        value="${BASH_REMATCH[3]}"
      else
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      env2ini::log "    + '${setting}'"

      if [[ -z "${section}" ]]; then
        export "ENV_TO_INI____${setting^^}=${value}"                           # '^^' makes the variable content uppercase
        return
      fi

      local masked_section="${section//./_0X2E_}"                            # '//' instructs to replace all matches
      masked_section="${masked_section//-/_0X2D_}"

      export "ENV_TO_INI__${masked_section^^}__${setting^^}=${value}"        # '^^' makes the variable content uppercase
    }

    function env2ini::process_config_file() {
      local config_file="${1}"
      local section="$(basename "${config_file}")"

      if [[ $section == '_generals_' ]]; then
        env2ini::log "  [ini root]"
        section=''
      else
        env2ini::log "  ${section}"
      fi

      while read -r line; do
        env2ini::read_config_to_env "${section}" "${line}"
      done < <(awk 1 "${config_file}")                             # Helm .toYaml trims the trailing new line which breaks line processing; awk 1 ... adds it back while reading
    }

    function env2ini::load_config_sources() {
      local path="${1}"

      env2ini::log "Processing $(basename "${path}")..."

      while read -d '' configFile; do
        env2ini::process_config_file "${configFile}"
      done < <(find "${path}" -type l -not -name '..data' -print0)

      env2ini::log "\n"
    }

    function env2ini::generate_initial_secrets() {
      # These environment variables will either be
      #   - overwritten with user defined values,
      #   - initially used to set up Gitea
      # Anyway, they won't harm existing app.ini files

      export ENV_TO_INI__SECURITY__INTERNAL_TOKEN=$(gitea generate secret INTERNAL_TOKEN)
      export ENV_TO_INI__SECURITY__SECRET_KEY=$(gitea generate secret SECRET_KEY)
      export ENV_TO_INI__OAUTH2__JWT_SECRET=$(gitea generate secret JWT_SECRET)

      env2ini::log "...Initial secrets generated\n"
    }

    # MUST BE CALLED BEFORE OTHER CONFIGURATION
    env2ini::generate_initial_secrets

    env2ini::load_config_sources '/env-to-ini-mounts/inlines/'
    env2ini::load_config_sources '/env-to-ini-mounts/additionals/'

    env2ini::log "=== All configuration sources loaded ===\n"

    # safety to prevent rewrite of secret keys if an app.ini already exists
    if [ -f ${GITEA_APP_INI} ]; then
      env2ini::log 'An app.ini file already exists. To prevent overwriting secret keys, these settings are dropped and remain unchanged:'
      env2ini::log '  - security.INTERNAL_TOKEN'
      env2ini::log '  - security.SECRET_KEY'
      env2ini::log '  - oauth2.JWT_SECRET'

      unset ENV_TO_INI__SECURITY__INTERNAL_TOKEN
      unset ENV_TO_INI__SECURITY__SECRET_KEY
      unset ENV_TO_INI__OAUTH2__JWT_SECRET
    fi

    environment-to-ini -o $GITEA_APP_INI -p ENV_TO_INI
---
# Source: oes/charts/gitea/templates/gitea/init.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-gitea-init
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  init_directory_structure.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail

    set -x
    chown 1000:1000 /data
    mkdir -p /data/git/.ssh
    chmod -R 700 /data/git/.ssh
    [ ! -d /data/gitea ] && mkdir -p /data/gitea/conf

    # prepare temp directory structure
    mkdir -p "${GITEA_TEMP}"
    chown 1000:1000 "${GITEA_TEMP}"
    chmod ug+rwx "${GITEA_TEMP}"

  configure_gitea.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail
    # Connection retry inspired by https://gist.github.com/dublx/e99ea94858c07d2ca6de
    function test_db_connection() {
      local RETRY=0
      local MAX=30

      echo 'Wait for database to become avialable...'
      until [ "${RETRY}" -ge "${MAX}" ]; do
        nc -vz -w2 isd-postgresql 5432 && break
        RETRY=$[${RETRY}+1]
        echo "...not ready yet (${RETRY}/${MAX})"
      done

      if [ "${RETRY}" -ge "${MAX}" ]; then
        echo "Database not reachable after '${MAX}' attempts!"
        exit 1
      fi
    }

    test_db_connection

    echo '==== BEGIN GITEA CONFIGURATION ===='

    gitea migrate
    function configure_admin_user() {
      local ACCOUNT_ID=$(gitea admin user list --admin | grep -e "\s\+${GITEA_ADMIN_USERNAME}\s\+" | awk -F " " "{printf \$1}")
      if [[ -z "${ACCOUNT_ID}" ]]; then
        echo "No admin user '${GITEA_ADMIN_USERNAME}' found. Creating now..."
        gitea admin user create --admin --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}" --email "support@opsmx.com" --must-change-password=false
        echo '...created.'
      else
        echo "Admin account '${GITEA_ADMIN_USERNAME}' already exist. Running update to sync password..."
        gitea admin user change-password --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}"
        echo '...password sync done.'
      fi
    }

    configure_admin_user

    function configure_ldap() {
        echo 'no ldap configuration... skipping.'
    }

    configure_ldap

    function configure_oauth() {
        echo 'no oauth configuration... skipping.'
    }

    configure_oauth

    echo '==== END GITEA CONFIGURATION ===='
---
# Source: oes/charts/minio/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
type: Opaque
data:
  accesskey: "c3Bpbm5ha2VyYWRtaW4="
  secretkey: "c3Bpbm5ha2VyYWRtaW4="
---
# Source: oes/charts/openldap/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-openldap
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
type: Opaque
data:
  LDAP_ADMIN_PASSWORD: "b3BzbXhhZG1pbjEyMw=="
  LDAP_CONFIG_PASSWORD: "b3BzbXhjb25maWcxMjM="
---
# Source: oes/charts/redis/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-redis
  labels:
    app: redis
    chart: redis-10.5.3
    release: "isd"
    heritage: "Helm"
type: Opaque
data:
  redis-password: "cGFzc3dvcmQ="
---
# Source: oes/charts/spinnaker/templates/secrets/registry.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-spinnaker-registry
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
    component: clouddriver
type: Opaque
data:
  dockerhub: ""
---
# Source: oes/charts/spinnaker/templates/secrets/spin-config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-spinnaker-spin-config
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
stringData:
  config: |
    auth:
      basic:
        password: saporadmin
        username: admin
      enabled: true
    gate:
      endpoint: http://sapor-gate:8084
---
# Source: oes/templates/customstages/ansible-secrets.yaml
apiVersion: v1
stringData:
  gitpassword: 4fmschdd3455
  gitusername: opsmxuser2
  nodeuser: ubuntu
  userpassword: ubuntupassword
kind: Secret
metadata:
  name: ansible-secrets
type: Opaque
---
# Source: oes/templates/customstages/customnotification-ssmtp-secrets.yaml
apiVersion: v1
stringData:
  emailpassword: passowrdmail
  ssmtpemail: opsmxuser@opsmx.io
kind: Secret
metadata:
  name: ssmtp-secrets
type: Opaque
---
# Source: oes/templates/customstages/terraspinbackendconfig.yaml
apiVersion: v1
stringData:
  artifactaccounts.json: |
         {
            "artifactaccounts": [
               {
                 "accountname": "OpsMx-artifact-Github-account",
                 "artifacttype": "Github",
                 "host": "https://github.com",
                 "username": "opsmx",
                 "password": "wtwetr4543534"
                }
               ]
         }
kind: Secret
metadata:
  name: terraspinbackendconfig
---
# Source: oes/templates/customstages/updatepr-secrets.yaml
apiVersion: v1
stringData:
  accesstoken: dfvjkbv346jsd93os0skw0
kind: Secret
metadata:
  name: updatepr-secrets
type: Opaque
---
# Source: oes/templates/pipeline-promotion/local-spin-cli-config-secret.yaml
apiVersion: v1
stringData:
  # Spin CLI config content used by syncToSpinnaker stage
  # It is placed under ~/.spin/config
  # endpoint should be the spinnaker gate where pipelines are created/updated
  config: |-
    auth:
      basic:
        password: saporadmin
        username: admin
      enabled: true
    gate:
      endpoint: http://sapor-gate:8084
kind: Secret
metadata:
  name: local-spin-cli-config
---
# Source: oes/templates/pipeline-promotion/spin-cli-config-secret.yaml
apiVersion: v1
stringData:
  # Spin CLI config content used by syncToGit stage
  # It is placed under ~/.spin/config
  # custom job stage runs a spin cli and fetches the application/pipeline data
  # gate endpoint should point to the spinnaker from where application/pipeline data is fetched
  config: |-
    auth:
      basic:
        password: saporadmin
        username: admin
      enabled: true
    gate:
      endpoint: http://sapor-gate:8084
kind: Secret
metadata:
  name: spin-cli-config
---
# Source: oes/templates/sapor-gate/sapor-gate-secret.yaml
apiVersion: v1
data:
  gate-local.yml:
    c2VydmVyOgogIHRvbWNhdDoKICAgIGh0dHBzU2VydmVyUG9ydDogWC1Gb3J3YXJkZWQtUG9ydAogICAgaW50ZXJuYWxQcm94aWVzOiAuKgogICAgcHJvdG9jb2xIZWFkZXI6IFgtRm9yd2FyZGVkLVByb3RvCiAgICByZW1vdGVJcEhlYWRlcjogWC1Gb3J3YXJkZWQtRm9yCnNlY3VyaXR5OgogIGJhc2ljZm9ybToKICAgIGVuYWJsZWQ6IHRydWUKICB1c2VyOgogICAgbmFtZTogYWRtaW4KICAgIHBhc3N3b3JkOiBzYXBvcmFkbWluCiAgICByb2xlczogYWRtaW4K
  gate-overrides.yml:
    IyMgV0FSTklORwojIyBUaGlzIGZpbGUgd2FzIGF1dG9nZW5lcmF0ZWQsIGFuZCBfd2lsbF8gYmUgb3ZlcndyaXR0ZW4gYnkgSGFseWFyZC4KIyMgQW55IGVkaXRzIHlvdSBtYWtlIGhlcmUgX3dpbGxfIGJlIGxvc3QuCgpzZXJ2aWNlczoKICBjbG91ZGRyaXZlcjoKICAgIGJhc2VVcmw6IGh0dHA6Ly9zcGluLWNsb3VkZHJpdmVyLXJvOjcwMDIKICAgIGVuYWJsZWQ6IHRydWUKICBlY2hvOgogICAgYmFzZVVybDogaHR0cDovL3NwaW4tZWNoby13b3JrZXI6ODA4OQogICAgZW5hYmxlZDogdHJ1ZQoKZ2xvYmFsLnNwaW5uYWtlci50aW1lem9uZTogQW1lcmljYS9Mb3NfQW5nZWxlcw==
  gate.yml:
    IyMgV0FSTklORwojIyBUaGlzIGZpbGUgd2FzIGF1dG9nZW5lcmF0ZWQsIGFuZCBfd2lsbF8gYmUgb3ZlcndyaXR0ZW4gYnkgSGFseWFyZC4KIyMgQW55IGVkaXRzIHlvdSBtYWtlIGhlcmUgX3dpbGxfIGJlIGxvc3QuCgpzcGVjdGF0b3I6CiAgYXBwbGljYXRpb25OYW1lOiAke3NwcmluZy5hcHBsaWNhdGlvbi5uYW1lfQogIHdlYkVuZHBvaW50OgogICAgZW5hYmxlZDogZmFsc2UKCnNwaW5uYWtlcjoKICBleHRlbnNpYmlsaXR5OgogICAgcGx1Z2luczoge30KICAgIHJlcG9zaXRvcmllczoge30KICAgIHBsdWdpbnMtcm9vdC1wYXRoOiAvb3B0L2dhdGUvcGx1Z2lucwogICAgc3RyaWN0LXBsdWdpbi1sb2FkaW5nOiBmYWxzZQoKc2VydmVyOgogIHNzbDoKICAgIGVuYWJsZWQ6IGZhbHNlCiAgcG9ydDogJzgwODQnCiAgYWRkcmVzczogMC4wLjAuMApzZWN1cml0eToKICBiYXNpYzoKICAgIGVuYWJsZWQ6IHRydWUKICB1c2VyOiB7fQpjb3JzOiB7fQpnb29nbGU6IHt9CgppbnRlZ3JhdGlvbnM6CiAgZ3JlbWxpbjoKICAgIGVuYWJsZWQ6IGZhbHNlCiAgICBiYXNlVXJsOiBodHRwczovL2FwaS5ncmVtbGluLmNvbS92MQoKIyBoYWxjb25maWcKCnNlcnZpY2VzOgogIGNsb3VkZHJpdmVyOgogICAgY29uZmlnOgogICAgICBkeW5hbWljRW5kcG9pbnRzOgogICAgICAgIGRlY2s6IGh0dHA6Ly9zcGluLWNsb3VkZHJpdmVyLXJvLWRlY2s6NzAwMgogIHBsYXRmb3JtOgogICAgYmFzZVVybDogaHR0cDovL29lcy1wbGF0Zm9ybTo4MDk1CiAgICB1c2VyR3JvdXBBcGlQYXRoOiAvcGxhdGZvcm1zZXJ2aWNlL3YxL3VzZXJzL3t1c2VybmFtZX0vdXNlcmdyb3Vwcy9pbXBvcnRBbmRDYWNoZQogICAgZW5hYmxlZDogdHJ1ZQo=
  spinnaker.yml:
    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
  spinnakerconfig.yml:
    I0VtcHR5IGZpbGUK
kind: Secret
metadata:
  labels:
    app: oes
    component: sapor-gate
  name: sapor-gate-files
type: Opaque
---
# Source: oes/templates/secrets/bootstrap-secret.yaml
apiVersion: v1
stringData:
  bootstrap.yml: |-
    spring:
      cloud:
        vault:
          enterprise: false
          namespace: admin/isd-platform
          uri: https://server.vaultint.opsmx.net
          token: 123132
          enabled: false
          kv:
            enabled: false
          generic:
            enabled: false
    jasypt:
      encryptor:
        password: Q7udUkHPuA3VnNlOtksSgQ
    datasource:
      secretManagement:
        source: db
kind: Secret
metadata:
  name: bootstrap
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
---
# Source: oes/templates/secrets/gitea-secret.yaml
apiVersion: v1
stringData:
  # Repo uri to fetch halyard configuration
  username: opsmx 
  password: opsmxadmin123
kind: Secret
metadata:
  name: gitea-secret
type: Opaque
---
# Source: oes/templates/secrets/oes-audit-client-secret.yaml
apiVersion: v1
stringData:
  audit-local.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/auditdb
        username: 'postgres'
        password: 'networks123'
    logging:
      level:
        com.opsmx.auditclientservice: INFO
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    oes:
      admin:
        user: admin
    feign:
      client:
        platformservice:
          name: platformservice
          url: http://oes-platform:8095
        visibilityservice:
          name: visibilityservice
          url: http://oes-visibility:8096
    
    fixedDelay:
      in:
        milliseconds: 120000
    initialDelay:
      in:
        milliseconds: 300000
    scheduler:
      threads: 16
    
kind: Secret
metadata:
  labels:
    app: oes
    component: auditclient
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-audit-client-config
---
# Source: oes/templates/secrets/oes-audit-service-secret.yaml
apiVersion: v1
stringData:
  audit-local.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/auditdb
        username: 'postgres'
        password: 'networks123'
    logging:
        level:
          com.opsmx.auditservice: INFO
    message-broker:
      enabled: true
      username: 'rabbitmq'
      password: 'Networks123'
      host: rabbitmq-service
      port: 5672
      endpoint:
        name: rabbitmq
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    feign:
      client:
        platformservice:
          name: platformservice
          url: http://oes-platform:8095
        auditclientservice:
          name: auditclientservice
          url: http://oes-audit-client:8098
        oes:
          url: http://oes-sapor:8085
        autopilot:
          url: http://oes-autopilot:8090
        visibilityservice:
          url: http://oes-visibility:8096
        dashboard:
          url: http://oes-dashboard:8094
    
kind: Secret
metadata:
  labels:
    app: oes
    component: auditservice
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-audit-service-config
---
# Source: oes/templates/secrets/oes-autopilot-secret.yaml
apiVersion: v1
stringData:
  autopilot.properties: |
    # Enable Build Analysis
    build.analysis=false
    # DB configuration
    secret.datasource.username=postgres
    secret.datasource.password=networks123
    secret.datasource.url=jdbc:postgresql://oes-db:5432/opsmx
    secret.platform.url=http://oes-platform:8095
    secret.ds.protocol=http://
    secret.ds.url=localhost:5005
    
    server.host.dns.name=/ui
    
    gate.url=http://oes-gate:8084
    #gate.url=http://oes.example.ops.com/gate
    
    #datascience configuration
    oes.datascience.baseUrl=http://oes-datascience:5005
    #build.analysis=false
    ds.async.flow=true
    
    # Standard-error-path
    standardErrorCodes.filePath=/opsmx/conf/standard-error-code.csv
    
    #storage configuration
    storage.type =db_storage
    #storage.type =object_storage
    #storage.endpoint=http://isd-minio:9000
    #storage.accesskey = spinnakeradmin
    #storage.secretkey = spinnakeradmin
    #storage.region= us-east-1
    ds.seperate.service=true
    
    
    # Logging Level
    logging.level.com.opsmx.analytics=ERROR
    datasource.secretManagement.source = db
    
kind: Secret
metadata:
  name: oes-autopilot-config
  labels:
    app: oes
    component: autopilot
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
---
# Source: oes/templates/secrets/oes-datascience-secret.yaml
apiVersion: v1
stringData:
  app-config.yml: |
    # Enable Build Analysis
    APP:
       ENVIRONMENT: dev
       DEBUG: True
       # Only accept True or False
       BIND: 0.0.0.0:5005
       WORKERS: 1
       PROTOCOL: http://
       TIMEOUT: 3600
       CELERY_ENABLED: True
       # Only accept True or False
    
    OBJECT_STORAGE:
          ENDPOINT: http://isd-minio:9000
          BUCKET_NAME: autopilot
    POSTGRES:
          USERNAME: 'postgres'
          PASSWORD: 'networks123'
          HOST: oes-db
          PORT: 5432
          DB: autopilotqueue
    
    RABBITMQ:
          USERNAME: 'rabbitmq'
          PASSWORD: 'Networks123'
          HOST: rabbitmq-service
          PORT: 5672
    
  minio-credentials: |
    [default]
        aws_access_key_id = spinnakeradmin
        aws_secret_access_key = spinnakeradmin
    
    
kind: Secret
metadata:
  labels:
    app: oes
    component: datascience
  name: oes-datascience-config
---
# Source: oes/templates/secrets/oes-gate-configmap.yaml
apiVersion: v1
stringData:
  gate.yml: |
    retrofit:
      connectTimeout: 60000
      readTimeout: 60000
      callTimeout: 60000
      writeTimeout: 60000
      retryOnConnectionFailure: true
    services:
      opsmx:
        baseUrl: http://oes-sapor:8085
        enabled: true
      autopilot:
        baseUrl: http://oes-autopilot:8090
        enabled: true
      platform:
        baseUrl: http://oes-platform:8095
        userGroupApiPath: /platformservice/v1/users/{username}/usergroups/importAndCache
        enabled: true
      dashboard:
        baseUrl: http://oes-dashboard:8094
        enabled: true
      visibility:
        baseUrl: http://oes-visibility:8096
        enabled: true
      auditservice:
         baseUrl: "http://oes-audit-service:8097"
         enabled: true
      auditclient:
         baseUrl: "http://oes-audit-client:8098"
         enabled: true
      oesui:
        externalUrl: /ui/
      keel:
        enabled: false
      clouddriver:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-ro:7002
        enabled: true
      clouddriverCaching:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-caching:7002
        enabled: true
      clouddriverRo:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-ro:7002
        enabled: true
      clouddriverRoDeck:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-ro-deck:7002
        enabled: true
      clouddriverRw:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-rw:7002
        enabled: true
      deck:
        host: 0.0.0.0
        port: 9000
        baseUrl: http://oes.example.ops.com
        enabled: true
      echo:
        host: 0.0.0.0
        port: 8089
        baseUrl: http://spin-echo-worker:8089
        enabled: true
      echoScheduler:
        host: 0.0.0.0
        port: 8089
        baseUrl: http://spin-echo-scheduler:8089
        enabled: true
      echoWorker:
        host: 0.0.0.0
        port: 8089
        baseUrl: http://spin-echo-worker:8089
        enabled: true
      fiat:
        host: 0.0.0.0
        port: 7003
        baseUrl: http://spin-fiat:7003
        enabled: false
      front50:
        host: 0.0.0.0
        port: 8080
        baseUrl: http://spin-front50:8080
        enabled: true
      gate:
        host: 0.0.0.0
        port: 8084
        baseUrl: http://oes-gate.example.ops.com
        enabled: true
      igor:
        host: 0.0.0.0
        port: 8088
        baseUrl: http://spin-igor:8088
        enabled: true
      kayenta:
        host: 0.0.0.0
        port: 8090
        baseUrl: http://spin-kayenta:8090
        enabled: false
      orca:
        host: 0.0.0.0
        port: 8083
        baseUrl: http://spin-orca:8083
        enabled: true
      redis:
        host: 0.0.0.0
        port: 6379
        baseUrl: redis://:password@isd-redis-master:6379
        enabled: true
      rosco:
        host: 0.0.0.0
        port: 8087
        baseUrl: http://spin-rosco:8087
        enabled: true
      user: {}
    cors:
      allowed-origins-pattern: ^https?://(?:localhost|oes.example.ops.com|spin.example.ops.com|opsmx.com)(?::[1-9]\d*)?/?
      
    ldap:
      enabled: true
      url: ldap://isd-openldap:389
      managerDn: cn=admin,dc=example,dc=org
      managerPassword: opsmxadmin123
      groupSearchBase: ou=groups,dc=example,dc=org
      groupSearchFilter: member={0}
      groupRoleAttributes: cn
      userDnPattern: cn={0},dc=example,dc=org
    
    file:
      enabled: false
      url: /platformservice/v1/users/authenticate
    authn:
      mode: session
    google: {}
    redis:
      connection: redis://:password@isd-redis-master:6379
    server:
      session:
        timeoutInSeconds: 7200
      tomcat:
        httpsServerPort: X-Forwarded-Port
        internalProxies: .*
        protocolHeader: X-Forwarded-Proto
        remoteIpHeader: X-Forwarded-For
    gate:
      installation:
        mode: common    #Allowed values are --> oes,common
    rbac:
      feature:
        application:
          enabled: false
    security:
      contentSecurityPolicy: "object-src 'none'; script-src 'unsafe-eval' 'unsafe-inline' https: http:;"
    spinnaker:
      extensibility:
        plugins:
        deck-proxy:
          enabled: true
          plugins:
            Opsmx.VerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.TestVerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.PolicyGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VisibilityApprovalPlugin:
              enabled: true
              version: 1.0.1
        repositories:
            opsmx-repo:
              url: file:///opt/spinnaker/plugins/plugins.json
              #url: https://raw.githubusercontent.com/OpsMx/spinnakerPluginRepository/v3.10.0/plugins.json
    
    allowUnauthenticatedAccess:
      agentAPI: false
      webhooks: true
    
    logging:
      level:
        com.netflix.spinnaker.gate.security: INFO
        org.springframework.security: INFO
        org.springframework.web: INFO
        #com.netflix.spinnaker.gate.security: DEBUG
        #org.springframework.security: DEBUG
        #org.springframework.web: DEBUG
    
kind: Secret
metadata:
  name: oes-gate-config
  labels:
    app: oes
    component: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
---
# Source: oes/templates/secrets/oes-gate-secret.yaml
apiVersion: v1
stringData:
  GATEURL: http://sapor-gate:8084
  GATEUSER: admin
  GATEPASS: saporadmin
kind: Secret
metadata:
  name: oes-gate-secret
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
---
# Source: oes/templates/secrets/oes-platform-configmap.yaml
apiVersion: v1
stringData:
  platform-local.yml: |
    
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/platformdb
        username: 'postgres'
        password: 'networks123'
    ldap.managerPassword: 'opsmxadmin123'
    redis:
        connection: redis://:password@isd-redis-master:6379
    #datasource.url: jdbc:postgresql://oes-db:5432/visibilitydb
    #postgres.password: 'networks123'
    #postgres.username: 'postgres'
    
    datasource:
      secretManagement:
        source: db
    rbacEnabled: false
    supportedFeatures:
      - deployment_verification
      - sapor
      - visibility
    userGroup:
      superAdminGroups: admin
    fixedDelay:
      in:
        milliseconds: 120000
    initialDelay:
      in:
        milliseconds: 300000
    scheduler:
      workerThreads: 50
    user:
      source: ldap
    ldap:
      enabled: true
      url: ldap://isd-openldap:389
      managerDn: cn=admin,dc=example,dc=org
      groupSearchBase: ou=groups,dc=example,dc=org
      groupSearchFilter: member={0}
      groupRoleAttributes: cn
      userDnPattern: cn={0},dc=example,dc=org
    
    oes:
      sapor:
        url: http://oes-sapor:8085
      autopilot:
        url: http://oes-autopilot:8090
      dashboard:
        url: http://oes-dashboard:8094
      visibility:
        url: http://oes-visibility:8096
      auditclient:
        url: http://oes-audit-client:8098
      policyGate:
        url: http://oes-gate:8084
        path: /v1/data/
      ui:
      # Ex: "https://oes-poc.dev.opsmx.org/"
        url: "http://oes.example.ops.com/ui"
      gate:
        url: http://oes-gate:8084
      approvalGate:
        apiUrl: http://oes-gate:8084/visibilityservice/v5/approvalGates/{id}/trigger
    
      verificationGate:
        apiUrl: http://oes-gate:8084/autopilot/api/v3/registerCanary
    
    logging:
      level:
        com.opsmx.platformservice: INFO
        org.springframework.security: INFO
        org.springframework.web: INFO
    
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    
kind: Secret
metadata:
  name: oes-platform-config
  labels:
    app: oes
    component: platform
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
---
# Source: oes/templates/secrets/oes-sapor-configmap.yaml
apiVersion: v1
stringData:
  application.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/oesdb
        username: 'postgres'
        password: 'networks123'
    
    message-broker:
      enabled: true
      username: 'rabbitmq'
      password: 'Networks123'
      host: rabbitmq-service
      port: 5672
      endpoint:
        name: rabbitmq
    
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    
    secretManagement:
      source:
        config: db
      encryption: true
    oes:
      rbac:
        enabled: true
      admin:
        user: admin
      platform:
        url: http://oes-platform:8095
      visibility:
        url: http://oes-visibility:8096
      auditservice:
        enabled: true
        url: "http://oes-audit-service:8097"
      dashboard:
        url: http://oes-dashboard:8094
      commongateurl: http://oes-gate:8084
    pipeline-promotion:
      github:
        
        enabled: true
        
        username:  opsmx
        token: opsmxadmin123
        branch: master
        cloneUrl: http://opsmx:opsmxadmin123@isd-gitea-http.opsmx-isd:3000/opsmx/gitea-standard-repo
      bitbucket:
        
        enabled: false
        
        username:  git/stash_username
        token: git/stash_token
        branch: master
        cloneUrl: https://git/stash_username:git/stash_token@github.com/OpsMx//standard-gitops-repo
      amazonS3:
        
        enabled: false
        
        accessKeyId: AWS_ACCESS_KEY_ID
        secretAccessKey: AWS_SECRET_ACCESS_KEY
        region: regionofbucket
        bucketName: bucket name.e.g-testbucket 
    spinnaker:
      restart:
        endPoint: /webhooks/webhook/restartSpinnaker
      encrypt:
        enabled: false
      sync:
        permission:
          enabled: true
    
    datasources:
      platform: true
    
    ## Set the below field to true if agent for kubernetes
    kubernetes:
      kinds:
      omitKinds:
      - podPreset
      agent:
        enabled: true
        serverInternalHostName: opsmx-controller-controller1
        serverPort: 9003
        caCertfile: /opt/opsmx/controller/ca.crt
        certFile: /opt/opsmx/controller/cert/tls.crt
        keyFile: /opt/opsmx/controller/cert/tls.key
        image: quay.io/opsmxpublic/forwarder-agent:v3.5.6
      template:
        path: /opt/opsmx/controller
        kubectlTemplateFileName: kubeconfig.template
        manifestTemplateFileName: deploy-agent.template
    
  client.p12: |
    
kind: Secret
metadata:
  name: oes-sapor-config
  labels:
    app: oes
    component: sapor
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
---
# Source: oes/templates/secrets/oes-visibility-secret.yaml
apiVersion: v1
stringData:
  visibility-local.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/visibilitydb
        username: 'postgres'
        password: 'networks123'
        #sslmode: require
      visiblity:
        connectors:
          configured: JIRA,GIT,AUTOPILOT,SONARQUBE,JENKINS,AQUAWAVE
      logging:
        level:  
          io:     
            swagger:
              models: 
                parameters:
                  AbstractSerializableParameter: ERROR
    
    management:
      endpoints:
        web:
          base-path: /mgmt
          exposure:
            include: health,info,metrics,prometheus
      endpoint:
        health:
          show-details: always
          show-components: always
      health:
        elasticsearch:
          enabled: false
        ldap:
          enabled: false
    
    ui:
      approval:
        url: /ui/plugin-isd/approval/{applicationId}/{serviceId}/{approvalGateId}
    
    gate:
      url: http://oes-gate:8084
    
    jira:
      api:
        url: /rest/api/2/search
      navigate:
        url: hosturl/browse/{issue_Id}
    
    git:
      apiurl: /repos/{account}/{repo}/commits/{commitId}
      userurl: /user
      navigate.url: https://github.com/{account}/{repo_name}/commit/{commit_Id}
    
    jenkins:
      api:
        url: /job/{jobname}/{buildId}/api/json
      navigate:
        url: hosturl/job/{jobname}/{buildId}
    
    sonar:
      navigate:
        Url: hosturl/dashboard?id={projectKey}
    
    aquawave:
      api:
        url: https://api.aquasec.com/v2/images/{id}
      navigate:
        url: https://cloud.aquasec.com/vs/#/images/{id}
    
    autopilot:
      api:
        url: http://oes-autopilot:8090
    
    platform:
      service:
        url: http://oes-platform:8095
    
    datasource:
      secretManagement:
        source: db
    
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    
    
kind: Secret
metadata:
  name: oes-visibility-config
  labels:
    app: oes
    component: visibility
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
---
# Source: oes/templates/secrets/opsmx-gitops-secret.yaml
apiVersion: v1
stringData:
  # Repo uri to fetch halyard configuration
  gitcloneparam: https://git/stash_username:git%2Fstash_token@github.com/OpsMx/standard-gitops-repo.git

  # Repo details to fetch dynamic configuration
  dynamicaccountsgituri: https://github.com/OpsMx/standard-gitops-repo.git
  gituser: git/stash_username
  gittoken: git/stash_token
  dynamicAccRepository: standard-gitops-repo

kind: Secret
metadata:
  name: opsmx-gitops-auth
type: Opaque
---
# Source: oes/templates/secrets/sapor-bootstrap-secret.yaml
apiVersion: v1
stringData:
  bootstrap.yml: |-
    spring:
      cloud:
        config:
          server:
            composite:
              - type: native
                search-locations: ${user.home}/config
        vault:
          enterprise: false
          namespace: admin/isd-platform
          uri: https://server.vaultint.opsmx.net
          token: 123132
          enabled: false
          kv:
            enabled: false
          generic:
            enabled: false
    jasypt:
      encryptor:
        password: Q7udUkHPuA3VnNlOtksSgQ
kind: Secret
metadata:
  name: sapor-bootstrap
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
---
# Source: oes/charts/minio/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
data:
  initialize: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"
    
    # connectToMinio
    # Use a check-sleep-check loop to wait for Minio service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/accesskey) ; SECRET=$(cat /config/secretkey) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to Minio server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} config host add myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }
    
    # checkBucketExists ($bucket)
    # Check if the bucket exists, by using the exit code of `mc ls`
    checkBucketExists() {
      BUCKET=$1
      CMD=$(${MC} ls myminio/$BUCKET > /dev/null 2>&1)
      return $?
    }
    
    # createBucket ($bucket, $policy, $purge)
    # Ensure bucket exists, purging if asked to
    createBucket() {
      BUCKET=$1
      POLICY=$2
      PURGE=$3
      VERSIONING=$4
    
      # Purge the bucket, if set & exists
      # Since PURGE is user input, check explicitly for `true`
      if [ $PURGE = true ]; then
        if checkBucketExists $BUCKET ; then
          echo "Purging bucket '$BUCKET'."
          set +e ; # don't exit if this fails
          ${MC} rm -r --force myminio/$BUCKET
          set -e ; # reset `e` as active
        else
          echo "Bucket '$BUCKET' does not exist, skipping purge."
        fi
      fi
    
      # Create the bucket if it does not exist
      if ! checkBucketExists $BUCKET ; then
        echo "Creating bucket '$BUCKET'"
        ${MC} mb myminio/$BUCKET
      else
        echo "Bucket '$BUCKET' already exists."
      fi
    
    
      # set versioning for bucket
      if [ ! -z $VERSIONING ] ; then
        if [ $VERSIONING = true ] ; then
            echo "Enabling versioning for '$BUCKET'"
            ${MC} version enable myminio/$BUCKET
        elif [ $VERSIONING = false ] ; then
            echo "Suspending versioning for '$BUCKET'"
            ${MC} version suspend myminio/$BUCKET
        fi
      else
          echo "Bucket '$BUCKET' versioning unchanged."
      fi
    
      # At this point, the bucket should exist, skip checking for existence
      # Set policy on the bucket
      echo "Setting policy of bucket '$BUCKET' to '$POLICY'."
      ${MC} policy set $POLICY myminio/$BUCKET
    }
    
    # Try connecting to Minio instance
    scheme=http
    connectToMinio $scheme
    # Create the bucket
    
    # Create the buckets
    createBucket spinnaker none false 
    createBucket autopilot none false
---
# Source: oes/charts/openldap/templates/configmap-customldif.yaml
#
# A ConfigMap spec for openldap slapd that map directly to files under
# /container/service/slapd/assets/config/bootstrap/ldif/custom
#
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-openldap-customldif
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
data:
  01-memberof.ldif: |-
    dn: cn=module,cn=config
    cn: module
    objectClass: olcModuleList
    olcModuleLoad: memberof.la
    olcModulePath: /usr/lib/ldap
    
    dn: olcOverlay={0}memberof,olcDatabase={1}hdb,cn=config
    objectClass: olcConfig
    objectClass: olcMemberOf
    objectClass: olcOverlayConfig
    objectClass: top
    olcOverlay: memberof
    olcMemberOfDangling: ignore
    olcMemberOfRefInt: TRUE
    olcMemberOfGroupOC: groupOfNames
    olcMemberOfMemberAD: member
    olcMemberOfMemberOfAD: memberOf
  02-refint1.ldif: |-
    dn: cn=module{1},cn=config
    changetype: modify
    add: olcmoduleload
    olcmoduleload: refint.la
  03-refint2.ldif: |-
    dn: olcOverlay={1}refint,olcDatabase={1}hdb,cn=config
    objectClass: olcConfig
    objectClass: olcOverlayConfig
    objectClass: olcRefintConfig
    objectClass: top
    olcOverlay: {1}refint
    olcRefintAttribute: memberof member manager owner
  04-add_ou.ldif: |-
    dn: ou=groups,dc=example,dc=org
    objectClass: organizationalUnit
    ou: Groups
  05-admin.ldif: |-
    dn: cn=admin,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: admin
    description: read write and execute group
    member: cn=admin,dc=example,dc=org
  06-developer.ldif: |-
    dn: cn=developers,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: developers
    description: read only users
    member: cn=admin,dc=example,dc=org
    member: cn=developer,dc=example,dc=org
  07-qa.ldif: |-
    dn: cn=QA,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: QA
    description: read only users
    member: cn=admin,dc=example,dc=org
    member: cn=qa,dc=example,dc=org
  08-manager.ldif: |-
    dn: cn=managers,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: managers
    description: read and execute group
    member: cn=admin,dc=example,dc=org
    member: cn=manager,dc=example,dc=org
  09-IT-manager.ldif: |-
    dn: cn=ITManagers,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: ITManagers
    description: read and execute group
    member: cn=admin,dc=example,dc=org
    member: cn=ITManager,dc=example,dc=org
  10-users.ldif: |-
    dn: cn=user1,dc=example,dc=org
    objectClass: simpleSecurityObject
    objectClass: organizationalRole
    cn: user1
    userpassword: {SSHA}Y9L4AsYL16WLK10qDZ62pTScFnaWb0nz
    
    dn: cn=user2,dc=example,dc=org
    objectClass: simpleSecurityObject
    objectClass: organizationalRole
    cn: user2
    userpassword: {SSHA}DasTBI0eut1F83Bh1F1HXmDT8juJj3pY
    
    dn: cn=user3,dc=example,dc=org
    objectClass: simpleSecurityObject
    objectClass: organizationalRole
    cn: user3
    userpassword: {SSHA}Qu1FW7BdLMndwM/Gf+zc3a8VIMAymbuv
    
    dn: cn=developers,ou=groups,dc=example,dc=org
    changetype: modify
    add: member
    member: cn=user1,dc=example,dc=org
    member: cn=user3,dc=example,dc=org
    
    dn: cn=QA,ou=groups,dc=example,dc=org
    changetype: modify
    add: member
    member: cn=user2,dc=example,dc=org
    member: cn=user3,dc=example,dc=org
---
# Source: oes/charts/openldap/templates/configmap-env.yaml
#
# A ConfigMap spec for openldap slapd that map directly to env variables in the Pod.
# List of environment variables supported is from the docker image:
# https://github.com/osixia/docker-openldap#beginner-guide
# Note that passwords are defined as secrets
#
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-openldap-env
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
data:
  LDAP_BACKEND: hdb
  LDAP_DOMAIN: example.org
  LDAP_ORGANISATION: Example Inc.
  LDAP_REMOVE_CONFIG_AFTER_SETUP: "false"
  LDAP_TLS: "true"
  LDAP_TLS_ENFORCE: "false"
---
# Source: oes/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-redis
  labels:
    app: redis
    chart: redis-10.5.3
    heritage: Helm
    release: isd
data:
  redis.conf: |-
    # User-supplied configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly no
    # Disable RDB persistence, AOF persistence already enabled.
    save 60 1000
  master.conf: |-
    dir /data
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
  replica.conf: |-
    dir /data
    slave-read-only yes
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
---
# Source: oes/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-redis-health
  labels:
    app: redis
    chart: redis-10.5.3
    heritage: Helm
    release: isd
data:
  ping_readiness_local.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_PASSWORD --no-auth-warning \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_PASSWORD --no-auth-warning \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_MASTER_PASSWORD --no-auth-warning \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_MASTER_PASSWORD --no-auth-warning \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: oes/charts/spinnaker/templates/configmap/additional-profile-configmaps.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-additional-profile-config-maps
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  echo-local.yml: |-
    microsoftteams:
      enabled: true
    rest:
      enabled: true
      endpoints:
      - url: http://oes-audit-service:8097/auditservice/v1/echo/events/data
        wrap: false
      - url: http://oes-sapor:8085/oes/echo
        wrap: false
  fiat-local.yml: |-
    auth:
      groupMembership:
        ldap:
          groupRoleAttributes: cn
          groupSearchBase: ou=groups,dc=example,dc=org
          groupSearchFilter: member={0}
          managerDn: cn=admin,dc=example,dc=org
          managerPassword: opsmxadmin123
          url: ldap://RELEASE_NAME-openldap:389
          userDnPattern: cn={0},dc=example,dc=org
        service: ldap
  front50-local.yml: |-
    policy:
      opa:
        enabled: true
        url: http://oes-sapor.opsmx-isd:8085
    spinnaker:
      s3:
        versioning: false
  gate-local.yml: |-
    server:
      tomcat:
        httpsServerPort: X-Forwarded-Port
        internalProxies: .*
        protocolHeader: X-Forwarded-Proto
        remoteIpHeader: X-Forwarded-For
    spinnaker:
      extensibility:
        deck-proxy:
          enabled: true
          plugins:
            Opsmx.CustomStagePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.PolicyGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.TestVerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VisibilityApprovalPlugin:
              enabled: true
              version: 1.0.1
        plugins: null
        repositories:
          opsmx-repo:
            url: https://raw.githubusercontent.com/opsmx/spinnakerPluginRepository/v3.9.0/plugins.json
  # Custom stage for pipeline promotion;
  # same configuration can be put in a repo for gitops style
  orca-local.yml: |-
    
    policy:
      opa:
        enabled: true
        url: http://oes-sapor:8085
    pollers:
      oldPipelineCleanup:
        enabled: true                  # This enables old pipeline execution cleanup (default: false)
        intervalMs: 3600000            # How many milliseconds between pipeline cleanup runs (default: 1hr or 3600000)
        thresholdDays: 30              # How old a pipeline execution must be to be deleted (default: 30)
        minimumPipelineExecutions: 5   # How many executions to keep around (default: 5)
    
    tasks:
      daysOfExecutionHistory: 180      # How many days to keep old task executions around.
    
    job:
      preconfigured:
        kubernetes:
          - label: pipelineSyncToGit
            cloudProvider: kubernetes
            credentials: default
            description: Update git with pipelines in Spinnaker
            account: default
            application: sampleapp
            type: pipelineSyncToGit
            waitForCompletion: true
            parameters:
              - defaultValue: "app1,app2,..."
                description: "Please enter spinnaker applications separated by comma"
                label: spinnaker applications
                mapping: 'manifest.spec.template.spec.containers[0].env[0].value'
                name: spinnaker_applications
              - defaultValue: "pipeline1,pipeline2..."
                description: "Please enter spinnaker pipelines separated by comma"
                label: pipieline names
                mapping: 'manifest.spec.template.spec.containers[0].env[1].value'
                name: spinnaker_pipelines
            manifest:
                apiVersion: batch/v1
                kind: Job
                metadata:
                  generateName: pipepromot-
                  namespace: SPINNAKER_NAMESPACE
                  labels:
                     stage: opsmx-custom
                     stagetype: pipelinepromotion
                spec:
                  backoffLimit: 0
                  template:
                    spec:
                      containers:
                      - command: ["bash", "scripts/deployer.sh"]
                        image: 'opsmxdev/pipepromot:1.0'
                        imagePullPolicy: IfNotPresent
                        name: pipepromot
                        volumeMounts:
                        - mountPath: /home/opsmx/scripts
                          name: pipe-promot-scripts
                        - mountPath: /home/opsmx/config
                          name: pipe-promot-config
                        - mountPath: /home/opsmx/.spin
                          name: spin-cli-config
                        env:
                          - name: spinnaker_applications
                            value: 'will be replaced'
                          - name: spinnaker_pipelines
                            value: 'will be replaced'
                          - name: command
                            value: 'upload'
                          - name: git_secret_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_secret_token
                          - name: git_pr_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_pr_token
                      volumes:
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-config
                        name: pipe-promot-config
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-scripts
                        name: pipe-promot-scripts
                      - name: spin-cli-config
                        secret:
                          defaultMode: 420
                          secretName: spin-cli-config
                      restartPolicy: Never
                      serviceAccountName: default
          - label: pipelineSyncToSpinnaker
            cloudProvider: kubernetes
            credentials: default
            description: Sync Spinnaker pipelines from git
            account: default
            application: sampleapp
            type: pipelineSyncToSpinnaker
            waitForCompletion: true
            parameters:
              - defaultValue: "app1,app2,..."
                description: "Please enter spinnaker applications separated by comma"
                label: spinnaker applications
                mapping: 'manifest.spec.template.spec.containers[0].env[0].value'
                name: spinnaker_applications
              - defaultValue: "pipeline1,pipeline2..."
                description: "Please enter spinnaker pipelines separated by comma"
                label: pipieline names
                mapping: 'manifest.spec.template.spec.containers[0].env[1].value'
                name: spinnaker_pipelines
            manifest:
                apiVersion: batch/v1
                kind: Job
                metadata:
                  generateName: pipepromot-
                  namespace: SPINNAKER_NAMESPACE
                  labels:
                     stage: opsmx-custom
                     stagetype: pipelinepromotion
                spec:
                  backoffLimit: 0
                  template:
                    spec:
                      containers:
                      - command: ["bash", "scripts/deployer.sh"]
                        image: 'opsmxdev/pipepromot:1.0'
                        imagePullPolicy: IfNotPresent
                        name: pipepromot
                        volumeMounts:
                        - mountPath: /home/opsmx/scripts
                          name: pipe-promot-scripts
                        - mountPath: /home/opsmx/config
                          name: pipe-promot-config
                        - mountPath: /home/opsmx/.spin
                          name: spin-cli-config
                        env:
                          - name: spinnaker_applications
                            value: 'will be replaced'
                          - name: spinnaker_pipelines
                            value: 'will be replaced'
                          - name: command
                            value: 'download'
                          - name: git_secret_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_secret_token
                          - name: git_pr_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_pr_token
                      volumes:
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-config
                        name: pipe-promot-config
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-scripts
                        name: pipe-promot-scripts
                      - name: spin-cli-config
                        secret:
                          defaultMode: 420
                          secretName: local-spin-cli-config
                      restartPolicy: Never
                      serviceAccountName: default
    webhook:
      preconfigured:
      - label: "JIRA: Wait for state"
        type: waitJiraState
        enabled: true
        description: Custom stage that waits for a specific state on a Jira Issue
        method: GET
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        failPipeline: true
        progressJsonPath: "fields.status.name"
        payload: ""
        retryStatusCodes:
          - 200
        statusJsonPath: "fields.status.name"
        statusUrlResolution: "getMethod"
        successStatuses: ${parameterValues['success']}
        retryStatuses: ${parameterValue['retry']}
        terminalStatuses: ${parameterValues['terminate']}
        canceledStatuses: ${parameterValues['cancel']}
        waitBeforeMonitor: "1"
        waitForCompletion: true
        parameters:
        - label: JIRA Issue ID
          name: issue
          description: "The JIRA issue, the default relies on JIRA issue ID extraction"
          type: string
          defaultValue: ${jira_issue}
        - label: JIRA Retry States
          name: retry
          description: "JIRA issue states that Retry the stage e.g,: To Do, In Progress, etc."
          type: string
          defaultValue: To Do, In Progress
        - label: JIRA Success States
          name: success
          description: "JIRA issue States that progress the pipeline, e.g,: In Verificaiton etc."
          type: string
          defaultValue: In Verification
        - label: JIRA Temination States
          name: terminate
          description: "JIRA issue states that terminates the pipeline, e.g,: PR Raised etc."
          type: string
          defaultValue: PR Raised
        - label: JIRA Canceled States
          name: cancel
          description: "JIRA issue states that cancel the pipeline e.g,: Done, etc."
          type: string
          defaultValue: Done
      - label: "JIRA: Create Issue"
        type: addJiraIss
        enabled: true
        description: Custom stage that add an Issue in Jira
        method: POST
        url: https://<DOMAIN>/rest/api/2/issue/
        customHeaders:
         ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
         Authorization: Basic base64{<<USER>>:<<Jira-token>>}
         Content-Type: application/json
        payload: |-
          {
            "fields": {
               "project":
                {
                  "key": "${parameterValues['projectid']}"
                },
                "summary": "${parameterValues['summary']}",
                "description": "${parameterValues['description']}",
                "issuetype": {
                  "name": "${parameterValues['issuetype']}"
                },
                "components": [
                    {
                  "id": "${parameterValues['components']}"
                }
                ],
                "priority": {
                  "name": "${parameterValues['priority']}"
                }
            }
          }
        parameters:
        - label: Project ID ("ENG" or "DOCS")
          name: projectid
          description: Which JIRA project do you want to create an item in?
          type: string
        - label: Issue Type ("Improvement", "Task", "New Feature", or "Bug")
          name: issuetype
          description: issuetype
          type: string
        - label: Priority ("Low", "Medium", or "High")
          name: priority
          description: priority
          type: string
        - label: Components ("10103")
          name: components
          description: component of the project
        - label: Issue Summary
          name: summary
          description: summary
          type: string
        - label: Description
          name: description
          description: description
          type: string
      - label: "JIRA: Comment on Issue"
        type: comJiraIss
        enabled: true
        description: Custom stage that posts a comment in a Jira Issue
        method: POST
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}/comment
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        payload: |-
          {
            "body": "${parameterValues['message']}"
          }
        parameters:
        - label: Issue ID
          name: issue
          description: Issue
          type: string
        - label: Message
          name: message
          description: message
          type: string
      - label: "JIRA: Update Issue"
        type: updJiraIss
        enabled: true
        description: Custom stage that updates an Issue in Jira
        method: PUT
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        payload: |-
          {
            "update": {
                "summary": [
                    {
                        "set": "${parameterValues['summary']}"
                    }
                ],
                "description": [
                    {
                       "set": "${parameterValues['description']}"
                    }
                ]
            }
          }
        parameters:
        - label: Issue ID
          name: issue
          description: Issue
          type: string
        - label: Summary
          name: summary
          description: summary
          type: string
        - label: Description
          name: description
          description: description
      - label: "JIRA: Transition Issue"
        type: transJiraIss
        enabled: true
        description: Custom stage that transitions an Issue in Jira
        method: POST
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}/transitions
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        payload: |-
          {
            "transition": {
              "id": "${parameterValues['targetStageID']}"
            }
          }
        parameters:
        - label: Issue ID
          name: issue
          description: Issue
          type: string
        - label: Target Stage ID
          name: targetStageID
          description: Target Stage ID (11 is "To Do", 21 is "In Progress", 31 is "In Review", 41 is "Done")
          type: string
    spinnaker:
      extensibility:
        plugins-root-path: /tmp/plugins
        plugins:
          Opsmx.VerificationGatePlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.VisibilityApprovalPlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.TestVerificationGatePlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.PolicyGatePlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.RbacPlugin:
            enabled: true
            version: 1.0.1
            config:
        repositories:
          opsmx-repo:
            id: opsmx-repo
            url: file:///opt/spinnaker/plugins/plugins.json
            #url: https://raw.githubusercontent.com/opsmx/spinnakerPluginRepository/v3.10.0/plugins.json
    

  echo-local.yml: |-
    rest:
      enabled: true
      endpoints:
       -
        wrap: false
        url: http://oes-sapor.opsmx-isd:8085/oes/echo
---
# Source: oes/charts/spinnaker/templates/configmap/halyard-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-halyard-config
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  install.sh: |
    #!/bin/bash

    # Wait for the Hal daemon to be ready
    export DAEMON_ENDPOINT='curl http://isd-spinnaker-halyard:8064/health'
    export HAL_COMMAND="$DAEMON_ENDPOINT"
    until $HAL_COMMAND ; do sleep 10 ; done # end of if not gitops

    # This is performed by post-start script in halyard pod
    # in case gitopsHalyard is enabled
  clean.sh: |
    export HAL_COMMAND='hal --daemon-endpoint http://isd-spinnaker-halyard:8064'
    if $HAL_COMMAND --ready; then
      $HAL_COMMAND deploy clean -q
    fi
  config.sh: |
    # Spinnaker version
    
    $HAL_COMMAND config version edit --version 1.26.6
    

    # Storage
    
    echo spinnakeradmin | $HAL_COMMAND config storage s3 edit \
        --endpoint http://isd-minio:9000 \
        --access-key-id spinnakeradmin \
        --secret-access-key --bucket spinnaker \
        --path-style-access true
    $HAL_COMMAND config storage edit --type s3
    
    
    
    

    # Docker Registry
    $HAL_COMMAND config provider docker-registry enable

    if $HAL_COMMAND config provider docker-registry account get dockerhub; then
      PROVIDER_COMMAND='edit'
    else
      PROVIDER_COMMAND='add'
    fi

    $HAL_COMMAND config provider docker-registry account $PROVIDER_COMMAND dockerhub --address index.docker.io \
       \
      --repositories library/alpine,library/ubuntu,library/centos,library/nginx

    $HAL_COMMAND config provider kubernetes enable

    if $HAL_COMMAND config provider kubernetes account get default; then
      PROVIDER_COMMAND='edit'
    else
      PROVIDER_COMMAND='add'
    fi

    $HAL_COMMAND config provider kubernetes account $PROVIDER_COMMAND default --docker-registries dockerhub \
                --context default --service-account true \
                 \
                --only-spinnaker-managed true \
                 \
                 \
                --omit-namespaces=kube-system,kube-public \
                 \
                 \
                 \
                --provider-version v2
    $HAL_COMMAND config deploy edit --account-name default --type distributed \
                           --location opsmx-isd
    $HAL_COMMAND config deploy ha clouddriver enable
    $HAL_COMMAND config deploy ha echo enable

    
    



    # Enable Authentication by default
    $HAL_COMMAND config security authn ldap edit --url ldap://isd-openldap:389 --user-dn-pattern  'cn={0},dc=example,dc=org'
    $HAL_COMMAND config security authn ldap enable

    # Enable Authorization
    $HAL_COMMAND config security authz disable


    # Use Deck to route to Gate
---
# Source: oes/charts/spinnaker/templates/configmap/halyard-init-script.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-halyard-init-script
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  init.sh: |

    echo \"Checking for Gitea services\"
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    GITEA=$(grep gitea-0 /tmp/inst.status |grep -v deck | awk '{print $2}')

    wait_period=$(($wait_period+10))
    if [ "$GITEA" == "true" ];
    then
        echo \"Gitea Pod is ready\"
        break
    else
        if [ $wait_period -gt 1800 ];
        then
            echo \"Script is timed out as the Gitea is not ready in 30 min.......\"
            break
        else
            echo \"Waiting for Gitea to be ready\"
            sleep 1m
        fi
    fi
    done
    rm -rf /tmp/spinnaker/repo.json
    gitea_user=`echo $GITEA_USER | sed 's/ *$//g'`
    gitea_pass=`echo $GITEA_PASS | sed 's/ *$//g'`
    basic_auth=$(echo -n $gitea_user:$gitea_pass |base64)
    DYNAMIC_ACCOUNTS_REPO=http://isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git
    GIT_USER=$gitea_user
    GIT_TOKEN=$gitea_pass

    echo "Checking if the local gitea repo exists....." 
    curl -k -X GET "http://isd-gitea-http.$SPINNAKER_NAMESPACE:3000/api/v1/users/$gitea_user/repos" >/tmp/spinnaker/repo.json
    checkrepo=$(cat /tmp/spinnaker/repo.json | jq '.[] | select(.name=="gitea-standard-repo")')

        if [ -z "$checkrepo" ]
        then
                echo "Creating a New Local Gitea Repo gitea-standard-repo......."
                curl -k -X POST "http://isd-gitea-http.$SPINNAKER_NAMESPACE:3000/api/v1/user/repos" -H "content-type: application/json" -H "Authorization: Basic $basic_auth" --data '{"name":"'gitea-standard-repo'"}'
                git clone https://github.com/OpsMx/standard-gitops-repo.git -b v4.0 /tmp/spinnaker/test/standard-gitops-repo/
                git clone http://$gitea_user:$gitea_pass@isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git /tmp/spinnaker/test/gitea-standard-repo/
                cp -pr /tmp/spinnaker/test/standard-gitops-repo/* /tmp/spinnaker/test/gitea-standard-repo/
                cd /tmp/spinnaker/test/gitea-standard-repo/
                git status
                git add .
                git config user.email support@opsmx.com
                git config user.name $gitea_user
                git commit -m "cloned standard-gitops-repo content"
                git push
                cd
                rm -rf /tmp/spinnaker/test/gitea-standard-repo
                rm -rf /tmp/spinnaker/test/standard-gitops-repo
                rm -rf /tmp/spinnaker/test
                git clone http://$gitea_user:$gitea_pass@isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git /tmp/spinnaker/test/

        else
                echo "Local Repo exits...."
                rm -rf /tmp/spinnaker/test/gitea-standard-repo
                git clone http://$gitea_user:$gitea_pass@isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git /tmp/spinnaker/test
        fi
        #override the repotye to gitea in order to support pipelin-promotion
        sed -i  s/repo_type=git/repo_type=gitea/ /tmp/spinnaker/test/pipeline-promotion/pipe-promot-config-cm.yaml
        sed -i  s/git_user=/git_user=${GIT_USER}/ /tmp/spinnaker/test/pipeline-promotion/pipe-promot-config-cm.yaml
        sed -i  s/root_folder=/root_folder=pipeline-promotion/ /tmp/spinnaker/test/pipeline-promotion/pipe-promot-config-cm.yaml
    #!/bin/bash -x
    rm -rf /tmp/spinnaker/.hal


    cp -r /tmp/spinnaker/test// /tmp/spinnaker/.hal
    if [ -d "/tmp/spinnaker/test/pipeline-promotion/" ]
    then
       cp -r /tmp/spinnaker/test/pipeline-promotion /tmp/spinnaker/pipeline-promotion
    fi
    if [ -d "/tmp/spinnaker/test/clusterconfig/" ]
    then
       cp -r /tmp/spinnaker/test/clusterconfig /tmp/spinnaker/clusterconfig
    fi
    rm -rf /tmp/spinnaker/test
    DYNAMIC_ACCOUNTS_REPO=`echo $DYNAMIC_ACCOUNTS_REPO | sed 's/ *$//g'`
    sed -i  s/SPINNAKER_NAMESPACE/${SPINNAKER_NAMESPACE}/ /tmp/spinnaker/.hal/config
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/config
    sed -i  s/GIT_USER/${GIT_USER}/g /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s/GIT_TOKEN/${GIT_TOKEN}/g /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  's|DYNAMIC_ACCOUNTS_REPO|'"${DYNAMIC_ACCOUNTS_REPO}"'|' /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s%DYN_ACCNT_CONFG_PATH%/%g /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/default/profiles/rosco-local.yml
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/default/service-settings/redis.yml
    yq e '.deploymentConfigurations.[].security.authz.enabled = "false"' /tmp/spinnaker/.hal/config > /tmp/spinnaker/.hal/config1
    mv /tmp/spinnaker/.hal/config1 /tmp/spinnaker/.hal/config
    if [ -f /tmp/spinnaker/.hal/default/profiles/fiat-local.yml ]; then
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/default/profiles/fiat-local.yml
    fi
    sed -i  s/SPINNAKER_NAMESPACE/${SPINNAKER_NAMESPACE}/ /tmp/spinnaker/.hal/default/profiles/orca-local.yml
    printf 'server.address: 0.0.0.0\n' > /tmp/config/halyard-local.yml
    if [ -f /tmp/spinnaker/.hal/halyard.yaml ]; then
    cp /tmp/spinnaker/.hal/halyard.yaml /tmp/config
    fi
    yq e '.deploymentConfigurations.[].security.authn.saml.enabled = "false"' /tmp/spinnaker/.hal/config > /tmp/spinnaker/.hal/config1
    mv /tmp/spinnaker/.hal/config1 /tmp/spinnaker/.hal/config
    rm -rf /tmp/spinnaker/.hal/default/profiles/orca-overrides.yml
    rm -rf /tmp/spinnaker/.hal/default/profiles/fiat-overrides.yml
    rm -rf /tmp/spinnaker/.hal/default/profiles/gate-overrides.yml
    rm -rf /tmp/spinnaker/.hal/default/profiles/spinnaker.yml  # git or stash  # Enabled  # End of S3
    # pipeline promotion configuration setup
    #
    ls -lart /home/spinnaker/java-lib/
    if [ -d "/tmp/spinnaker/pipeline-promotion/" ]
    then
      #decrypt_key=$(kubectl get cm bootstrap -o yaml  -n ${SPINNAKER_NAMESPACE}| grep 'password:' | awk '{ print $2}')
      #decrypt_key=$(kubectl get secret bootstrap -o jsonpath='{.data.bootstrap\.yml}' -n ${SPINNAKER_NAMESPACE} | base64 -d | grep 'password:' | awk '{ print $2}')
      kubectl get secret bootstrap -o jsonpath='{.data.bootstrap\.yml}' -n ${SPINNAKER_NAMESPACE} | base64 -d > /tmp/decryptkry.txt
      decrypt_key=$(yq e '.jasypt.encryptor.password' /tmp/decryptkry.txt)
      if [[ $decrypt_key != "" ]];
      then
        for filename in /tmp/spinnaker/pipeline-promotion/*; do
          java -cp "Decryptor.jar:/home/spinnaker/java-lib/*" Decryptor $decrypt_key "$filename"
        done
      mkdir /tmp/spinnaker/pipeline-decrypted/
      mv /tmp/spinnaker/pipeline-promotion/*decrypted.yaml /tmp/spinnaker/pipeline-decrypted/
      kubectl apply -f /tmp/spinnaker/pipeline-promotion/pipe-promot-config-cm.yaml -n ${SPINNAKER_NAMESPACE}
      kubectl apply -f /tmp/spinnaker/pipeline-decrypted/ -n ${SPINNAKER_NAMESPACE}
     fi
    fi
   
    ############# Auto Configuration for Custom Stages in ORCA #############

    if [ -d "/tmp/spinnaker/clusterconfig/" ]
    then
      #decrypt_key=$(kubectl get secret bootstrap -o jsonpath='{.data.bootstrap\.yml}' -n ${SPINNAKER_NAMESPACE} | base64 -d | grep 'password:' | awk '{ print $2}')
      kubectl get secret bootstrap -o jsonpath='{.data.bootstrap\.yml}' -n ${SPINNAKER_NAMESPACE} | base64 -d > /tmp/decryptkry.txt
      decrypt_key=$(yq e '.jasypt.encryptor.password' /tmp/decryptkry.txt)
      if [[ $decrypt_key != "" ]];
      then
        for filename in /tmp/spinnaker/clusterconfig/*; do
          java -cp "Decryptor.jar:/home/spinnaker/java-lib/*" Decryptor $decrypt_key "$filename"
        done
      mkdir /tmp/spinnaker/clusterconfig-decrypted/
      mv /tmp/spinnaker/clusterconfig/*decrypted.yaml /tmp/spinnaker/clusterconfig-decrypted/
      kubectl apply -f /tmp/spinnaker/clusterconfig-decrypted/ -n ${SPINNAKER_NAMESPACE}
        if [ -r "/tmp/spinnaker/clusterconfig/servicenow-secret.yaml" ]
        then
           #### Extracting the Service NOW information from secret ####
           SERVICENOW_USER=$(kubectl get secret servicenow-secret -o jsonpath='{.data.SERVICENOW_USERNAME}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           SERVICENOW_DNS=$(kubectl get secret servicenow-secret -o jsonpath='{.data.SERVICENOW_URL}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           SERVICENOW_PASSWD=$(kubectl get secret servicenow-secret -o jsonpath='{.data.SERVICENOW_PASSWORD}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           SERVICENOW_BASE64_USR_PASSWD=$(echo -n "$SERVICENOW_USER:$SERVICENOW_PASSWD" | base64)
           sed -i s%SERVICENOW_URL%${SERVICENOW_DNS}%g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
           sed -i  s/SERVICENOW_BASE64_USR_PASSWD/${SERVICENOW_BASE64_USR_PASSWD}/g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
        else
           echo "Not able to find the ServiceNow secret file"
        fi
        if [ -r "/tmp/spinnaker/clusterconfig/jira-secret.yaml" ]
        then
           #### Extracting the JIRA information from secret ####
           JIRA_USER=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_USERNAME}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           JIRA_DNS=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_URL}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           JIRA_TOKN=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_TOKEN}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           JIRA_BASE64_USR_PASSWD=$(echo -n "$JIRA_USER:$JIRA_TOKN" | base64)
           sed -i s%JIRA_URL%${JIRA_DNS}%g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
           sed -i  s/JIRA_BASE64_USR_PASSWD/${JIRA_BASE64_USR_PASSWD}/g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
        else
           echo "Not able to find the ServiceNow secret file"
        fi
     fi
    fi
---
# Source: oes/charts/spinnaker/templates/configmap/halyard-overrideurl.yaml
apiVersion: v1
data:
  call_overrides.sh: |
    echo $SPINNAKER_NAMESPACE
    sh /tmp/autoconfig/config_overrideurl.sh spin-gate-overrideurl-gitops
    sh /tmp/autoconfig/config_overrideurl.sh spin-deck-overrideurl-gitops
  config_overrideurl.sh: |
    #!/bin/bash -x

    if [ $# -gt 1 ]
    then
       echo "Invalid input, only one argument expected"
       exit
    fi

    COMPONENT=$1
    EXTERNAL_IP_CHECK_DELAY=1

    check_for_loadBalancer()
    {
        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        iter=0
        lapsedTime=0
        while [ $iter -lt 100 ]
        do
          ENDPOINT_IP=$(kubectl get svc $1 -o jsonpath="{.status.loadBalancer.ingress[].ip}")
          if [ ! -z "$ENDPOINT_IP" ];
          then
            echo "Found LoadBalancer IP for" $1
            break
          fi
          sleep 5
          lapsedTime=`expr $lapsedTime + 5`
          if [ $lapsedTime -gt $EXTERNAL_IP_CHECK_DELAY ];
          then
    	echo "Time Lapsed" $lapsedTime
            echo "Timeout! Fetching nodeport IP alternatively"
            break
          fi
          echo "Time Lapsed" $lapsedTime
          iter=`expr $iter + 1`
        done
    }

    case "$COMPONENT" in
      spin-gate)
        ENDPOINT_IP=""
        PORT=8084

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-gate-lb

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort IP and replace in spinnaker.yaml
          #ENDPOINT_IP=$(kubectl get ep kubernetes -n default -o jsonpath="{.subsets[].addresses[].ip}")
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-gate-np -o jsonpath="{.spec.ports[].nodePort}")
          sed -i  s/OVERRIDE_API_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        else
          ## Substitute spin-gate external IP in hal config
          sed -i  s/OVERRIDE_API_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        fi
        ;;

      spin-deck)
        ENDPOINT_IP=""
        PORT=9000

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-deck-lb

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort & nodeport and replace in app-config.js
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-deck-np -o jsonpath="{.spec.ports[].nodePort}")
          sed -i  s/OVERRIDE_DECK_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        else
          ## Substitute spin-deck external IP in hal config
          sed -i  s/OVERRIDE_DECK_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        fi
        ;;
      override-gate-url)
        ENDPOINT_IP=""
        PORT=8084

        export DAEMON_ENDPOINT=http://isd-spinnaker-halyard:8064
        export HAL_COMMAND="hal --daemon-endpoint $DAEMON_ENDPOINT"

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-gate-np

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort IP and replace in spinnaker.yaml
          #ENDPOINT_IP=$(kubectl get ep kubernetes -n default -o jsonpath="{.subsets[].addresses[].ip}")
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-gate-np -o jsonpath="{.spec.ports[].nodePort}")
          $HAL_COMMAND config security api edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        else
          ## Run hal config edit command to override gate url
          $HAL_COMMAND config security api edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        fi
        ;;
      override-deck-url)
        ENDPOINT_IP=""
        PORT=9000

        export DAEMON_ENDPOINT=http://isd-spinnaker-halyard:8064
        export HAL_COMMAND="hal --daemon-endpoint $DAEMON_ENDPOINT"

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-deck-np

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort & nodeport and replace in app-config.js
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-deck-np -o jsonpath="{.spec.ports[].nodePort}")
          $HAL_COMMAND config security ui edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        else
          ## Run hal config edit command to override deck url
          $HAL_COMMAND config security ui edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        fi
        ;;
      spin-gate-overrideurl-gitops)
        ## Configured ingress host url as override url
          echo "Substituting gate url"
          sed -i 's,PROTOCOL,http,g' /tmp/spinnaker/.hal/config
          sed -i 's,OVERRIDE_API_URL,oes.example.ops.com/gate,g' /tmp/spinnaker/.hal/config
        ;;
      spin-deck-overrideurl-gitops)
        ## Configured ingress host url as override url
          echo "Substituting deck url"
          sed -i 's,OVERRIDE_DECK_URL,oes.example.ops.com/deck,g' /tmp/spinnaker/.hal/config
        ;;
      *)
        echo  COMP=$COMPONENT
        echo "Invalid input:$COMPONENT"
        ;;
    esac

kind: ConfigMap
metadata:
  name: isd-spinnaker-halyard-overrideurl
---
# Source: oes/charts/spinnaker/templates/configmap/secret-decoder.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-spin-secret-decoder
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  run.sh: |-
    #!/bin/bash
    echo "##########Replacing Secret#########"
    grep -ir encrypted: /tmp/spinnaker/.hal | sort -t: -u -k1,1 |cut -d : -f1 > tmp.list
    while IFS= read -r file; do
    grep encrypted: $file > tmp1.list
    while read line ; do
    echo ${line#*encrypted:} ;
    done < tmp1.list > secret-strings.list
    while read secret ; do
    secretName=${secret%%:*}
    echo "---------$secretName---"
    keyName=${secret#*:}
    keyName=${keyName%%\"*}
    keyName=${keyName%% *}
    echo "----------$keyName--"
    #echo "secret Name= $secretName and key is = $keyName"
    #kubectl get secret -o jis
    #echo kubectl --kubeconfig /home/srini/ibm-cloud/staging/ibmstaging.config -n ninja-srini get secret $secretName -o json  jq -r ".data.$keyName"
    jqParam=".data.\"$keyName\""
    value=$(kubectl get secret $secretName -o json | jq -r $jqParam | base64 -d)
    value=$(echo $value | sed -e 's`[][\\/.*^$]`\\&`g')
    #echo "-----------$value---"
    #echo "secret Name= $secretName and key is = $keyName and value is $value"
    sed -i s/encrypted:$secretName:$keyName/$value/g $file
    done < secret-strings.list
    done < tmp.list

    echo "########### Replacing Kubeconfigs ############"
    grep encryptedFile /tmp/spinnaker/.hal/config > tmp.list
    while read line ; do
    echo ${line#*encryptedFile:} ;
    done < tmp.list  > secret-files.list

    while read secret ; do
    secretName=${secret%%:*}
    keyName=${secret#*:}
    keyName=${keyName%%\"*}
    keyName=${keyName%% *}
    echo "secret Name= $secretName and key is = $keyName"
    jqParam=".data.\"$keyName\""
    mkdir -p /tmp/spinnaker/kubeconfigdir
    kubectl get secret $secretName -o json | jq -r $jqParam | base64 -d > /tmp/spinnaker/kubeconfigdir/$keyName
    #echo "secret Name= $secretName and key is = $keyName and value is in $keyName"
    old_value="encryptedFile:$secretName:$keyName"
    new_value="/home/spinnaker/kubeconfigdir/$keyName"
    #echo $old_value
    #echo $new_value
    sed -i "s/${old_value}/$(echo $new_value | sed 's_/_\\/_g')/g" /tmp/spinnaker/.hal/config
    done < secret-files.list
    rm -rf secret-files.list secret-strings.list tmp.list
---
# Source: oes/charts/spinnaker/templates/configmap/service-settings.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-service-settings
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"

data:
  clouddriver-caching.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver-ro-deck.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver-ro.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver-rw.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  deck.yml: |-
    artifactId: quay.io/opsmxpublic/ubi8-oes-deck:3.5.1
    env:
      API_HOST: http://spin-gate:8084
  echo-scheduler.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1'
  echo-worker.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1'
  echo.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1'
  fiat.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-fiat:1.16.0'
  front50.yml: 'artifactId: quay.io/opsmxpublic/ubi8-oes-front50:0.27.1-opa'
  gate.yml: |-
    artifactId: quay.io/opsmxpublic/ubi8-oes-spin-gate:1.22.1
    healthEndpoint: /health
    kubernetes:
      useExecHealthCheck: false
  igor.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-igor:1.16.0'
  kayenta.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-kayenta:0.21.0'
  orca.yml: 'artifactId: quay.io/opsmxpublic/ubi8-oes-orca:2.20.4'
  redis.yml: |-
    overrideBaseUrl: redis://<EXTERNAL-REDIS-HOST-NAME>:6379
    skipLifeCycleManagement: true
  rosco.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-rosco:0.25.0'
---
# Source: oes/charts/spinnaker/templates/configmap/spin-pipeline-import.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-spin-pipeline-import
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  spin-pipeline-import.sh: |-
    #!/bin/bash
    echo \"Waiting for all Spinnaker Services to come-up\"
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    ## NON-HA
    CLOUDDRIVER=$(grep spin-clouddriver /tmp/inst.status |grep -v deck | awk '{print $2}')
    ECHO=$(grep spin-echo /tmp/inst.status | awk '{print $2}')
    ## HA
    CLOUDRO=$(grep spin-clouddriver-ro /tmp/inst.status |grep -v deck | awk '{print $2}')
    CLOUDRODECK=$(grep spin-clouddriver-ro-deck /tmp/inst.status | awk '{print $2}')
    CLOUDRW=$(grep spin-clouddriver-rw /tmp/inst.status | awk '{print $2}')
    CLOUDCACHING=$(grep spin-clouddriver-caching /tmp/inst.status | awk '{print $2}')
    DECK=$(grep spin-deck /tmp/inst.status | awk '{print $2}')
    ECHOWORKER=$(grep spin-echo-worker /tmp/inst.status | awk '{print $2}')
    ECHOSCHEDULER=$(grep spin-echo-scheduler  /tmp/inst.status | awk '{print $2}')
    FRONT=$(grep spin-front /tmp/inst.status  | awk '{print $2}')
    GATE=$(grep spin-gate /tmp/inst.status | awk '{print $2}')
    IGOR=$(grep spin-igor /tmp/inst.status | awk '{print $2}')
    ORCA=$(grep spin-orca /tmp/inst.status | awk '{print $2}')
    FIAT=$(grep spin-fiat /tmp/inst.status | awk '{print $2}')
    #ROSCO=$(grep spin-rosco /tmp/inst.status | awk '{print $2}')
    ## AUTOPILOT
    SAPORGATE=$(grep sapor-gate /tmp/inst.status | awk '{print $2}')
    OESGATE=$(grep oes-gate /tmp/inst.status | awk '{print $2}')


    wait_period=$(($wait_period+10))
    READYBASIC=$( [ "$DECK" == "true" ] && [ "$CLOUDCACHING" == "true" ] && [ "$CLOUDRO" == "true" ] && [ "$CLOUDRW" == "true" ] && [ "$CLOUDRODECK" == "true" ] && [ "$FRONT" == "true" ] && [ "$GATE" == "true" ] && [ "$ORCA" == "true" ] && [ "$ECHOWORKER" == "true" ] && [ "$ECHOSCHEDULER" == "true" ] && [ "$SAPORGATE" == "true" ] && [ "$OESGATE" == "true" ];  echo $(($? == 0)) )
    READY=$READYBASIC


    if [ $READY == 1 ];
    #CLOUDRO=$(grep spin-clouddriver-ro /tmp/inst.status |grep -v deck | awk '{print $2}')
    #CLOUDRODECK=$(grep spin-clouddriver-ro-deck /tmp/inst.status | awk '{print $2}')
    #CLOUDRW=$(grep spin-clouddriver-rw /tmp/inst.status | awk '{print $2}')
    #CLOUDCACHING=$(grep spin-clouddriver-caching /tmp/inst.status | awk '{print $2}')
    #DECK=$(grep spin-deck /tmp/inst.status | awk '{print $2}')
    #ECHOWORKER=$(grep spin-echo-worker /tmp/inst.status | awk '{print $2}')
    #ECHOSCHEDULER=$(grep spin-echo-scheduler  /tmp/inst.status | awk '{print $2}')
    #FRONT=$(grep spin-front /tmp/inst.status  | awk '{print $2}')
    #GATE=$(grep spin-gate /tmp/inst.status | awk '{print $2}')
    #FIAT=$(grep spin-fiat /tmp/inst.status | awk '{print $2}')
    #ORCA=$(grep spin-orca /tmp/inst.status | awk '{print $2}')
    #SAPORGATE=$(grep sapor-gate /tmp/inst.status | awk '{print $2}')
    #OESGATE=$(grep oes-gate /tmp/inst.status | awk '{print $2}')
    #wait_period=$(($wait_period+10))
    #
    #if [ "$DECK" == "true" ] && [ "$CLOUDCACHING" == "true" ] && [ "$CLOUDRO" == "true" ] && [ "$CLOUDRW" == "true" ] && [ "$CLOUDRODECK" == "true" ] && [ "$FRONT" == "true" ] && [ "$GATE" == "true" ] && [ "$ORCA" == "true" ] && [ "$ECHOWORKER" == "true" ] && [ "$ECHOSCHEDULER" == "true" ] && [ "$SAPORGATE" == "true" ] && [ "$OESGATE" == "true" ];
    #
    then
        echo \"Spinnaker and OES is Installed and ready\"
        mkdir -p /tmp/config/git/
        git -c http.sslVerify=false clone https://github.com/OpsMx/sample-pipelines.git /tmp/config/git/
        if [[ $? != 0 ]]; then
        echo "ERROR: Failed while cloning the repo https://github.com/OpsMx/sample-pipelines.git"
          exit 1
        fi
        echo "processing.........."
        sleep 100
        cd /tmp/config/git
        cp -p /tmp/config/spin/config .
        ### remove commected line in file
        grep -v "#" create-app.sh > removecomment.sh 
        sed 's/$/ --config config/' removecomment.sh > create-app1.sh
        #### Loop begins to save the json if fails it tries for 3 times
        INPUT=$(sed -n '$=' create-app1.sh)
        for i in $(seq 1 $INPUT); do
        command=$(sed -n "$i"p create-app1.sh);
        $command > /dev/null 2>&1
        if [[ $? != 0 ]]; then
          n=0
          until [ "$n" -ge 3 ]
          do
           echo Retrying.....
           $command > /dev/null 2>&1
            if [[ $? != 0 ]]; then
              echo "ERROR: Failed to save the Application using the spincli. Please check the spincli configuration in isd-spinnaker-spin-config  secret or check the pipelinejson"
              #exit 1
              if [[ "$i" == 3 ]]; then
              echo "ERROR: Failed to save the Application using the spincli. Please check the spincli configuration in isd-spinnaker-spin-config  secret or check the pipelinejson"
              exit 1
              fi
            else
              echo "$command"
              echo "Saved successfully"
            fi
           n=$((n+1))
           sleep 5
         done
        else
          echo "$command"
          echo "Saved successfully"
        fi
        done
        break
    else
        if [ $wait_period -gt 1800 ];
        then
            echo \"Script is timed out as the Spinnaker is not ready in 30 min.......\"
            break
        else
            echo \"Waiting for Spinnaker services to be ready\"
            sleep 1m
        fi
    fi
    done
---
# Source: oes/templates/clouddriver-sidecar/k8sconfig-sync.yaml
apiVersion: v1
data:
  k8config-sync.sh: |
    #!/bin/bash
    export GIT_CLONE_PARAM=$(cat /tmp/secret/gitcloneparam)
    export GIT_URL=$(cat /tmp/secret/dynamicaccountsgituri)
    export DYNAMIC_ACCOUNTS_REPO=$(cat /tmp/secret/dynamicAccRepository)
    rm -rf $DYNAMIC_ACCOUNTS_REPO
    mkdir -p /opsmx
    echo " ####### Cloning the Dynamic Account Repo #################"
    git clone -c http.sslVerify=false $GIT_CLONE_PARAM
    #cd $DYNAMIC_ACCOUNTS_REPO/
    cat $DYNAMIC_ACCOUNTS_REPO///clouddriver-local.yml |grep -i opsmx |awk '{print $2}' |tr -d '"' | awk 'BEGIN{FS="/opsmx/"}{print $2}' > /opsmx/config_files.txt
    for config in $(cat /opsmx/config_files.txt)
    do
    kubectl get secrets $config -o=jsonpath='{.data.*}'|base64 -d > /opsmx/$config
    done
kind: ConfigMap
metadata:
  name: k8config-sync
---
# Source: oes/templates/configmaps/datasource-creation.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-oes-datasource-creation
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
data:
  datasource-api.sh: |-
    #!/bin/bash
    set -x
    echo \"Waiting for all Spinnaker and OES Services to come-up\"
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    ## NON-HA
    CLOUDDRIVER=$(grep spin-clouddriver /tmp/inst.status |grep -v deck | awk '{print $2}')
    ECHO=$(grep spin-echo /tmp/inst.status | awk '{print $2}')
    ## HA
    CLOUDRO=$(grep spin-clouddriver-ro /tmp/inst.status |grep -v deck | awk '{print $2}')
    CLOUDRODECK=$(grep spin-clouddriver-ro-deck /tmp/inst.status | awk '{print $2}')
    CLOUDRW=$(grep spin-clouddriver-rw /tmp/inst.status | awk '{print $2}')
    CLOUDCACHING=$(grep spin-clouddriver-caching /tmp/inst.status | awk '{print $2}')
    DECK=$(grep spin-deck /tmp/inst.status | awk '{print $2}')
    ECHOWORKER=$(grep spin-echo-worker /tmp/inst.status | awk '{print $2}')
    ECHOSCHEDULER=$(grep spin-echo-scheduler  /tmp/inst.status | awk '{print $2}')
    FRONT=$(grep spin-front /tmp/inst.status  | awk '{print $2}')
    GATE=$(grep spin-gate /tmp/inst.status | awk '{print $2}')
    IGOR=$(grep spin-igor /tmp/inst.status | awk '{print $2}')
    ORCA=$(grep spin-orca /tmp/inst.status | awk '{print $2}')
    FIAT=$(grep spin-fiat /tmp/inst.status | awk '{print $2}')
    #ROSCO=$(grep spin-rosco /tmp/inst.status | awk '{print $2}')
    ## AUTOPILOT
    SAPOR=$(grep oes-sapor /tmp/inst.status | awk '{print $2}')
    PLATFORM=$(grep oes-platform /tmp/inst.status | awk '{print $2}')
    AUTOPILOT=$(grep oes-autopilot /tmp/inst.status | awk '{print $2}')


    wait_period=$(($wait_period+10))
    READYBASIC=$([ "$DECK" == "true" ] && [ "$CLOUDCACHING" == "true" ] && [ "$CLOUDRO" == "true" ] && [ "$CLOUDRW" == "true" ] && [ "$CLOUDRODECK" == "true" ] && [ "$FRONT" == "true" ] && [ "$ORCA" == "true" ]  && [ "$ECHOWORKER" == "true" ] && [ "$ECHOSCHEDULER" == "true" ] && [ "$SAPOR" == "true" ] && [ "$PLATFORM" == "true" ] && [ "$AUTOPILOT" == "true" ] && [ "$GATE" == "true" ] && [ "$IGOR" == "true" ]; echo $(($? == 0)) )
    READY=$READYBASIC


    if [ $READY == 1 ] ;
        then
            echo \"Spinnaker and OES services are Up and Ready..\"
            sleep 5
            curl -X POST "http://sapor-gate:8084/login?username=admin&password=saporadmin&submit=Login"
            curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "OPA", "name": "OPA", "configurationFields": {"endPoint": "http://opa:8181"}}'   http://oes-platform:8095/platformservice/v2/datasources
            curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "AUTOPILOT", "name": "Autopilot", "configurationFields": {"username": "admin"} }'   http://oes-platform:8095/platformservice/v2/datasources
            #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "ELASTICSEARCH", "name": "elastic-default", "configurationFields": {"endPoint": "https://newoeselastic.opsmx.com", "username": "opsmxuser", "password": "OpsMx@123", "kibanaEndPoint": "https://newoeskibana.opsmx.com", "kibanaPassword": "OpsMx@123", "kibanaUsername": "opsmxuser" }}'   http://oes-platform:8095/platformservice/v2/datasources
            #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "PROMETHEUS", "name": "prometheus-default", "configurationFields": {"endPoint": "http://prometheus:9090"} }'   http://oes-platform:8095/platformservice/v2/datasources
            echo "Creating OPA Policies"
            curl --header 'Content-Type: application/json' --header 'x-spinnaker-user: admin' --request POST http://oes-sapor:8085/oes/v2/policy/save --data '{"name":"AppMustHaveRbac","type":"Static","accountType":"OPA","accountName":"OPA","description":"Enforce Application in Spinnakr to have Roles defined.","status":"INACTIVE","rego":"# Static Policy to enforce assigning roles when creating an application\n# Once enforced, it is not possible to create an application that is visible to all\n# by mistake\n\npackage opsmx.spinnaker.authorization\n\ndeny[\"Permissions must be specified\"] {\n   not(appHasWritePermissions)\n   input.new.job[_].type==\"updateApp\"\n }{\n   not(appHasWritePermissions)\n   input.new.job[_].type==\"createApp\"\n}\nappHasWritePermissions {\n  count(input.new.job[0].application.permissions.WRITE) > 0\n}"}'
            curl --header 'Content-Type: application/json' --header 'x-spinnaker-user: admin' --request POST http://oes-sapor:8085/oes/v2/policy/save --data '{"name":"StageLevelRBAC","type":"Static","accountType":"OPA","accountName":"OPA","description":"Restrict a group of users from modifying certain stages","status":"INACTIVE","rego":"package opsmx.spinnaker.stage_rbac\nimport future.keywords.in\n\n# The permissions json is to be defined to restrict some users from making changes to a specific stage\n# in the pipeline. The parameters for each stage are \"name\" of the pipeline, \"type\" of the pipeline and \"grant\" privilege\n# which can hold 2 values: allow and deny\npermissions = {\n  \"role_grants\": {\n    \"demo-users\": [\n      {\n        \"name\": \"Build\",\n        \"type\": \"jenkins\",\n        \"grant\": \"deny\"\n      },\n      { \n        \"name\": \"Deploy \",\n        \"type\": \"deployManifest\",\n        \"grant\": \"deny\"\n      },\n      { \n        \"name\": \"Manual Judgment \",\n        \"type\": \"manualJudgment\",\n        \"grant\": \"deny\"\n      },\n      {\n        \"name\": \"Wait\",\n        \"type\": \"wait\",\n        \"grant\": \"deny\"\n      }\n    ]\n  }\n}\n\n\n# modified_stages is the set of stages which carry \"modified\", \"new\" and \"deleted\" stageStatus. \n# only the stages with stageStatus = unmodified are excluded.\n\nmodified_stages = [input.pipeline.stages[idx] | input.pipeline.stages[idx].stageStatus != \"unmodified\"]\n#modified_stage_name = [input.pipeline.stages[idx].name | input.pipeline.stages[idx].stageStatus != \"unmodified\"]\n\n\n# The operation is denied if there is no modified/new/deleted stage in the pipeline\ndeny[\"No modified stages found\"]{\n  count(input.pipeline.stages) > 0         # only because we still have fron50 plugin; this will be removed in 3.12.x release\n  count(modified_stages) <= 0\n}\n\n# If there are modifications in the pipeline, the privileges of users to operate on a set of stages\n# is evaluated on the basis of\n\n# 1. If the user is admin, allow the user to do anything\n# 2. If the permissions json does not carry definition of privileges for any group assigned to the user,\n# then the user is to be allowed to make any changes\n# 3. If there are no denials in the permissions definition, then the user is to be allowed to make any changes\n# 4. If there are denials for some stages in any of the role assigned to user, then\n#\t4a. Checking if the same stages is allowed for any other role assigned to user\n#   4b. If a respective allow privilege is available, then allow.\n#   4c. If not then deny\n# 5. If there are any denials w.r.t. modified stages, simply deny the user from saving.\n# Rule 4 and 5 are contradicting, one of them is to be enabled. Comment line 92-100 to disable rule 4.\n\ndeny[msg]{\n  #not user_is_admin\n  \n  some i\n  role_def = permissions.role_grants[i]\n  role_def_flag = i in input.pipeline.user.groups\n  role_def_flag == true\n  \n  denial_set = user_is_denied\n  denial_size = count(denial_set) \n  to_number(denial_size) > 0\n\n# Comment rest of the statements in this rule if rule 4 is to be enabled\n  acceptance_set = user_is_allowed\n\n  some j\n  accepted_stages = [acceptance_set[j].name | acceptance_set[j].grant == \"allow\"]\n  \n  some k\n  denied_stages = [denial_set[k].name | denial_set[k].grant == \"deny\"; not denial_set[k].name in accepted_stages]\n  denial_size_after_acceptance = count(denied_stages)\n  denial_size_after_acceptance > 0\n  \n  denial_stage_msg = concat(\",\" , denied_stages)\n  msg = sprintf(\"Denied for stages: %v\", [denial_stage_msg])\n}\n\n\n# Check if user is admin\n#user_is_admin {\n # \"admin\" in input.pipeline.user.groups\n#}\n\n# Obtain list of denied and allowed stages for the groups assigned to user\nmake_grant_decision{  \n  some grant_idx\n  user_is_denied[grant_idx]\n\n  some grant_idx2\n  user_is_allowed[grant_idx2]\n}\n\nuser_is_denied[grant_idx] {\n  some stage in modified_stages\n  some role in input.pipeline.user.groups\n  some grant_idx in permissions.role_grants[role]\n  \n  grant_idx.name == stage.name\n  grant_idx.type == stage.type\n  grant_idx.grant == \"deny\" \n}\n\nuser_is_allowed[grant_idx2] {\n  some stage in modified_stages\n  some role in input.pipeline.user.groups\n  some grant_idx2 in permissions.role_grants[role]\n  \n  grant_idx2.name == stage.name\n  grant_idx2.type == stage.type\n  grant_idx2.grant == \"allow\" \n}"}'
            curl --header 'Content-Type: application/json' --header 'x-spinnaker-user: admin' --request POST http://oes-sapor:8085/oes/v2/policy/save --data '{"name":"BlackOutWindow","type":"Runtime","accountType":"OPA","accountName":"OPA","description":"Policy to Prevent deployment during a specified date/time range.","status":"INACTIVE","rego":"# Sample Runtime policy\n  # This policy blocks deployments in the blackout window period\n  \n  package opsmx.blackoutwindow\n  \n  deny[\"No deploys between 25th - 31st Dec 2020\"] {\n    [year, month, day] := time.date([time.now_ns(), \"America/Los_Angeles\"])\n    year == 2020\n    month == 12\n    day >= 25\n    day <= 31\n  }"}'

            STORAGE_TYPE=gitea
            GITEA_USERNAME=opsmx
            GITEA_PASSWORD=opsmxadmin123
            USERNAME=admin
            PASSWORD=saporadmin
            response=$(curl -s http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker)
            name=$(echo $response | jq '.[].name')
            if [ -z "$name" ];
            then
              if [[ "$STORAGE_TYPE"  ==  "gitea" ]];
              then

              curl -X POST -H "Content-Type: application/json"  -k -d '{"name":"'"$GITEA_USERNAME"'"}' -u $GITEA_USERNAME:$GITEA_PASSWORD http://isd-gitea-http.opsmx-isd:3000/api/v1/users/$GITEA_USERNAME/tokens >token.json
              TOKEN=$(cat token.json | jq '.sha1' -r)

              response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v6/datasource --data '{"datasourceType": "GITHUB", "name": "gitops", "spinEnabled": "false", "configurationFields": {"token": "'$TOKEN'", "username": "", "hostUrl": "http://isd-gitea-http:3000", "url": "http://isd-gitea-http:3000/api/v1/users/opsmx" } }')
              
              id=$(echo $response | jq '.id')
              curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":true,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITHUB","config":{"bucketName":"","region":"","endPoint":"http://isd-gitea-http:3000/'$GITEA_USERNAME'/gitea-standard-repo.git","sourcePath":""}},"pipelinePromotionConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITHUB","config":{"bucketName":"","region":"","endPoint":"http://isd-gitea-http:3000/'$GITEA_USERNAME'/gitea-standard-repo.git","sourcePath":""}},"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'

              sleep 5
              kubectl delete po isd-spinnaker-halyard-0 -n opsmx-isd
              #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":false,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITHUB","config":{"bucketName":"","region":"","endPoint":"http://isd-gitea-http:3000/'$GITEA_USERNAME'/gitea-standard-repo.git","sourcePath":""}},"pipelinePromotionConfiguration":null,"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'
                 break
              fi
            fi

            STORAGE_TYPE=git
            BASEURL_HOST=github.com
            USERNAME=admin
            PASSWORD=saporadmin
            TOKEN=$(echo -n "$USERNAME":"$PASSWORD" | base64)
            response=$(curl -s http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker)
            name=$(echo $response | jq '.[].name')
            if [ -z "$name" ];
            then
              if [[ "$STORAGE_TYPE"  ==  "git" && "$BASEURL_HOST" == "github.com" ]];
              then
              response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v6/datasource --data '{"datasourceType": "GITHUB", "name": "gitops", "spinEnabled": "false", "configurationFields": {"token": "git/stash_token", "username": "git/stash_username", "hostUrl": "https://github.com/", "url": "https://api.github.com" } }')
              id=$(echo $response | jq '.id')
              curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":false,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITHUB","config":{"bucketName":"","region":"","endPoint":"https://github.com/OpsMx/standard-gitops-repo.git","sourcePath":""}},"pipelinePromotionConfiguration":null,"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'
              #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://oes-gate.example.ops.com", "authenticationType": "LDAP", "token": "'"${TOKEN}"'", "externalAccountFlag": "true","pipelinePromotionFlag": "false","syncAccountFlag": "false", "externalAccountConfiguration": {"accountId": "'"${id}"'","accountName": "gitops", "provider": "GITHUB", "config": {"bucketName": "", "region": "","endPoint": "https://github.com/OpsMx/standard-gitops-repo.git", "sourcePath": "" }}}'
                  break
              fi
              if [[ "$STORAGE_TYPE"  ==  "git" && "$BASEURL_HOST" == "gitlab.com" ]];
              then
              response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v6/datasource --data '{"datasourceType": "GITLAB", "name": "gitops", "spinEnabled": "false", "configurationFields": {"token": "git/stash_token", "hostUrl": "https://gitlab.com/" } }')
              id=$(echo $response | jq '.id')
              curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":false,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITLAB","config":{"bucketName":"","region":"","endPoint":"https://gitlab.com/OpsMx/standard-gitops-repo.git","sourcePath":""}},"pipelinePromotionConfiguration":null,"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'
                  break
              fi
              if [[ "$STORAGE_TYPE"  ==  "stash" ]];
              then
                if [[ "" ]]
                then
                  response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v2/datasources --data '{"datasourceType": "BITBUCKET", "name": "gitops-bitbucket", "spinEnabled": "false", "configurationFields": {"authType":"bearer","username": "git/stash_username","token": "git/stash_token","read":"","write":"",  "hostUrl": "https://github.com/OpsMx//standard-gitops-repo.git", "url": "https://api.bitbucket.org/2.0/" } }')
                  id=$(echo $response | jq '.id')
                   curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://sapor-gate:8084", "authenticationType": "LDAP", "token": "'"${TOKEN}"'", "externalAccountFlag": "true", "pipelinePromotionFlag": "false","syncAccountFlag": "false", externalAccountConfiguration": {"accountId": "'"${id}"'","accountName": "gitops-bitbucket", "provider": "BITBUCKET", "config": {"bucketName": "", "region": "","endPoint": "https://github.com/OpsMx//standard-gitops-repo.git", "sourcePath": " " }}}'

                  break
                else
                  response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v2/datasources --data '{"datasourceType": "BITBUCKET", "name": "gitops-bitbucket", "spinEnabled": "false", "configurationFields": {"authType":"bearer","username": "git/stash_username","token": "git/stash_token","read":"","write":"", "hostUrl": "https://github.com/OpsMx//standard-gitops-repo.git", "url": "https://api.bitbucket.org/2.0/" } }')
                  id=$(echo $response | jq '.id')
                  curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://sapor-gate:8084", "authenticationType": "LDAP", "token": "'"${TOKEN}"'", "externalAccountFlag": "true", "pipelinePromotionFlag":"false","syncAccountFlag":"false", externalAccountConfiguration": {"accountId": "'"${id}"'","accountName": "gitops-bitbucket", "provider": "BITBUCKET", "config": {"bucketName": "", "region": "","endPoint": "https://github.com/OpsMx//standard-gitops-repo.git", "sourcePath": "" }}}'
                  break
                fi
              fi
              if [[ "$STORAGE_TYPE"  ==  "s3" ]];
              then
                 curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v2/datasources --data '{"datasourceType":"AMAZONS3","name":"gitops-s3","configurationFields":{"access_id":"AWS_ACCESS_KEY_ID","secret_key":"AWS_SECRET_ACCESS_KEY"},"spinnakerNames":[""],"spinEnabled": "false"} }'
                 curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://sapor-gate:8084", "authenticationType": "LDAP", "token": "'"${TOKEN}"'" , "externalAccountFlag": "true", "pipelinePromotionFlag":"false", "syncAccountFlag":"false", externalAccountConfiguration": {"accountName": "gitops-s3","config":{"bucketName":"bucket name.e.g-testbucket","region":"regionofbucket","endPoint":""},"provider": "AMAZONS3"}}'
              fi
            else
              echo "Spinnaker is already Integrated"
              break
            fi
        

    else
        if [ $wait_period -gt 2000 ];
        then
            echo \"Script is timed out as the Spinnaker is not ready yet.......\"
            break
        else
            echo \"Waiting for Spinnaker services to be ready\"
            sleep 1m
        fi
    fi
    done
---
# Source: oes/templates/configmaps/oes-dashboard-configmap.yaml
apiVersion: v1
data:
  dashboard-local.yml: |
    opsmx:
      dashboard:
        installation:
          mode: OES-AP
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    platformservice.url: http://oes-platform:8095
    autopilot.url: http://oes-autopilot:8090
    oes.sapor.url: http://oes-sapor:8085
    visibilityservice.url: http://oes-visibility:8096
    auditclientservice:
      url: "http://oes-audit-client:8098"
    gateservice:
      url: "http://oes-gate:8084"
    app:
      sync:
        enabled: true
    spinnakerLink: /deck/
    
kind: ConfigMap
metadata:
  name: oes-dashboard-config
  labels:
    app: oes
    component: dashboard
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
---
# Source: oes/templates/configmaps/oes-ui-configmap.yaml
apiVersion: v1
data:
  app-config.json: |
    {
        "endPointUrl": "/gate/",
        "setApplicationInterval": 300000,
        "triggerPipeline": false
    }
  help-text.json: "{\n  \"POLICY_LISTING\": {\n    \"HEADER\": \"Policies not found!\",\n
    \   \"BODY\": \"<div><p>Policy Management feature allows you to create policies
    to set guardrails for safe and fine grained controls in CI/CD pipelines.</p> <p>Static
    Policy lets users validate the conditions when creating a pipeline, whereas Runtime
    Policy enables users for automated decision making during pipeline execution.</p>
    <p>A policy defines a set of conditions that must be met.</p> <p>As an example,
    a policy could be created to define a blackout window period (or a moratorium period)
    for performing production deployments. A moratorium period defines the time period
    within which no production deployments should be performed. Any deployment to the
    production environment during this period will automatically be rejected/stopped.</p>
    <p>ISD uses Open Policy Engine(OPA) for policy definition & execution. OPA is a
    open source, general-purpose policy engine that unifies policy enforcement across
    the stack. It uses a high-level declarative language called Rego that lets you specify
    policy as code.</p> <p>Click on <b>New Policy</b> button to create a new policy.</p></div>\"\n
    \ },\n  \"AGENT_LISTING\": {\n    \"HEADER\": \"No Agents found!\",\n    \"BODY\":
    \"<div><p>The Agent allows ISD to reach through firewalls in a secure manner, allowing
    access to private Kubernetes clusters as well as reach internal services such as
    Jenkins and Artifactory. The agent is typically used with OpsMx's SaaS ISD offering,
    where OpsMx hosts the ISD Platform, but services used by the platform are within
    a secure area owned by the customer. One of the core advantages of using an agent
    is that the credentials do not need to be disclosed to anyone i.e. credentials remain
    with-in the cluster where deployment is done.</p> <p>The Agent is a two part system:
    a <b>Controller</b> runs near ISD, and the <b>Agent</b> runs in the target secure
    cluster. The Agent is configured to communicate with specific services (Kubernetes,
    Jenkins etc) within a customer's security domain, while the Controller is in ISD's
    domain.</p> <p>The Agent is deployed using a manifest generated by ISD. This manifest
    has per-installation credentials to authenticate to the controller, controller address
    etc. Services are configured in the Agent by the customer. URL endpoints, CD account
    names and credentials are provided to the agent using a service configuration. The
    credentials never leave the agent's security domain.</p> <p>Click on <b>New Agent</b>
    to create the Agent for your environment. This button is enabled when CD Instance
    is configured in <b>Setup->CD Integration</b>.\"\n  },\n  \"AGENT_CREATION\": {\n
    \   \"HEADER\": \"Agent\",\n    \"BODY\": \"<div><p>Adding an agent involves the
    following steps:</p><ul class='helpTextUI'><li>Enter the details (name, cluster
    and description) and click save</li> <li>Click <b>Download Manifest</b> which appears
    after save</li><li>In the remote Kubernetes cluster, create service configmap in
    the default namespace. Examples are available here: https://github.com/OpsMx/standard-gitops-repo/tree/master/SAMPLES/agent-config</li>
    <li>Apply the downloaded manifest in the default namespace using <b>kubectl apply
    -f <downloaded file></b> ; Note that the agent should be able to reach the Load
    Balancer configured for the agent-grpc service,</li><li>Check the Setup->Agents
    screen for the agent connection status</li></ul></div>\",\n    \"AGENT_NAME\": {\n
    \     \"TOOLTIP\": \"Name of the agent with which it will referred to\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Agent Name cannot be empty\",\n        \"cannotContainSpace\":
    \"Agent Name cannot contain space\",\n        \"noSpecialCharacters\": \"Allowed
    special character is '-'\",\n        \"startingFromNumber\": \"Agent Name should
    not start with number\",\n        \"agentNameExist\": \"Agent Name already exists\"\n
    \     }\n    },\n    \"CLUSTER_NAME\": {\n      \"TOOLTIP\": \"Name of the remote
    cluster on which agent will be installed on\",\n      \"VALIDATION_MESSAGE\": {\n
    \       \"required\": \"Cluster Name cannot be empty\",\n        \"cannotContainSpace\":
    \"Cluster Name cannot contain space\",\n        \"noSpecialCharacters\": \"Allowed
    special character is '-'\",\n        \"startingFromNumber\": \"Cluster Name should
    not start with number\"\n      }\n    },\n    \"DESCRIPTION\": {\n      \"TOOLTIP\":
    \"Short description about the agent\",\n      \"VALIDATION_MESSAGE\": {}\n    },\n
    \   \"CONNECT_TO_SPINNAKER\": {\n      \"TOOLTIP\": \"The spinnaker instance you
    want to associate this account to\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Please select Spinnaker\"\n      }\n    }\n  },\n  \"CLOUDPROVIDER_LISTING\":
    {\n  \"HEADER\": \"No Cloud Targets found!\",\n  \"BODY\": \"<div><p>Cloud Targets
    are integrations to Cloud platforms you deploy your applications to.</p> <p>In this
    section, you’ll register credentials for your Cloud platforms. Those credentials
    are known as Accounts. ISD allows you to create & manage Accounts for different
    Cloud Providers such as AWS, GCP, Kubernetes, etc.</p> <p>When CD instance (Spinnaker)
    is configured for <b>Direct Sync</b>, <b>New Accounts</b> button will not be visible.</p>
    <p><b>New Accounts</b> button will be enabled when CD instance (Spinnaker) is configured
    to use External Accounts in <b>Setup->CD Integration</b>.Click on <b>New Accounts</b>
    button to create an account for your cloud provider. You can create multiple accounts
    for the same provider.</p> <p>Click on <b>Sync Accounts</b> button to sync Cloud
    target accounts with CD Tool</p></div>\"\n   },\n    \"CLOUDPROVIDER_CREATION\":
    {\n      \"HEADER\": \"Cloud Target\",\n      \"BODY\": \"<p>In this page, you can
    create & manage Cloud Target Accounts</p>\",\n      \"AGENT_NAME\": {\n        \"TOOLTIP\":
    \"\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\": \"Agent name cannot
    be empty\",\n          \"cannotContainSpace\": \"Agent name cannot contain space\",\n
    \         \"noSpecialCharacters\": \"Allowed special character are ',-'\"\n        }\n
    \     },\n      \"CLOUD_PROVIDER\": {\n        \"TOOLTIP\": \"The Cloud Target type
    for which you want to add the account\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Please select Cloud Target\"\n        }\n      },\n      \"SPINNAKER\": {\n        \"TOOLTIP\":
    \"The Spinnaker instance with which this account would be tied to\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Please select Spinnaker\"\n        }\n      },\n      \"ENVIRONMENT\":
    {\n        \"TOOLTIP\": \"The environment name for the account. Many accounts can
    share the same environment (e.g. dev, test, prod)\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Please select Environment\"\n        }\n      },\n
    \     \"CUSTOM_ENVIRONMENT\": {\n        \"TOOLTIP\": \"\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"noSpecialCharacters\": \"Environment Name cannot contain special
    characters\",\n          \"cannotContainSpace\": \"Environment Name cannot contain
    space\",\n          \"required\": \"Environment Name cannot be empty\",\n          \"startingFromNumber\":
    \"Environment Name cannot start with number\",\n          \"maxlength\": \"Environment
    name should not have more than 63 characters!\",\n          \"exists\": \"Environment
    name already exists\"\n        }\n      },\n      \"ACCOUNT_NAME\": {\n        \"TOOLTIP\":
    \"Name of the account to operate on\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Account name cannot be empty\",\n          \"cannotContainSpace\": \"Account name
    cannot contain space\",\n          \"noSpecialCharacters\": \"Allowed special character
    is '-'\"\n        }\n      },\n      \"NAMESPACE\": {\n        \"TOOLTIP\": \"A
    list of namespaces this Spinnaker account can deploy to and will cache (namespaces
    should be 'coma' separated ex: default,dev\",\n        \"VALIDATION_MESSAGE\": {\n
    \         \"required\": \"Namespace cannot be empty\",\n          \"cannotContainSpace\":
    \"Namespace cannot contain space\",\n          \"noSpecialCharacters\": \"Special
    characters not allowed except ',-'\"\n        }\n      },\n      \"UPLOAD_KUBECONFIG_FILE\":
    {\n        \"TOOLTIP\": \"The path to your kubeconfig file. By default, it will
    be under the Spinnaker user’s home directory in the typical .kube/config location.\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"File cannot be empty\"\n
    \       }\n      },\n      \"READ\": {\n        \"TOOLTIP\": \"A user must have
    at least one of these roles in order to view this account’s cloud resources.\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"cannotContainSpace\": \"Read Permissions
    cannot contain space\"\n        }\n      },\n      \"WRITE\": {\n        \"TOOLTIP\":
    \"A user must have at least one of these roles in order to make changes to this
    account’s cloud resources\",\n        \"VALIDATION_MESSAGE\": {\n          \"cannotContainSpace\":
    \"Write Permissions cannot contain space\"\n        }\n      },\n      \"EXECUTE\":
    {\n        \"TOOLTIP\": \"\",\n        \"VALIDATION_MESSAGE\": {\n          \"cannotContainSpace\":
    \"Execute Permissions cannot contain space\"\n        }\n      },\n      \"ACCOUNT_ID\":
    {\n        \"TOOLTIP\": \"Your AWS account ID to manage. Refer http://docs.aws.amazon.com/IAM/latest/UserGuide/console_account-alias.html
    for more information\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Account Id cannot be empty\",\n          \"cannotContainSpace\": \"Account Id
    cannot contain space\"\n        }\n      },\n      \"ROLE\": {\n        \"TOOLTIP\":
    \"If set, Halyard will configure a credentials provider that uses AWS Security Token
    Service to assume the specified role\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Role cannot be empty\",\n          \"cannotContainSpace\": \"Role cannot contain
    space\"\n        }\n      },\n      \"REGIONS\": {\n        \"TOOLTIP\": \"The AWS
    regions this Spinnaker account will manage\",\n        \"VALIDATION_MESSAGE\": {\n
    \         \"required\": \"Region cannot be empty\",\n          \"cannotContainSpace\":
    \"Region cannot contain space\"\n        }\n      },\n      \"PRIMARY_ACCOUNT\":
    {\n        \"TOOLTIP\": \"Whether this account is the primary account? If yes then
    provide the access & secret key details.\",\n        \"VALIDATION_MESSAGE\": {}\n
    \     },\n      \"ACCESS_KEY\": {\n        \"TOOLTIP\": \"The default access key
    used to communicate with AWS\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Access key cannot be empty\"\n        }\n      },\n      \"ACCESS_KEY_BAKERY\":
    {\n        \"TOOLTIP\": \"The default access key used for AWS bakery configuration\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"Access Key (Bakery)
    cannot be empty\"\n        }\n      },\n      \"SECRET_KEY\": {\n        \"TOOLTIP\":
    \"The secret key used to communicate with AWS\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Secret key cannot be empty\"\n        }\n      },\n
    \     \"SECRET_KEY_BAKERY\": {\n        \"TOOLTIP\": \"The default secret key used
    for AWS baskery configuration\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Secret Key (Bakery) cannot be empty\"\n        }\n      },\n      \"APP_KEY\":
    {\n        \"TOOLTIP\": \"The appKey (password) of your service principal\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"App key cannot be empty\",\n          \"cannotContainSpace\":
    \"App key cannot contain space\"\n        }\n      },\n      \"CLIENT_ID\": {\n
    \       \"TOOLTIP\": \"The clientId (also called appId) of your service principal\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"Client Id cannot be
    empty\",\n          \"cannotContainSpace\": \"Client Id cannot contain space\"\n
    \       }\n      },\n      \"DEFAULT_KEYVALUT\": {\n        \"TOOLTIP\": \"The name
    of a KeyVault that contains the user name, password, and ssh public key used to
    create VMs\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\": \"Default
    Keyvault cannot be empty\",\n          \"cannotContainSpace\": \"Default Keyvault
    cannot contain space\"\n        }\n      },\n      \"SUBSCRIPTION_ID\": {\n        \"TOOLTIP\":
    \"The subscriptionId that your service principal is assigned to\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Subscription Id cannot be empty\",\n          \"cannotContainSpace\":
    \"Subscription Id cannot contain space\"\n        }\n      },\n      \"TENANT_ID\":
    {\n        \"TOOLTIP\": \"The tenantId that your service principal is assigned to\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"Tenant Id cannot be
    empty\",\n          \"cannotContainSpace\": \"Tenant Id cannot contain space\"\n
    \       }\n      },\n      \"GCP_FILE\": {\n        \"TOOLTIP\": \"The path to a
    JSON service account that Spinnaker will use as credentials. This is only needed
    if Spinnaker is not deployed on a Google Compute Engine VM, or needs permissions
    not afforded to the VM it is running on. Refer https://cloud.google.com/compute/docs/access/service-accounts
    for more information\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"File cannot be empty\"\n        }\n      },\n      \"AWS_ACCOUNT_NAME\": {\n        \"TOOLTIP\":
    \"\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\": \"Please Select
    AWS Account\"\n        }\n      }\n    },\n  \"SPINNAKER_LISTING\": {\n    \"HEADER\":
    \"No Spinnaker Configured!\",\n    \"BODY\": \"<div><p>CD Integration page allows
    you to connect to a CD instance. This enables ML based verification, Policy enforcement,
    Informed Approvals, etc.</p><p>Click on the <b>New CD Integration</b> button to
    connect to a CD instance. Only one instance is supported.</p></div>\"\n  },\n  \"SPINNAKER_SETUP\":
    {\n    \"HEADER\": \"Spinnaker\",\n    \"BODY\": \"<p>In this page you can add /
    update information about your CD instance.</p> <p><strong>Fields:</strong></p> <ul
    class='helpTextUI'> <li><strong>CD Name</strong>: User defined name for CD instance.<br><span>
    Example: opsmx-spinnaker</span></li> <li><strong>CD URL</strong>: Gate URL of the
    CD instance.<br> <span>Example: https://spinnaker-gate.xyz.com or http://oes-gate:8084</span></li>
    <li><strong>Authentication Type:</strong>: Can be LDAP or X509; for AD, use LDAP</li>
    <li><strong>Token: </strong> This is used when Authentication Type is LDAP; username
    & password to LDAP server separated by <b>:</b> in base64 format; Output of 'echo
    -ne 'username:password' | base64 -w0'</li> <li><strong>Password: </strong>This is
    used when Authentication Type is X509; Password for P12 File</li> <li><strong>P12
    File:</strong> This is used when Authentication Type is X509; P12 File needed for
    X509 Authentication</li></ul><p>GitOps style Spinnaker is suported where in all
    configuration is maintained in a repository such as git. These optional sections
    help configure gitOps style Spinnaker:</p><ul class='helpTextUI'><li><strong>Source
    Control for Accounts: </strong>You can specify the repository for External configuration
    in Spinnaker</li> <li><strong>Source Control for Pipeline: </strong>You can specify
    the repository for pipeline gitOps that allows you to save and restore pipelines
    from a git repository</li></ul>\",\n    \"SPINNAKER_NAME\": {\n      \"TOOLTIP\":
    \"Name of the Spinnaker instance\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"CD Name cannot be empty\",\n        \"cannotContainSpace\": \"CD Name cannot contain
    space\",\n        \"noSpecialCharacters\": \"Allowed special character is '-'\",\n
    \       \"startingFromNumber\": \"CD Name should not start with number\"\n      }\n
    \   },\n    \"SPINNAKER_GATE_URL\": {\n      \"TOOLTIP\": \"Gate Url of the Spinnaker
    instance\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"CD Gate URL
    cannot be empty\",\n        \"cannotContainSpace\": \"CD Gate URL cannot contain
    space\",\n        \"invalidUrl\": \"CD Gate URL is invalid\"\n      }\n    },\n
    \   \"AUTHENTICATION_TYPE\": {\n      \"TOOLTIP\": \"Select the type of authentication
    for the spinnaker being added\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Please select Authentication Type\"\n      }\n    },\n    \"LDAP_USERNAME\": {\n
    \     \"TOOLTIP\": \"User Name\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"User Name cannot be empty\",\n        \"minlength\": \"User Name should be more
    than 4 characters\"\n      }\n    },\n    \"LDAP_PASSWORD\": {\n      \"TOOLTIP\":
    \"Password\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Password
    cannot be empty\",\n        \"minlength\": \"Password should be more than 8 characters\"\n
    \     }\n    },\n    \"TOKEN\": {\n      \"TOOLTIP\": \"Token for Spinnaker authentication\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Token cannot be empty\",\n
    \       \"minlength\": \"Token should be more than 8 characters\"\n      }\n    },\n
    \   \"PASSWORD\": {\n      \"TOOLTIP\": \"Password\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Password cannot be empty\",\n        \"minlength\": \"Password
    should be more than 8 characters\"\n      }\n    },\n    \"P12_FILE\": {\n      \"TOOLTIP\":
    \"P12 File\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"P12 File
    cannot be empty\"\n      }\n    },\n    \"SYNC_ACCOUNTS\": {\n      \"TOOLTIP\":
    \"Select Mode of synchronisation of Cloud Targets between Autopilot & Spinnaker\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Please select Sync Accounts
    type\"\n      }\n    },\n    \"ACCOUNTS_PROVIDER\": {\n      \"TOOLTIP\": \"Source
    Control for Halyard Configuration and / or External Account Configuration\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Please select provider\"\n      }\n    },\n    \"ACCOUNTS_ACCOUNT_NAME\":
    {\n      \"TOOLTIP\": \"Account name of the Source Control\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Please select Account Name\"\n      }\n    },\n    \"ACCOUNTS_REPOSITORY\":
    {\n      \"TOOLTIP\": \"Repository name with full path in the selected Source Control
    Eg., https://github.com/OpsMx/Opsmx-Saas.git\",\n      \"VALIDATION_MESSAGE\": {\n
    \       \"required\": \"Repository cannot be empty\",\n        \"cannotContainSpace\":
    \"Repository cannot contain space\",\n        \"invalidUrl\": \"Repository is invalid\"\n
    \     }\n    },\n    \"ACCOUNTS_SOURCE_PATH\": {\n      \"TOOLTIP\": \"Existing
    path in the repository\",\n      \"VALIDATION_MESSAGE\": {}\n    },\n    \"ACCOUNTS_REGION\":
    {\n      \"TOOLTIP\": \"The AWS regions this Spinnaker account will manage\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Region cannot be empty\",\n
    \       \"cannotContainSpace\": \"Region cannot contain space\",\n        \"startingFromNumber\":
    \"Region should not start with number\"\n      }\n    },\n    \"ACCOUNTS_BUCKET_NAME\":
    {\n      \"TOOLTIP\": \"Bucket Name\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Bucket Name cannot be empty\",\n        \"cannotContainSpace\": \"Bucket Name
    cannot contain space\",\n        \"startingFromNumber\": \"Bucket Name should not
    start with number\"\n      }\n    },\n    \"PIPELINE_PROVIDER\": {\n      \"TOOLTIP\":
    \"Use this Spinnaker for pipeline promotion.\",\n      \"VALIDATION_MESSAGE\": {\n
    \       \"required\": \"Please select provider\"\n      }\n    },\n    \"PIPELINE_ACCOUNT_NAME\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Please select Account Name\"\n      }\n    },\n    \"PIPELINE_REPOSITORY\": {\n
    \     \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Repository cannot be empty\",\n        \"cannotContainSpace\": \"Repository cannot
    contain space\",\n        \"invalidUrl\": \"Repository is invalid\"\n      }\n    },\n
    \   \"PIPELINE_SOURCE_PATH\": {\n      \"TOOLTIP\": \"Existing path in the repository\",\n
    \     \"VALIDATION_MESSAGE\": {}\n    },\n    \"PIPELINE_REGION\": {\n      \"TOOLTIP\":
    \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Region cannot be
    empty\",\n        \"cannotContainSpace\": \"Region cannot contain space\",\n        \"startingFromNumber\":
    \"Region should not start with number\"\n      }\n    },\n    \"PIPELINE_BUCKET_NAME\":
    {\n      \"TOOLTIP\": \"Bucket Name\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Bucket Name cannot be empty\",\n        \"cannotContainSpace\": \"Bucket Name
    cannot contain space\",\n        \"startingFromNumber\": \"Bucket Name should not
    start with number\"\n      }\n    }\n  },\n  \"INTEGRATOR_LISTING\": {\n    \"HEADER\":
    \"No Integrator found!\",\n    \"BODY\": \"<div><p>ISD offers integration with many
    CI/CD Tools. Integrations are grouped under the following categories - Artifact,
    CI, Governance, Monitoring Tools, Notifications, Policy and SAST/DAST.</p> <p>Integrations
    are used to</p> <ul><li>pull logs & metrics for Continuous Verification</li><li>pull
    meta data from CI/CD Tools for Informed Approvals</li><li>enforce organizational
    policies at the time of creation or execution of a pipeline</li><li>configure Artifacts,
    Cloud Providers etc.</li><p>Click on the <b<New Integration</b> button to start
    integrating your tools </p></div>\",\n    \"SYNC_SPINNAKER_ACCOUNTS\": {\n      \"TOOLTIP\":
    \"Push Integration changes to Spinnaker\",\n      \"VALIDATION_MESSAGE\": \"\"\n
    \   }\n  },\n  \"PIPELINE_EXECUTION_AUDIT_LISTING\": {\n    \"HEADER\": \"Pipeline
    executions not found!\",\n    \"BODY\": \"<div>This page shows pipeline executions
    coming from a CD Tool such as Spinnaker in a list view. It also contains the summary
    view showing the total number of Pipeline Runs, Successful Runs, Failed Runs, Cancelled
    Runs.</p> <p> Only important fields including Application, Service, Pipeline, Status,
    Start Time and End Time are shown by default. Additional fields can be enabled using
    the Hamburger menu towards the right corner.</p></div>\",\n    \"TOOLTIP\": {\n
    \     \"EXECUTION_DATA\": \"Pipeline is in Running State\",\n      \"CONNECTOR_DATA\":
    \"Pipeline is in Running State\",\n      \"STAGE_DURATION\": \"Pipeline is in Running
    State\"\n    },\n    \"VALIDATION_MESSAGE\": {\n      \"STAGE_DURATION\": \"No Data
    available to view Stage Duration\",\n      \"PIPELINE_NOT_EXISTS\" : \"Execution
    details not found.\"\n    }\n  },\n  \"PIPELINE_AUDIT_LISTING\": {\n    \"HEADER\":
    \"Pipeline updates not found!\",\n    \"BODY\": \"<div>This page shows pipeline
    updates coming from a CD Tool such as Spinnaker in a list view.</div>\"\n  },\n
    \ \"POLICY_AUDIT_LISTING\": {\n    \"HEADER\": \"Policy updates / executions not
    found!\",\n    \"BODY\": \"<div><p>This page shows policy updates and policy executions,
    along with allowed/denied information, in a list view. Possible uses, apart from
    audit and compliance, includes helping users understand the policies that they might
    be inadvertently trying to break.</p><p>For policy updates, ensure that a policy
    is created/updated under <strong><a routerLink='/policymanagement'>Setup -> Policies</a></strong>.
    For policy execution events, please add a policy stage in a pipeline and execute
    it.</div>\"\n  },\n  \"POLICY_CREATION\": {\n    \"HEADER\": \"Policy\",\n    \"BODY\":
    \"<p>In this page, you can define & manage policies.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li> <strong>Name:</strong> User defined name for the policy</li><li><strong>Policy
    Type:</strong> Static Policy lets users validate the conditions when creating a
    pipeline, whereas Runtime Policy enables users for automated decision making during
    pipeline execution.</li><li> <strong>Policy Engine:</strong> Policy Engine to be
    used; currently, only OPA is supported</li> <li><strong>Policy Engine Account:</strong>
    Policy Engine Account for the Credentials. You can manage accounts from Setup ->
    Integrations -> Policy </li> <li><strong>Policy File:</strong> File containing the
    Policy You can upload the file by clicking on <strong>Choose File</strong> button.
    This is optional. If not present, you can enter the policy directly in the <strong>Policy
    Details</strong> field</li><li> <strong>Policy Details:</strong> Policy definition</li>
    <li><strong>Policy Permissions:</strong>Enable/disable access to the policy in Autopilot
    to specific usergroups</li></ul>\",\n    \"NAME\": {\n      \"TOOLTIP\": \"Policy
    Name\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Name cannot be
    empty\",\n        \"cannotContainSpace\": \"Name cannot contain space\",\n        \"exists\":
    \"Name already exists\"\n      }\n    },\n    \"POLICY_DETAILS\": {\n      \"TOOLTIP\":
    \"Define your policy using the rego language\",\n      \"VALIDATION_MESSAGE\": {\n
    \       \"required\": \"Policy Details cannot be empty\"\n      }\n    },\n    \"POLICY_ENGINE\":
    {\n      \"TOOLTIP\": \"Supported Policy Account Types\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Please select Policy Account Type\"\n      }\n    },\n
    \   \"POLICY_ENGINE_ACCOUNT\": {\n      \"TOOLTIP\": \"Policy Account Names\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Please select Policy Engine
    Account\"\n      }\n    },\n    \"POLICY_TYPE\": {\n      \"TOOLTIP\": \"A static
    policy lets users validate conditions before the start of execution, whereas a Runtime
    policy enables users for automated decision making during execution.\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Please select Policy Engine Type\"\n      }\n    },\n
    \   \"POLICY_DESCRIPTION\": {\n      \"TOOLTIP\": \"Optional Description for the
    policy\"\n    },\n    \"POLICY_FILE\": {\n      \"TOOLTIP\": \"File containing the
    Policy. You can upload the file by clicking on 'Choose File' button. This is optional.
    If not present, you can enter the policy directly in the 'Policy Details' field\"\n
    \   }\n  },\n  \"VERIFICATION\": {\n    \"HEADER\": \"Verification Gate executions
    not found!\",\n    \"BODY\": \"<div><p>This page shows Verification Gate executions
    in a list view.</p> <p>The Continuous Verification performs automated log and metrics
    analysis for new releases with built-in unsupervised and supervised machine learning
    algorithms for risk analysis and canary deployments.</p><p>Continuous Verification
    is a release verification process that provides Dev and Ops engineers an intelligent
    automated real-time actionable risk assessment of a new release deployed. The Continuous
    Verification verifies the latest version of the service comparing to the baseline
    or prior release after production rollout. The baseline can be a deployment done
    prior or the current deployment during rollout using canary or blue/green or rolling
    update strategies.</p> <p>It leverages unsupervised and supervised machine learning
    techniques to analyze 100s of metrics and logs data to perform in-depth analysis
    of architectural regressions, performance, scalability and security violations of
    new releases in a scalable way for enterprises.</p> <p>ISD provides a Verification
    Gate to analyze logs from your Target Application and this can be inserted as a
    Stage in your CI/CD Pipeline. Note that one must configure the metric and log datasources,
    such as Prometheus and Elastic before using this functionality.</p> <p>Insert Verification
    Gate to a pipeline in your application using <b>Pipeline Builder -> Add Stage</b>.
    When the pipeline is run, the Gate executions will start appearing in this page.</p></div>\",\n
    \   \"LOG_ANALYSIS\": {\n      \"BODY\": \"\",\n      \"SENSITIVITY\": {\n        \"TOOLTIP\":
    \"Impact of Unexpected Issues on the log scoring\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"PERCEIVED_RISK\": {\n        \"TOOLTIP\": \"The overall risk
    associated with changes made in this verification run\",\n        \"VALIDATION_MESSAGE\":
    {}\n      }\n    },\n    \"ANALYSIS_SUMMARY\": {\n      \"LOG_TEMPLATE\": {\n        \"TOOLTIP\":
    \"Log template for the verification run\",\n        \"VALIDATION_MESSAGE\": {}\n
    \     },\n      \"METRIC_TEMPLATE\": {\n        \"TOOLTIP\": \"Metric template for
    the verification run\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"LOG_BASELINE_START_TIME\":
    {\n        \"TOOLTIP\": \"Start time of the canary analysis for Baseline\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"LOG_BASELINE_END_TIME\": {\n        \"TOOLTIP\": \"End  time
    of the canary analysis for Baseline\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"LOG_NEW_RELEASE_START_TIME\": {\n        \"TOOLTIP\": \"Start time of the
    canary analysis for New Release\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"LOG_NEW_RELEASE_END_TIME\": {\n        \"TOOLTIP\": \"End  time of the canary
    analysis for New Release\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"ANALYSIS_TYPE\":
    {\n        \"TOOLTIP\": \"The type of verification analysis done, can be metric,
    log or both metric and log analysis\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"LOG_STATUS\": {\n        \"TOOLTIP\": \"The current status of the log analysis\",\n
    \       \"VALIDATION_MESSAGE\": {}\n      },\n      \"LOG_SCORE\": {\n        \"TOOLTIP\":
    \"The overall score of the current log analysis report\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"METRIC_STATUS\": {\n        \"TOOLTIP\": \"The current status
    of the metric analysis\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"METRIC_SCORE\":
    {\n        \"TOOLTIP\": \"The overall score of the current metric analysis report\",\n
    \       \"VALIDATION_MESSAGE\": {}\n      },\n      \"BASELINE_SIZE\": {\n        \"TOOLTIP\":
    \"The size of the file with the Baseline logs\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"NEW_RELEASE_SIZE\": {\n        \"TOOLTIP\": \"The size of
    the file with the New Release logs\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"BASELINE_LINES\": {\n        \"TOOLTIP\": \"The number of log lines for
    the Baseline\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"NEW_RELEASE_LINES\":
    {\n        \"TOOLTIP\": \"The number of log lines for the New Release\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"ANALYSIS_DURATION\": {\n        \"TOOLTIP\": \"The time taken
    to perform the current verification run\",\n        \"VALIDATION_MESSAGE\": {}\n
    \     },\n      \"LIFETIME_HOURS\": {\n        \"TOOLTIP\": \"The duration for which
    the canary analysis was performed, 1 lifetime hour is equal to 1 hour.\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"RECLASSIFICATION_DURATION\": {\n        \"TOOLTIP\": \"The
    time taken to perform reclassification\",\n        \"VALIDATION_MESSAGE\": {}\n
    \     },\n      \"INTERVAL_MINUTES\": {\n        \"TOOLTIP\": \"The Lifetime hours
    in minutes\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"REGULAR_EXPRESSION\":
    {\n        \"TOOLTIP\": \"A sequence of characters to specify the search pattern\",\n
    \       \"VALIDATION_MESSAGE\": {}\n      },\n      \"RESPONSE_KEY\": {\n        \"TOOLTIP\":
    \"Field name in the index where the regular expression is to be searched\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"SCORING_ALGORITHM\": {\n        \"TOOLTIP\": \"Scoring Algorithm
    for the risk analysis\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"BASELINE_LOGS\":
    {\n        \"TOOLTIP\": \"View the Baseline logs\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"NEW_RELEASE_LOGS\": {\n        \"TOOLTIP\": \"View the New
    Release logs\",\n        \"VALIDATION_MESSAGE\": {}\n      }\n    },\n    \"METRIC_ANALYSIS\":
    {\n      \"BODY\": \"\"\n    },\n    \"CORRELATION\": {\n      \"BODY\": \"\"\n
    \   }\n  },\n  \"MANUAL_TRIGGER\": {\n    \"BODY\": \"<p>Continuous Verification
    is a REST service that can be deployed on premise or use managed cloud service for
    analysis. Continuous Verification interfaces with monitoring systems for logs and
    metrics and uses the metadata provided in start analysis phase to retrieve the logs
    and metrics for deployment verification. Continuous Verification does not interface
    with the services deployed directly for its analysis.            Deployment Pipeline
    can be based on Spinnaker or Jenkins for Enterprise Continuous Delivery. Verification
    can also be triggered manually by providing the required parameters in this dialog
    box.</p>\",\n    \"APPLICATION\": {\n      \"TOOLTIP\": \"Name of the application\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"BASELINE_START_TIME\": {\n      \"TOOLTIP\":
    \"Time to enable warming up of the container\",\n      \"VALIDATION_MESSAGE\": \"\"\n
    \   },\n    \"NEW_RELEASE_START_TIME\": {\n      \"TOOLTIP\": \"Intervals in which
    metric-data is fetched and analysed\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n
    \   \"SUCCESSFUL_SCORE\": {\n      \"TOOLTIP\": \"The score under which the Analysis
    should fail\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"UNHEALTHY_SCORE\":
    {\n      \"TOOLTIP\": \"The score above which the Analysis should be a pass\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"ANALYSIS_LIFETIME\": {\n      \"TOOLTIP\":
    \"The time in hours for which the Canary Analysis should be run\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"RUN_INFO\": {\n      \"TOOLTIP\": {\n        \"Build Info\":
    \"http://jenkins.opsmx.net:8181/jenkins/job/Dev-visibilityservice-build-branch/770/\",\n
    \       \"Code Repository\": \"https://github.com/OpsMx/visibility-service\",\n
    \       \"Version\": \"v1.09\"\n      },\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n
    \   \"SERVICE\": {\n      \"TOOLTIP\": \"Service\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"TEMPLATE_NAME\": {\n      \"TOOLTIP\": \"Template Name\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"GATE\": {\n      \"TOOLTIP\":
    \"Gate\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"FILTER_KEY\": {\n      \"TOOLTIP\":
    \"Filter Key\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"BASELINE\": {\n
    \     \"TOOLTIP\": \"Baseline\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"NEW_RELEASE\":
    {\n      \"TOOLTIP\": \"New Release\",\n      \"VALIDATION_MESSAGE\": \"\"\n    }\n
    \ },\n  \"TEST_VERIFICATON\": {\n    \"HEADER\": \"Test Verification Gate executions
    not found!\",\n    \"BODY\": \"<div> <p>The Continuous Verification performs automated
    log and metric analysis for new releases with built-in unsupervised and supervised
    machine learning algorithms for risk analysis. Autopilot provides a Test Verification
    Gate to analyse logs from your Test Harness and this can be inserted as a Stage
    in your CI/CD Pipeline. </p>     <p>This page shows Test Verification Gate executions
    in a list view. </p> <p>Insert Test Verification Gate to a pipeline in your application
    using <a [routerLink]='['/setup/applications']'><strong>Setup -> Applications</strong></a>.When
    the pipeline is run, the Gate executions will start appearing in this page.</p>
    </div>\"\n  },\n  \"TEST_CASE\": {\n    \"HEADER\": \"Test Cases not found!\",\n
    \   \"BODY\": \"<div> <p>The Continuous Verification performs automated log and
    metric analysis for new releases with built-in unsupervised and supervised machine
    learning algorithms for risk analysis. Autopilot provides a Test Verification Gate
    to analyse logs from your Test Harness and this can be inserted as a Stage in your
    CI/CD Pipeline. </p>     <p>This page shows Test Cases in a list view. </p> <p>Insert
    Test Verification Gate to a pipeline in your application using <a [routerLink]='['/setup/applications']'><strong>Setup
    -> Applications</strong></a>.When the pipeline is run, the Gate executions will
    start appearing in this page.</p> </div>\"\n  },\n  \"VISIBILITY_LISTING\": {\n
    \   \"HEADER\": \" <div><span style='font-size: 16px; font-weight: bold;'>Approval
    Gate executions not found!</span></div>\",\n    \"BODY\": \"<div><p>This page shows
    Approval Gate executions in a list view.</p> <p>ISD provides <b>approval</b> mechanism
    for deployments. To make an informed decision regarding pipeline execution, an approver
    may need to check the data from multiple data sources, such as CI Systems, Repositories,
    SAST/DAST Tools etc. ISD provides Approval Gate feature which fetches relevant information
    from multiple CI/CD Tools and presents the data in one place, to enable the user
    to make an quick and informed decision on pipeline execution. This Gate can be inserted
    as a Stage in your CI/CD Pipeline.</p> <p>Note that appropriate data sources must
    be configured in the <b>Setup -> Integration</b> view before Approval stage can
    be used.</p> <p>Insert Approval Gate to a pipeline in your application using <b>Pipeline
    Builder -> Add Stage</b>. When the pipeline is run, the Gate executions will start
    appearing in this page.</p></div>\"\n  },\n  \"VISIBILITY_DETAILS\": {\n    \"APPLICATION_NAME\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"SERVICE_NAME\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"APPROVAL_BTN_TITLE\":
    {\n      \"TOOLTIP\": \"Insufficient Permission to execute\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"GATE_NAME\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"STATUS\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"COMMENT\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"TRIGGER_URL\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"APPROVAL_GROUP\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"CONNECTORS\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"ACTIVATED_TIME\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"REVIEWED_AT\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"REVIEWER\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"COMMENTS\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    }\n  },\n  \"FORM_GRID\": {\n    \"ADD_NEW_ROW\": {\n      \"TOOLTIP\":
    \"Add New Row\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"DELETE_ROW\":
    {\n      \"TOOLTIP\": \"Delete row\",\n      \"VALIDATION_MESSAGE\": \"\"\n    }\n
    \ },\n  \"APPLICATION_DASHBOARD\": {\n    \"VERIFICATION_FAILURES\": {\n      \"TOOLTIP\":
    \"Total number of Verification Failures including Test Verification Failures\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    }\n  },\n  \"APPLICATION_LISTING\": {\n
    \   \"HEADER\": \"No applications were found to match your filter!\",\n    \"BODY\":
    \"\",\n    \"PLACEHOLDER\": \"You don't have access to this Page. Please contact
    your Administrator\",\n    \"SYNC_SPINNAKER\": {\n      \"TOOLTIP\": \"To be able
    to work on applications created in Spinnaker, you need to import them here\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"SYNC_SPINNAKER_NOT_CONFIGURED\":
    {\n      \"TOOLTIP\": \"Configure Spinnaker to Sync Spinnaker Applications from
    here\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"SYNC_SPINNAKER_ERROR\":
    {\n      \"TOOLTIP\": \"Could not fetch Spinnaker Details. Please contact Administrator\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"DISABLE_CREATE_APPLICATION_BTN\":
    {\n      \"TOOLTIP\": \"You do not have permission to create Application\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    }\n  },\n  \"START_DEPLOYMENT\": {\n    \"APPLICATION_NAME\": {\n      \"TOOLTIP\":
    \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Application Name
    is required\",\n        \"empty\": \"Please create Spinnaker Application to continue\"\n
    \     }\n    },\n    \"SERVICE_NAME\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Service Name is required\",\n        \"empty\": \"Pipelines
    are not present for this Application\"\n      }\n    },\n    \"START_DEPLOYMENT_BTN\":
    {\n      \"TOOLTIP\": \"Please create Spinnaker Application to 'Start New Deployment'\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Service Name is required\"\n
    \     }\n    }\n  },\n  \"APPLICATION_DETAILS\": {\n    \"HEADER\": \"Application
    Details\",\n    \"BODY\": \"<ul class='helpTextUI'><li><strong>Application Name</strong>:
    User defined name of the application</li> <li><strong>Description</strong>: Application
    description</li> <li><strong>Email ID</strong>: Your email id</li></ul>\",\n    \"APPLICATION_NAME\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"exists\":
    \"Application already exists\",\n        \"noSpecialCharacters\": \"Application
    Name cannot contain special characters\",\n        \"cannotContainSpace\": \"Application
    Name cannot contain space\",\n        \"required\": \"Application Name cannot be
    empty\",\n        \"startingFromNumber\": \"Application Name cannot start with numbers\",\n
    \       \"maxlength\": \"Application name should not have more than 63 characters!\"\n
    \     }\n    },\n    \"APPLICATION_DESCRIPTION\": {\n      \"TOOLTIP\": \"\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"EMAIL_ID\": {\n      \"TOOLTIP\":
    \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"email\": \"Email Id is invalid\",\n
    \       \"required\": \"Email Id cannot be empty\"\n      }\n    }\n  },\n  \"SERVICE_DETAILS\":
    {\n    \"HEADER\": \"Services\",\n    \"BODY\": \"<p>An Application can contain
    multiple services. A service can contain multiple pipelines. When a Service is created,
    a Pipeline with the same name is created automatically. You can add more pipelines
    by clicking on '+' symbol in <strong>Service Pipeline</strong></p>\",\n    \"SERVICE_NAME\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"exists\":
    \"Service already exists\",\n        \"noSpecialCharacters\": \"Service Name cannot
    contain special characters\",\n        \"cannotContainSpace\": \"Service Name cannot
    contain space\",\n        \"required\": \"Service Name cannot be empty\",\n        \"startingFromNumber\":
    \"Service Name cannot start with number\",\n        \"maxlength\": \"Service name
    should not have more than 63 characters!\"\n      }\n    },\n    \"SERVICE_PIPELINE\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"ADD_NEW_SERVICE\":
    {\n      \"TOOLTIP\": \"Add a new Service\",\n      \"VALIDATION_MESSAGE\": \"\"\n
    \   },\n    \"SHOW_OR_HIDE_SERVICE\": {\n      \"TOOLTIP\": \"Show/Hide this service
    in the deployment dashboard\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"DELETE_PIPELINE_ICON\":
    {\n      \"TOOLTIP\": \"Delete Pipeline from Service\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"DELETE_PERMISSION\": {\n      \"TOOLTIP\": \"Insufficient Permission
    to Delete this Service\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"DELETE_SERVICE\":
    {\n      \"TOOLTIP\": \"Service can be deleted on deleting pipelines\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    }\n  },\n  \"GROUP_PERMISSION\": {\n    \"APP_PERMISSIONS\": {\n      \"TOOLTIP\":
    \"Authorization definition for this Application\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"groupValid\": \"Groups cannot be empty\",\n        \"permissionsValid\":
    \"Atleast 1 permission should be assigned to the groups\",\n        \"allPermissionForOneGroup\":
    \"Atleast 1 group should have all permissions\"\n      }\n    },\n    \"INTEGRATORS_PERMISSIONS\":
    {\n      \"TOOLTIP\": \"Authorization definition for this Integration\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"CLOUD_PROVIDER_PERMISSIONS\": {\n      \"TOOLTIP\": \"Authorization
    definition for this Cloud Targets\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n
    \   \"AGENT_PERMISSIONS\": {\n      \"TOOLTIP\": \"Authorization definition for
    this Agent\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"POLICY_PERMISSIONS\":
    {\n      \"TOOLTIP\": \"Authorization definition for this Policy\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"ADD_GROUP\": {\n      \"TOOLTIP\": \"Add New Group\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"DELETE\": {\n      \"TOOLTIP\": \"Delete\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    }\n  },\n  \"GATE_DETAILS\": {\n    \"HEADER\": \"Gate Configuration\",\n
    \   \"BODY\": \"<p>Select Gates from <strong>Existing Gates</strong> dropdown to
    load Gate Configuration and to add new Gate Configuration click the <strong>Add
    New Gate</strong> button</p> <p>Autopilot has the following Gate Types</p> <ul class='helpTextUI'>
    <li><strong>Approval</strong>: Fetches relevant information from multiple CI/CD
    Tools, presents the data in one place, to enable the user to make quick and informed
    decision on pipeline execution</li> <li><strong>Verification</strong>: Analyze logs
    & metrics from your target application to evaluate the risk in software delivery</li>
    <li><strong>Test Verification</strong>: Analyze logs from your Test Harness to evaluate
    the risk in software delivery</li>  <li><strong>Policy</strong>: Defines a set of
    conditions that need to be verified while creating or executing a CI/CD pipeline</li>
    </ul>\",\n    \"PIPELINE\": {\n      \"TOOLTIP\": \"Shows the structure of how the
    Gates are stacked in the Pipeline\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n
    \   \"TYPE\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": \"\"\n
    \   },\n    \"EXISITING_GATE\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"ENVIRONMENT\": {\n      \"TOOLTIP\": \"Specify Environment for
    this Gate\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Environment
    Name is Invalid\"\n      }\n    },\n    \"CUSTOM_ENVIRONMENT_NAME\": {\n      \"TOOLTIP\":
    \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"noSpecialCharacters\": \"Environment
    Name cannot contain special characters\",\n        \"cannotContainSpace\": \"Environment
    Name cannot contain space\",\n        \"required\": \"Environment Name cannot be
    empty\",\n        \"startingFromNumber\": \"Environment Name cannot start with number\",\n
    \       \"maxlength\": \"Environment name should not have more than 63 characters!\",\n
    \       \"exists\": \"Environment name already exists\"\n      }\n    },\n    \"GATE_NAME\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"exists\":
    \"Gate already exists\",\n        \"noSpecialCharacters\": \"Gate Name cannot contain
    special characters\",\n        \"cannotContainSpace\": \"Gate Name cannot contain
    space\",\n        \"required\": \"Gate Name cannot be empty\",\n        \"startingFromNumber\":
    \"Gate Name cannot start with number\",\n        \"maxlength\": \"Gate name should
    not have more than 63 characters!\"\n      }\n    },\n    \"DEPENDS_ON\": {\n      \"TOOLTIP\":
    \"This field determines the placement of the current Gate in the Pipeline. This
    field is not required if there are no Stages in the Pipeline\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Depends On cannot be empty\"\n      }\n    },\n    \"CONNECTOR\":
    {\n      \"TOOLTIP\": \"Tool to gather information for informed Approvals\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Please select Connector\"\n      }\n    },\n    \"ACCOUNT\":
    {\n      \"TOOLTIP\": \"Account name of the connector\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Please select Account\"\n      }\n    },\n    \"TEMPLATE\":
    {\n      \"TOOLTIP\": \"Define the specific fields of interest from connector\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Please select Template\"\n
    \     }\n    },\n    \"ADD_NEW_TEMPLATE\": {\n      \"TOOLTIP\": \"Add New Connector\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"EDIT_TEMPLATE\": {\n      \"TOOLTIP\":
    \"Edit Template\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"VIEW_TEMPLATE\":
    {\n      \"TOOLTIP\": \"View Template\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n
    \   \"DELETE_TEMPLATE\": {\n      \"TOOLTIP\": \"Delete Template\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"TEMPLATE_TOOL_TYPE\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"TEMPLATE_NAME\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"noSpecialCharacters\": \"Template Name cannot contain special characters\",\n
    \       \"required\": \"Template Name cannot be empty\",\n        \"startingFromNumber\":
    \"Template Name cannot start with number\",\n        \"maxlength\": \"Template Name
    should not have more than 63 characters!\"\n      }\n    },\n    \"TEMPLATE_DESCRIPTION\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"AUTOMATED_APPROVAL\":
    {\n      \"TOOLTIP\": \"Use predefined conditions to Approve or Reject a request.
    You can configure conditions using Policies.\",\n      \"VALIDATION_MESSAGE\": {\n
    \       \"required\": \"Please select Approval Condition\"\n      }\n    },\n    \"APPROVAL_GROUPS\":
    {\n      \"TOOLTIP\": \"Selected groups will be able to review this Approval Gate\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Please select Approval
    Groups to continue\"\n      }\n    },\n    \"APPROVAL_GROUP_MSG\": {\n      \"TOOLTIP\":
    \"Selected groups should have atleast view access to the application\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"GATE_SECURITY_SOURCE_URL\": {\n      \"TOOLTIP\": \"Source Url\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"GATE_SECURITY_SOURCE_URL_COPY\":
    {\n      \"TOOLTIP\": \"Copy Source Url\",\n      \"VALIDATION_MESSAGE\": \"\"\n
    \   },\n    \"PAYLOAD_CONSTRAINTS\": {\n      \"TOOLTIP\": \"Payload Constraints
    for Gate Security\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"PAYLOAD_CONSTRAINTS_KEY\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"cannotContainSpace\":
    \"Key cannot contain space\",\n        \"required\": \"Invalid Key\"\n      }\n
    \   },\n    \"LOG_TEMPLATE\": {\n      \"TOOLTIP\": \"A collection of all the information
    needed to run the log analysis\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n
    \   \"CREATE_GATE_CONFIG_TEMPLATE\": {\n      \"TOOLTIP\": \"Create New Template\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"EDIT_GATE_CONFIG_TEMPLATE\": {\n
    \     \"TOOLTIP\": \"Edit Template\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n
    \   \"VIEW_GATE_CONFIG_TEMPLATE\": {\n      \"TOOLTIP\": \"View Template\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"DELETE_GATE_CONFIG_TEMPLATE\": {\n      \"TOOLTIP\": \"Delete
    Template\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"METRIC_TEMPLATE\":
    {\n      \"TOOLTIP\": \"Information needed to run the metric analysis\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"POLICY\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"DELETE_PERMISSION\": {\n      \"TOOLTIP\": \"Insufficient Permission
    to Delete this Gate\",\n      \"VALIDATION_MESSAGE\": \"\"\n    }\n  },\n  \"LOGGED_INUSER_DETAILS\":
    {\n    \"HEADER\": \"No Users found\",\n    \"BODY\": \"\"\n  },\n    \n  \"APPLICATION_DEPLOYMENT\":
    {\n    \"DEPLOYMENT_GRID_SYNC\": {\n      \"TOOLTIP\": \"When the cluster deployment
    matches with the latest pipeline execution it is 'In Sync'; if not, it is 'Out of
    Sync'\"\n    }\n  },\n          \"INTEGRATION\": {\n\"AMAZONS3\":{\n  \"HEADER\":
    \"Amazon S3\",\n  \"BODY\":\"<span><p>Amazon S3 integration can be used to configure
    Spinnaker for Amazon S3.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User defined name for the Amazon S3 Account <span class='noBr'>(Example:
    opsmx-s3)</span></li><li><strong>Access Key Id</strong>: AWS Access Key Id</li><li><strong>Secret
    Access Key</strong>: AWS Secret Access Key</li><li><strong>Connect to Spinnaker</strong>:
    Toggle to configure Spinnaker for Amazon S3</li><li><strong>Permissions</strong>:
    Enable/disable access to the Amazon S3 account in Autopilot to specific usergroups</li></ul></span>\",\n
    \ \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"The name of the account to operate on\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name cannot
    contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"ACCESS_ID\":{\n    \"TOOLTIP\":\"AWS Access Key Id\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Access Key Id cannot be empty\"\n    }\n  },\n  \"SECRET_KEY\":{\n
    \   \"TOOLTIP\":\"AWS Secret Access Key\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Secret
    Access Key cannot be empty\"\n    }\n  },\n  \"REGION\":{\n    \"TOOLTIP\":\"S3
    region\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"S3 region cannot be
    empty\"\n    }\n  },\n  \"APIENDPOINT\":{\n    \"TOOLTIP\":\"S3 api endpoint\",\n
    \   \"VALIDATION_MESSAGE\":{\n    }\n  },\n  \"APIREGION\":{\n    \"TOOLTIP\":\"S3
    api region\",\n    \"VALIDATION_MESSAGE\":{\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n
    \   \"TOOLTIP\":\"Switch On this toggle to configure the resource in a gitops enabled
    Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"ARTIFACTORY\":{\n
    \ \"HEADER\": \"Artifactory\",\n  \"BODY\":\"<span><p>Artifactory integration can
    be used as a datasource for Approval Gate as well as to configure Spinnaker for
    Artifactory.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User defined name for the Artifactory Account <span class='noBr'>(Example:
    opsmx-artifactory)</span></li><li><strong>Endpoint</strong>: Artifactory URL <span
    class='noBr'>(Example: https://xyz.myjfrog.com)</span></li><li><strong>Token</strong>:
    Artifactory personal access token. You can find <a href='https://www.jfrog.com/confluence/display/JFROG/Access+Tokens'
    target='_blank'>here</a> how to generate personal access tokens. <span class='autolinebreak'>(Example:
    ZlQDAwMFwvdXNlcnNcL21hZGh1a2FyIiwic2NwIjoiYXBwbGllZC1wZXJtaXNzaW9uc1wvYWRtaW4gYXBpOioiLCJhdWQiOlsiamZydEAqIiwiamZhY0AqIiwiamZldnmbWRAKiJdLCJpc3MiOiJqZmZlQDAAzNzY3MiwiaWF0IjoxNjI5ODY0ODcyLCJqdGkiOiI1ZWFiNjlhYi1hZDY0LTRjOGItOTMyZC0wMDAxMWZiZWU5YWIifQ.tzBgL3fQgZ1dwlLLS2UAT7G)</span></li><li><strong>Connect
    to Spinnaker</strong>: Toggle to configure Spinnaker for Artifactory</li><li><strong>Permissions</strong>:
    Enable/disable access to the Artifactory account in Autopilot to specific usergroups</li></ul></span>\",\n
    \ \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"The name of the account to operate on\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name cannot
    contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"ENDPOINT\":{ \n    \"TOOLTIP\":\"The base url your artifactory search
    is reachable at\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Endpoint
    cannot be empty\",\n      \"invalidUrl\": \"URL is invalid\"\n    }\n  },\n  \"REPO\":{
    \n    \"TOOLTIP\":\"The repo in your artifactory to be searched\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Repo cannot be empty\"\n    }\n  },\n  \"REPOTYPE\":{ \n    \"TOOLTIP\":\"The
    package type of repo in your artifactory to be searched\",\n    \"VALIDATION_MESSAGE\":{\n
    \   }\n  },\n  \"GROUPID\":{ \n    \"TOOLTIP\":\"The group id in your artifactory
    to be searched\",\n    \"VALIDATION_MESSAGE\":{\n    }\n  },\n  \"AUTHENTICATIONTYPE\":{\n
    \   \"TOOLTIP\":\"Select how the external resource confirms the user credentials\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"Authentication cannot be empty\"\n
    \   }\n  },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"The Token of the artifactory user
    to authenticate as\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token
    cannot be empty\"\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"The username
    of the artifactory user to authenticate as\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Username
    cannot be empty\"\n    }\n  },\n  \"PASSWORD\":{\n    \"TOOLTIP\":\"The password
    of the artifactory user to authenticate as\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Password
    cannot be empty\"\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch
    On this toggle to configure the resource in a gitops enabled Spinnaker instance\",\n
    \   \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"BITBUCKET\":{\n  \"HEADER\": \"Bitbucket
    Cloud\",\n  \"BODY\":\"<span><p>BitBucket Cloud integration can be used as a datasource
    for Approval Gate as well as to configure Spinnaker for BitBucket Cloud.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Name</strong>: User defined name for the Bitbucket
    Cloud Account <span class='noBr'>(Example: opsmx-bitbucket)</span></li><li><strong>Host
    URL</strong>: BitBucket Cloud URL <span class='noBr'>(Example: https://bitbucket.org)</span></li><li><strong>API
    URL</strong>: This is needed by Autopilot to access Bitbucket Cloud resources such
    as accounts & repositories through API calls <span class='noBr'>(Example: https://api.bitbucket.org/2.0/repositories)</span></li><li><strong>Authentication
    Type</strong>: can be Token or User Name/Password</li><li><strong>User Name</strong>:
    Bitbucket Cloud User Name</li><li><strong>Token</strong>: BitBucket personal access
    token <span class='noBr'>(Example: xCPkVZfxaE9iULmfYYkK)</span></li> <li><strong>Password</strong>:
    Bitbucket Cloud Password</li><li><strong>Connect to Spinnaker</strong>: Toggle to
    configure Spinnaker for Bitbucket Cloud</li><li><strong>Permissions</strong>: Enable/disable
    access to the Bitbucket Account in Autopilot to specific usergroups</li></ul></span>\",\n
    \ \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"The name of the account to operate on\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name cannot
    contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"HOSTURL\":{\n    \"TOOLTIP\":\"BitBucket Cloud URL\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Host URL cannot be empty\",\n      \"invalidUrl\": \"URL is
    invalid\"\n    }\n  },\n  \"APIURL\":{\n    \"TOOLTIP\":\"Bitbucket API base URL.
    Eg. https://api.github.com\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"API
    URL cannot be empty\",\n      \"invalidUrl\": \"URL is invalid\"\n    }\n  },\n
    \ \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select how the external resource confirms
    the user credentials\",\n    \"VALIDATION_MESSAGE\":{}\n  },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"The
    Token of the Bitbucket user to authenticate as\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Token cannot be empty\"\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"The
    username of the Bitbucket user to authenticate as\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"User Name cannot contain special characters other
    than - and _\",\n      \"cannotContainSpace\":\"User Name cannot contain space\",\n
    \     \"required\":\"User Name cannot be empty\",\n      \"startingFromNumber\":
    \"User Name cannot start with numbers\"\n    }\n  },\n  \"PASSWORD\":{\n    \"TOOLTIP\":\"The
    password of the Bitbucket user to authenticate as\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Password cannot be empty\"\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n
    \   \"TOOLTIP\":\"Switch On this toggle to configure the resource in a gitops enabled
    Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"BITBUCKET_SERVER\":{\n
    \ \"HEADER\": \"Bitbucket Server\",\n  \"BODY\":\"<span><p>BitBucket Server integration
    can be used as a datasource for Approval Gate as well as to configure Spinnaker
    for BitBucket Server.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User defined name for the Bitbucket Server Account <span class='noBr'>(Example:
    opsmx-bitbucket)</span></li><li><strong>Host URL</strong>: BitBucket Server URL
    <span class='noBr'>(Example: https://xyz.mybitbucket.com)</span></li><li><strong>Authentication
    Type</strong>: can be Token or User Name/Password</li><li><strong>User Name</strong>:
    Bitbucket Server User Name</li><li><strong>Token</strong>: BitBucket Server personal
    access token. You can find <a href='https://confluence.atlassian.com/bitbucketserver/personal-access-tokens-939515499.html'
    target='_blank'>here</a> how to generate personal access tokens. <span class='noBr'>(Example:
    DjpMgHmwqUnIvvmljFgqGQ)</span></li><li><strong>Password</strong>: Bitbucket Server
    Password</li><li><strong>Connect to Spinnaker</strong>: Toggle to configure Spinnaker
    for Bitbucket Server</li><li><strong>Permissions</strong>: Enable/disable access
    to the Bitbucket Server account in Autopilot to specific usergroups</li></ul></span>\",\n
    \ \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"The name of the account to operate on\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name cannot
    contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"HOSTURL\":{\n    \"TOOLTIP\":\"Bitbucket Cloud URL\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Host URL cannot be empty\",\n      \"invalidUrl\": \"URL is
    invalid\"\n    }\n  },\n  \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select how
    the external resource confirms the user credentials\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"The Token of the Bitbucket user to authenticate
    as\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token cannot be empty\"\n
    \   }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"The username of the Bitbucket user
    to authenticate as\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"User Name cannot contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"PASSWORD\":{\n    \"TOOLTIP\":\"The password of the Bitbucket user to authenticate
    as\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Password cannot be empty\"\n
    \   }\n  },\n  \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch On this toggle to
    configure the resource in a gitops enabled Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ }\n},\n\"DOCKERHUB\":{\n  \"HEADER\": \"Docker Registry\",\n  \"BODY\":\"\",\n
    \ \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"The name of the account to operate on\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name cannot
    contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select how the external resource
    confirms the user credentials\",\n    \"VALIDATION_MESSAGE\":{}\n  },\n  \"TOKEN\":{\n
    \   \"TOOLTIP\":\"The token of the Docker Registry user to authenticate as\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token cannot be empty\"\n    }\n
    \ },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"The username of the Docker Registry user
    to authenticate as\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"User Name cannot contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"PASSWORD\":{\n    \"TOOLTIP\":\"The password of the Docker Registry user to
    authenticate as\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Password
    cannot be empty\"\n    }\n  },\n  \"HOSTURL\":{\n    \"TOOLTIP\":\"Docker Registry
    Host URL\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Host URL cannot
    be empty\",\n      \"invalidUrl\": \"URL is invalid\"\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n
    \   \"TOOLTIP\":\"Switch On this toggle to configure the resource in a gitops enabled
    Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"OCR\":{\n  \"HEADER\":
    \"Generic Docker Registries (ACR, Quay, JFrog)\",\n  \"BODY\":\"\",\n  \"ACCOUNTNAME\":{\n
    \   \"TOOLTIP\":\"The name of the account to operate on\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n  },\n  \"REPOSITORIES\":{\n
    \   \"TOOLTIP\":\"An optional list of repositories to cache images from\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"cannotContainSpace\":\"Repository cannot contain space\",\n      \"startingFromNumber\":
    \"Repository cannot start with numbers\"\n    }\n  },\n  \"REGISTRYURL\":{\n    \"TOOLTIP\":\"The
    registry address you want to pull and deploy images from. For example:quay.io -
    Quay\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Registry URL cannot
    be empty\"\n    }\n  },\n  \"GROUPMEMBERSHIP\":{\n    \"TOOLTIP\":\"A user must
    be a member of at least one specified group in order to make changes to this account’s
    cloud resources\",\n    \"VALIDATION_MESSAGE\":{\n      \"cannotContainSpace\":\"Repository
    cannot contain space\"\n    }\n  },\n  \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select
    how the external resource confirms the user credentials\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"Your docker registry token\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Token cannot be empty\"\n    }\n  },\n  \"PASSWORD\":{\n    \"TOOLTIP\":\"Your
    docker registry password\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Password
    cannot be empty\"\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"Your docker
    registry username\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"User Name cannot contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"HOSTURL\":{\n    \"TOOLTIP\":\"Container Registry Host URL\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Host URL cannot be empty\",\n      \"invalidUrl\": \"URL is
    invalid\"\n    }\n  }\n},\n\"GITHUB\":{\n  \"HEADER\": \"GitHub\",\n  \"BODY\":\"<span><p>GIT
    HUB integration can be used as a datasource for Approval Gate as well as to configure
    Spinnaker for GitHub.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User defined name for the GitHub Account<span class='noBr'>(Example:
    opsmx-github)</span></li><li><strong>Token</strong>: GitHub personal access token.
    You can find <a href='https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token'
    target='_blank'>here</a> how to generate personal access tokens. <span class='noBr'>(Example:
    ghp_ln1eJK4yuomnY6JREp72IDJC4Hq6Sm)</span></li><li><strong>User Name</strong>: GitHub
    User Name</li><li><strong>Connect to Spinnaker</strong>: Toggle to configure Spinnaker
    for GitHub</li><li><strong>Permissions</strong>: Enable/disable access to the GIT
    HUB account in Autopilot to specific usergroups</li></ul></span>\",\n  \"ACCOUNTNAME\":{\n
    \   \"TOOLTIP\":\"The name of the account to operate on\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n  },\n  \"HOSTURL\":{\n    \"TOOLTIP\":\"GitHub
    URL\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Host URL cannot be empty\",\n
    \     \"invalidUrl\": \"URL is invalid\"\n    }\n  },\n  \"URL\":{\n    \"TOOLTIP\":\"GitHub
    API base URL. Eg. https://api.github.com\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"API
    URL cannot be empty\",\n      \"invalidUrl\": \"URL is invalid\"\n    }\n  },\n
    \ \"TOKEN\":{\n    \"TOOLTIP\":\"GitHub token\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Token cannot be empty\"\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"GitHub
    username\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"User
    Name cannot contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch On this toggle to configure the
    resource in a gitops enabled Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ }\n},\n\"GITLAB\":{\n  \"HEADER\": \"GitLab\",\n  \"BODY\":\"\",\n  \"ACCOUNTNAME\":{\n
    \   \"TOOLTIP\":\"User defined name for the GitLab account\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n  },\n  \"HOSTURL\":{\n    \"TOOLTIP\":\"GitLab
    Host URL\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Host URL cannot
    be empty\",\n      \"invalidUrl\": \"URL is invalid\"\n    }\n  },\n  \"APIBASEURL\":{\n
    \   \"TOOLTIP\":\"\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"API URL
    cannot be empty\",\n      \"invalidUrl\": \"URL is invalid\"\n    }\n  },\n  \"AUTHENTICATIONTYPE\":{\n
    \   \"TOOLTIP\":\"Select how the external resource confirms the user credentials\",\n
    \   \"VALIDATION_MESSAGE\":{}\n  },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"GitLab token\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token cannot be empty\"\n    }\n
    \ },\n  \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch On this toggle to configure
    the resource in a gitops enabled Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ }\n},\n\"GITREPO\":{\n  \"HEADER\": \"Git Repo\",\n  \"BODY\": \"\",\n  \"ACCOUNTNAME\":{\n
    \   \"TOOLTIP\":\"The name of the account to operate on\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n  },\n  \"DEPLOYMENT\":{\n    \"TOOLTIP\":\"This
    Halyard deployment will be used for Account creation / update\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"URL cannot be empty\",\n      \"invalidUrl\": \"URL is invalid\"\n
    \   }\n  },\n  \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select how the external
    resource confirms the user credentials\",\n    \"VALIDATION_MESSAGE\":{}\n  },\n
    \ \"URL\":{\n    \"TOOLTIP\":\"\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"API
    URL cannot be empty\",\n      \"invalidUrl\": \"URL is invalid\"\n    }\n  },\n
    \ \"TOKEN\":{\n    \"TOOLTIP\":\"Git token\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token
    cannot be empty\"\n    }\n  },\n  \"PASSWORD\":{\n    \"TOOLTIP\":\"Git password\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"Password cannot be empty\"\n
    \   }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"Git username\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"User Name cannot contain special characters other
    than - and _\",\n      \"cannotContainSpace\":\"User Name cannot contain space\",\n
    \     \"required\":\"User Name cannot be empty\",\n      \"startingFromNumber\":
    \"User Name cannot start with numbers\"\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n
    \   \"TOOLTIP\":\"Switch On this toggle to configure the resource in a gitops enabled
    Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"HELM\":{\n  \"HEADER\":
    \"Helm\",\n  \"BODY\": \"\",\n  \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"The name of
    the account to operate on\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"REPOSITORY\":{\n    \"TOOLTIP\":\"URL of the Helm Chart Repository\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"URL cannot be empty\",\n      \"invalidUrl\":
    \"URL is invalid\"\n    }\n  },\n  \"DEPLOYMENT\":{\n    \"TOOLTIP\":\"This Halyard
    deployment will be used for Account creation / update\",\n    \"VALIDATION_MESSAGE\":{\n
    \   \n    }\n  },\n  \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select how the
    external resource confirms the user credentials\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token
    cannot be empty\"\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"User Name\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"User Name cannot
    contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"PASSWORD\": {\n    \"TOOLTIP\": \"Password\",\n    \"VALIDATION_MESSAGE\":{\n
    \   }\n  },\n  \"PASSWORDCOMMAND\": {\n    \"TOOLTIP\": \"Command to retrieve docker
    token/password, commands must be available in environment\",\n    \"VALIDATION_MESSAGE\":{\n
    \   }\n  },\n  \"FILE\": {\n    \"TOOLTIP\": \"The path to a file containing your
    docker password in plaintext (not a docker/config.json file)\",\n    \"VALIDATION_MESSAGE\":
    {\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch On this toggle
    to configure the resource in a gitops enabled Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ }\n},\n\"HTTP\":{\n  \"HEADER\": \"Http\",\n  \"BODY\": \"\",\n  \"ACCOUNTNAME\":{\n
    \   \"TOOLTIP\":\"The name of the account to operate on\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n  },\n\n  \"AUTHENTICATIONTYPE\":{\n
    \   \"TOOLTIP\":\"Select how the external resource confirms the user credentials\",\n
    \   \"VALIDATION_MESSAGE\":{}\n  },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Token cannot be empty\"\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"HTTP
    basic auth User Name\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"User Name cannot contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"PASSWORD\": {\n    \"TOOLTIP\": \"Password\",\n    \"VALIDATION_MESSAGE\":{\n
    \   }\n  },\n  \"PASSWORDCOMMAND\": {\n    \"TOOLTIP\": \"Command to retrieve docker
    token/password, commands must be available in environment\",\n    \"VALIDATION_MESSAGE\":{\n
    \   }\n  },\n  \"FILE\": {\n    \"TOOLTIP\": \"The path to a file containing your
    docker password in plaintext (not a docker/config.json file)\",\n    \"VALIDATION_MESSAGE\":
    {\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch On this toggle
    to configure the resource in a gitops enabled Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ }\n},\n\"GCS\":{\n  \"HEADER\": \"GCS\",\n  \"BODY\": \"\",\n  \"ACCOUNTNAME\":{\n
    \   \"TOOLTIP\":\"The name of the account to operate on\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n  },\n  \"AUTHENTICATIONTYPE\":{\n
    \   \"TOOLTIP\":\"Select how the external resource confirms the user credentials\",\n
    \   \"VALIDATION_MESSAGE\":{}\n  },\n  \"FILE\": {\n    \"TOOLTIP\": \"JSON service
    account that Spinnaker will use as credentials\",\n    \"VALIDATION_MESSAGE\": {\n
    \   }\n  },\n  \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch On this toggle to
    configure the resource in a gitops enabled Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ }\n},\n\"ECR\":{\n  \"HEADER\": \"ECR\",\n  \"BODY\": \"\",\n  \"ACCOUNTNAME\":{\n
    \   \"TOOLTIP\":\"The name of the account to operate on\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n  },\n  \"REPOSITORIES\":{\n
    \   \"TOOLTIP\":\"An optional list of repositories to cache images from\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"cannotContainSpace\":\"Repository cannot contain space\",\n      \"startingFromNumber\":
    \"Repository cannot start with numbers\"\n    }\n  },\n  \"REGISTRYURL\":{\n    \"TOOLTIP\":\"The
    registry address you want to pull and deploy images from. For example: gcr.io\",\n
    \   \"VALIDATION_MESSAGE\":{\n    }\n  },\n  \"GROUPMEMBERSHIP\":{\n    \"TOOLTIP\":\"A
    user must be a member of at least one specified group in order to make changes to
    this account’s cloud resources\",\n    \"VALIDATION_MESSAGE\":{\n      \"cannotContainSpace\":\"Repository
    cannot contain space\"\n    }\n  },\n  \"REGION\": {\n    \"TOOLTIP\": \"AWS region\"\n
    \ },\n  \"EMAIL\":{\n    \"TOOLTIP\":\"Your docker registry email\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"email\":\"Email Id is invalid\",\n      \"required\":\"Email Id cannot be
    empty\"\n    }\n  },\n  \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select how the
    external resource confirms the user credentials\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token
    cannot be empty\"\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"Your docker
    registry username\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"User Name cannot contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"PASSWORD\": {\n    \"TOOLTIP\": \"Your docker registry password\",\n    \"VALIDATION_MESSAGE\":{\n
    \   }\n  },\n  \"PASSWORDCOMMAND\": {\n    \"TOOLTIP\": \"Command to retrieve docker
    token/password, commands must be available in environment\",\n    \"VALIDATION_MESSAGE\":{\n
    \   }\n  },\n  \"FILE\": {\n    \"TOOLTIP\": \"The path to a file containing your
    docker password in plaintext (not a docker/config.json file)\",\n    \"VALIDATION_MESSAGE\":
    {\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch On this toggle
    to configure the resource in a gitops enabled Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ }\n},\n\"PUBSUB\":{\n  \"HEADER\": \"PUBSUB\",\n  \"BODY\": \"\",\n  \"ACCOUNTNAME\":{\n
    \   \"TOOLTIP\":\"The name of the account to operate on\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n  },\n  \"PROJECTNAME\": {\n
    \   \"TOOLTIP\": \"The name of the GCP project your subscription lives in\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"cannotContainSpace\":\"Project Name cannot contain space\",\n      \"required\":\"Project
    Name cannot be empty\"\n    }\n  },\n  \"SUBSCRIPTIONNAME\": {\n    \"TOOLTIP\":
    \"The name of the subscription to listen to. This identifier does not include the
    name of the project, and must already be configured for Spinnaker to work.\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"cannotContainSpace\":\"Subscription Name cannot
    contain space\",\n      \"required\":\"Subscription Name cannot be empty\"\n    }\n
    \ },\n  \"MESSAGEFORMAT\": {\n    \"TOOLTIP\":\"Supporting Message Formats: GCB,GCS,GCR,CUSTOM\",\n
    \   \"VALIDATION_MESSAGE\": {}\n  },\n  \"TEMPLATEFILE\": {\n    \"TOOLTIP\":\"Applicable
    only for CUSTOM message format\",\n    \"VALIDATION_MESSAGE\": {}\n  },\n  \"AUTHENTICATIONTYPE\":{\n
    \   \"TOOLTIP\":\"Select how the external resource confirms the user credentials\",\n
    \   \"VALIDATION_MESSAGE\":{}\n  },\n  \"FILE\": {\n    \"TOOLTIP\": \"JSON service
    account that Spinnaker will use as credentials\",\n    \"VALIDATION_MESSAGE\": {\n
    \   }\n  },\n  \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch On this toggle to
    configure the resource in a gitops enabled Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ }\n},\n\"GCB\":{\n  \"HEADER\": \"GCB\",\n  \"BODY\": \"\",\n  \"ACCOUNTNAME\":{\n
    \   \"TOOLTIP\":\"The name of the account to operate on\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n  },\n  \"PROJECTNAME\": {\n
    \   \"TOOLTIP\": \"The name of the GCP project in which to trigger and monitor builds\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"cannotContainSpace\":\"Project Name cannot
    contain space\",\n      \"required\":\"Project Name cannot be empty\"\n    }\n  },\n
    \ \"SUBSCRIPTIONNAME\": {\n    \"TOOLTIP\": \"The name of the PubSub subscription
    on which to listen for build changes\",\n    \"VALIDATION_MESSAGE\":{\n      \"cannotContainSpace\":\"Subscription
    Name cannot contain space\",\n      \"required\":\"Subscription Name cannot be empty\"\n
    \   }\n  },\n  \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select how the external
    resource confirms the user credentials\",\n    \"VALIDATION_MESSAGE\":{}\n  },\n
    \ \"FILE\": {\n    \"TOOLTIP\": \"JSON service account that Spinnaker will use as
    credentials\",\n    \"VALIDATION_MESSAGE\": {\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"GCB
    User Name\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"User
    Name cannot contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"PASSWORD\": {\n    \"TOOLTIP\": \"Password\",\n    \"VALIDATION_MESSAGE\":{\n
    \   }\n  },\n  \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch On this toggle to
    configure the resource in a gitops enabled Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ }\n},\n\"GCR\":{\n  \"HEADER\": \"GCR\",\n  \"BODY\": \"\",\n  \"ACCOUNTNAME\":{\n
    \   \"TOOLTIP\":\"The name of the account to operate on\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n  },\n  \"AUTHENTICATIONTYPE\":{\n
    \   \"TOOLTIP\":\"Select how the external resource confirms the user credentials\",\n
    \   \"VALIDATION_MESSAGE\":{}\n  },\n  \"REPOSITORIES\":{\n    \"TOOLTIP\":\"An
    optional list of repositories to cache images from\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"cannotContainSpace\":\"Repository cannot contain space\",\n      \"startingFromNumber\":
    \"Repository cannot start with numbers\"\n    }\n  },\n  \"REGISTRYURL\":{\n    \"TOOLTIP\":\"The
    registry address you want to pull and deploy images from. For example: gcr.io\",\n
    \   \"VALIDATION_MESSAGE\":{\n    }\n  },\n  \"REQUIREDGROUPMEMBERSHIP\":{\n    \"TOOLTIP\":\"A
    user must be a member of at least one specified group in order to make changes to
    this account’s cloud resources\",\n    \"VALIDATION_MESSAGE\":{\n      \"cannotContainSpace\":\"Repository
    cannot contain space\"\n    }\n  },\n  \"EMAIL\":{\n    \"TOOLTIP\":\"Your docker
    registry email\",\n    \"VALIDATION_MESSAGE\":{\n      \"email\":\"Email Id is invalid\",\n
    \     \"required\":\"Email Id cannot be empty\"\n    }\n  },\n  \"URL\":{\n    \"TOOLTIP\":\"\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"API URL cannot be empty\",\n
    \     \"invalidUrl\": \"URL is invalid\"\n    }\n  },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token cannot be empty\"\n    }\n
    \ },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"GCR User Name\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"User Name cannot contain special characters other
    than - and _\",\n      \"cannotContainSpace\":\"User Name cannot contain space\",\n
    \     \"required\":\"User Name cannot be empty\",\n      \"startingFromNumber\":
    \"User Name cannot start with numbers\"\n    }\n  },\n  \"PASSWORD\": {\n    \"TOOLTIP\":
    \"Your docker registry password\",\n    \"VALIDATION_MESSAGE\":{\n    }\n  },\n
    \ \"PASSWORDCOMMAND\": {\n    \"TOOLTIP\": \"Command to retrieve docker token/password,
    commands must be available in environment\",\n    \"VALIDATION_MESSAGE\":{\n    }\n
    \ },\n  \"FILE\": {\n    \"TOOLTIP\": \"The path to a file containing your docker
    password in plaintext (not a docker/config.json file)\",\n    \"VALIDATION_MESSAGE\":
    {\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch On this toggle
    to configure the resource in a gitops enabled Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ }\n},\n\"BAMBOO\":{\n    \"HEADER\": \"Bamboo CI\",\n    \"BODY\":\" <span><p>Bamboo
    CI integration can be used as a datasource for Approval Gate.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'> <li><strong>Name</strong>: User defined name for the Bamboo
    CI Account <span class='noBr'>(Example: opsmx-bamboo)</span></li><li><strong>Endpoint</strong>:
    Bamboo CI URL <span class='noBr'>(Example: https://xyz.mybamboo.com)</span></li><li><strong>Token</strong>:
    Bamboo CI personal access token. You can find <a href='https://confluence.atlassian.com/bamboo/personal-access-tokens-976779873.html'
    target='_blank'>here</a> how to generate personal access tokens. <span>(Example:
    YmFrwqw0w9r90skfsOk9wcdd014p98kklw==)</span></li><li><strong>User Name</strong>:
    Bamboo CI User Name</li><li><strong>Password</strong>: Bamboo CI Password</li><li><strong>Permissions</strong>:
    Enable/disable access to the Bamboo CI account in Autopilot to specific usergroups</li></ul></span>\",\n
    \   \"ACCOUNTNAME\":{\n      \"TOOLTIP\":\"The name of the account to operate on\",\n
    \     \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name cannot
    contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \   },\n    \"ENDPOINT\":{\n      \"TOOLTIP\":\"Bamboo URL\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Bamboo End Point cannot be empty\",\n        \"invalidUrl\":
    \"URL is invalid\"\n      }\n    },\n    \"AUTHENTICATIONTYPE\":{\n      \"TOOLTIP\":\"Select
    how the external resource confirms the user credentials\",\n      \"VALIDATION_MESSAGE\":{}\n
    \   },\n    \"TOKEN\":{\n      \"TOOLTIP\":\"Your Bamboo token\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Token cannot be empty\"\n      }\n    },\n    \"USERNAME\":{\n
    \     \"TOOLTIP\":\"Your Bamboo username\",\n      \"VALIDATION_MESSAGE\":{\n        \"noSpecialCharacters\":
    \"User Name cannot contain special characters other than - and _\",\n        \"cannotContainSpace\":\"User
    Name cannot contain space\",\n        \"required\":\"User Name cannot be empty\",\n
    \       \"startingFromNumber\": \"User Name cannot start with numbers\"\n      }\n
    \   },\n    \"PASSWORD\":{\n      \"TOOLTIP\":\"Your Bamboo password\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Password cannot be empty\"\n      }\n    }\n  },\n  \"JENKINS\":{\n
    \   \"HEADER\":\"Jenkins\",\n    \"BODY\":\"<span><p>Jenkins integration can be
    used as a datasource for Approval Gate as well as to configure Spinnaker for Jenkins.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Account Name</strong>: User defined name for the
    Jenkins Account <span class='noBr'>(Example: opsmx-jenkins)</span></li><li><strong>Host
    URL</strong>: Jenkins URL <span class='noBr'>(Example: https://xyz.my-jenkins.com/jenkins)</span></li><li><strong>Authentication
    Type</strong>: can be Token or User Name/Password    </li><li><strong>Token</strong>:
    Jenkins personal access token. You can find <a href='https://www.jenkins.io/doc/book/using/using-credentials/'
    target='_blank'>here</a> how to generate personal access tokens. <span>(Example:
    77d67609a841b1811a114b7fbfa109b3c2)</span></li><li><strong>User Name</strong>: Jenkins
    User Name</li><li><strong>Password</strong>: Jenkins Password</li><li><strong>Connect
    to Spinnaker</strong>: Toggle to configure Spinnaker for Jenkins</li><li><strong>Permissions</strong>:
    Enable/disable access to the Jenkins account in Autopilot to specific usergroups</li></ul></span>\",\n
    \   \"ACCOUNTNAME\":{\n      \"TOOLTIP\":\"The name of the account to operate on\",\n
    \     \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name cannot
    contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \   },\n    \"HOSTURL\":{\n      \"TOOLTIP\":\"Jenkins URL\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Host URL cannot be empty\",\n        \"invalidUrl\": \"URL
    is invalid\"\n      }\n    },\n    \"AUTHENTICATIONTYPE\":{\n      \"TOOLTIP\":\"Select
    how the external resource confirms the user credentials\",\n      \"VALIDATION_MESSAGE\":{}\n
    \   },\n    \"TOKEN\":{\n      \"TOOLTIP\":\"Your Jenkins token\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Token cannot be empty\"\n      }\n    },\n    \"USERNAME\":{\n
    \     \"TOOLTIP\":\"Your Jenkins username\",\n      \"VALIDATION_MESSAGE\":{\n        \"noSpecialCharacters\":
    \"User Name cannot contain special characters other than - and _\",\n        \"cannotContainSpace\":\"User
    Name cannot contain space\",\n        \"required\":\"User Name cannot be empty\",\n
    \       \"startingFromNumber\": \"User Name cannot start with numbers\"\n      }\n
    \   },\n    \"PASSWORD\":{\n      \"TOOLTIP\":\"Your Jenkins password\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Password cannot be empty\"\n      }\n    },\n    \"SPINNAKERTOGGLE\":{\n
    \     \"TOOLTIP\":\"Switch On this toggle to configure the resource in a gitops
    enabled Spinnaker instance\",\n      \"VALIDATION_MESSAGE\":{}\n    }\n  },\n  \"JIRA\":{\n
    \   \"HEADER\": \"Jira\",\n    \"BODY\":\"\",\n    \"ACCOUNTNAME\":{\n      \"TOOLTIP\":\"User
    defined name for the Jira account\",\n      \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \   },\n    \"EMAIL\":{\n      \"TOOLTIP\":\"Jira Email Id\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"email\":\"Email Id is invalid\",\n        \"required\":\"Email Id cannot
    be empty\"\n      }\n    },\n    \"TOKEN\":{\n      \"TOOLTIP\":\"Jira Personal
    Access Token\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Token cannot
    be empty\"\n      }\n    },\n    \"HOSTURL\":{\n      \"TOOLTIP\":\"Jira Host URL\",\n
    \     \"VALIDATION_MESSAGE\":{\n        \"required\":\"Host URL cannot be empty\",\n
    \       \"invalidUrl\": \"URL is invalid\"\n      }\n    },\n    \"SPINNAKERTOGGLE\":{\n
    \     \"TOOLTIP\":\"Switch On this toggle to configure the resource in a gitops
    enabled Spinnaker instance\",\n      \"VALIDATION_MESSAGE\":{}\n    }\n    \n  },\n
    \ \"SERVICENOW\":{\n    \"HEADER\": \"Service Now\",\n    \"BODY\":\"<span><p>Service
    integration can be used to configure ServiceNow Custom stages in Spinnaker. In addition,
    it can also be used as a datasource for Approval Gate.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Account Name</strong>: User defined name for the
    Service Account <span class='noBr'>(Example: myservicenow)</span></li><li><strong>Host
    URL</strong>: ServiceNow URL <span class='noBr'>(Example: https://servicenow.opsmx.com)</span></li><li><strong>User
    Name</strong>: ServiceNow User Name, for authentication</li><li><strong>Password</strong>:
    ServiceNow Password for the User who is authenticated</li><li><strong>Connect to
    Spinnaker</strong>: Toggle to configure Spinnaker for ServiceNow</li><li><strong>Permissions</strong>:
    Enable/disable access to the ServiceNow account in Autopilot to specific usergroups</li></ul></span>\",\n
    \   \"ACCOUNTNAME\":{\n      \"TOOLTIP\":\"User defined name for the Service Now
    account\",\n      \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \   },\n    \"USERNAME\":{\n      \"TOOLTIP\":\"Service Now User Name\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"noSpecialCharacters\": \"User Name cannot contain special characters other
    than - and _\",\n        \"cannotContainSpace\":\"User Name cannot contain space\",\n
    \       \"required\":\"User Name cannot be empty\",\n        \"startingFromNumber\":
    \"User Name cannot start with numbers\"\n      }\n    },\n    \"PASSWORD\":{\n      \"TOOLTIP\":\"Service
    Now Password\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Password
    cannot be empty\"\n      }\n    },\n    \"HOSTURL\":{\n      \"TOOLTIP\":\"Service
    Now Host URL\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Host URL
    cannot be empty\",\n        \"invalidUrl\": \"URL is invalid\"\n      }\n    }\n
    \ }\n  ,\n  \"APPDYNAMICS\":{\n    \"HEADER\": \"APPDYNAMICS\",\n    \"BODY\":\"\",\n
    \   \"ACCOUNTNAME\":{\n      \"TOOLTIP\":\"User defined name for the APPDYNAMICS
    account\",\n      \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \   },\n    \"CONTROLLERHOST\":{\n      \"TOOLTIP\":\"APPDYNAMICS Controller Host\",\n
    \     \"VALIDATION_MESSAGE\":{\n        \"required\":\"Controller Host  cannot be
    empty\",\n        \"invalidUrl\": \"URL is invalid\"\n      }\n    },\n    \"TEMPORARYACCESSTOKEN\":{\n
    \     \"TOOLTIP\":\"APPDYNAMICS Personal Temporary Access Token\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Temporary Access Token cannot be empty\"\n      }\n    }\n
    \ },\n  \"CLOUDWATCH\":{\n    \"HEADER\": \"AWS-CLOUDWATCH\",\n    \"BODY\":\"\",\n
    \   \"ACCOUNTNAME\":{\n      \"TOOLTIP\":\"User defined name for the AWS-CLOUDWATCH
    account\",\n      \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \   },\n    \"ACCESS_ID\":{\n      \"TOOLTIP\":\"AWS-CLOUDWATCH Access Key Id\",\n
    \     \"VALIDATION_MESSAGE\":{\n        \"required\":\"Access Key Id cannot be empty\"\n
    \     }\n    },\n    \"SECRET_KEY\":{\n      \"TOOLTIP\":\"AWS-CLOUDWATCH Secret
    Access Key\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Secret Access
    Key cannot be empty\"\n      }\n    }\n  },\n  \"DATADOG\":{\n    \"HEADER\": \"DATADOG\",\n
    \   \"BODY\":\"\",\n    \"ACCOUNTNAME\":{\n      \"TOOLTIP\":\"User defined name
    for the DATADOG account\",\n      \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \   \n    },\n    \"API_KEY\":{\n      \"TOOLTIP\":\"DATADOG Api Key\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Application Key cannot be empty\"\n      }\n    },\n    \"APPLICATION_KEY\":{\n
    \     \"TOOLTIP\":\"DATADOG Application Key\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Application Key cannot be empty\"\n      }\n    }\n  },\n
    \ \"DYNATRACE\":{\n    \"HEADER\": \"Dynatrace\",\n    \"BODY\":\"\",\n    \"ACCOUNTNAME\":{\n
    \     \"TOOLTIP\":\"User defined name for the Dynatrace account\",\n      \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n    },\n    \"END_POINT\":{\n
    \     \"TOOLTIP\":\"Dynatrace URL\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Url
    cannot be empty\",\n        \"invalidUrl\": \"URL is invalid\"\n      }\n    },\n
    \   \"API_TOKEN\":{\n      \"TOOLTIP\":\"Dynatrace Personal Access Token\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Api Token cannot be empty\"\n      }\n    }\n  },\n  \"ELASTICSEARCH\":{\n
    \   \"HEADER\": \"Elasticsearch\",\n    \"BODY\":\"\",\n    \"ACCOUNTNAME\":{\n
    \     \"TOOLTIP\":\"User defined name for the Elasticsearch account\",\n      \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n    },\n    \"ENDPOINT\":{\n
    \     \"TOOLTIP\":\"ElasticSearch End Point\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Elastic End Point cannot be empty\",\n        \"invalidUrl\":
    \"URL is invalid\"\n      }\n    },\n    \"USERNAME\":{\n      \"TOOLTIP\":\"ElasticSearch
    User Name\",\n      \"VALIDATION_MESSAGE\":{\n        \"noSpecialCharacters\": \"User
    Name cannot contain special characters other than - and _\",\n        \"cannotContainSpace\":\"User
    Name cannot contain space\",\n        \"startingFromNumber\": \"User Name cannot
    start with numbers\"\n      }\n    },\n    \"PASSWORD\":{\n      \"TOOLTIP\":\"ElasticSearch
    Password\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Password cannot
    be empty\"\n      }\n    },\n    \"KIBANAENDPOINT\":{\n      \"TOOLTIP\":\"ElasticSearch
    Kibana End Point\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Kibana
    End Point cannot be empty\",\n        \"invalidUrl\": \"URL is invalid\"\n      }\n
    \   },\n    \"KIBANAUSERNAME\":{\n      \"TOOLTIP\":\"ElasticSearch Kibana User
    Name\",\n      \"VALIDATION_MESSAGE\":{\n        \"noSpecialCharacters\": \"Kibana
    User Name cannot contain special characters other than - and _\",\n        \"cannotContainSpace\":\"Kibana
    User Name cannot contain space\",\n        \"required\":\"Kibana User Name cannot
    be empty\",\n        \"startingFromNumber\": \"Kibana User Name cannot start with
    numbers\"\n      }\n    },\n    \"KIBANAPASSWORD\":{\n      \"TOOLTIP\":\"ElasticSearch
    Kibana Password\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Kibana
    Password cannot be empty\"\n      }\n    }\n  },\n    \"GRAPHITE\":{\n      \"HEADER\":
    \"Graphite\",\n      \"BODY\":\"\",\n      \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User
    defined name for the Graphite account\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"URL\":{\n        \"TOOLTIP\":\"Graphite End Point\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"End Point cannot be empty\",\n          \"invalidUrl\":
    \"URL is invalid\"\n        }\n      }\n    },\n    \"GRAYLOG\":{\n      \"HEADER\":
    \"GRAYLOG\",\n      \"BODY\":\"\",\n      \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User
    defined name for the GRAYLOG account\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"ENDPOINT\":{\n        \"TOOLTIP\":\"GrayLog End Point\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"End Point cannot be empty\",\n          \"invalidUrl\":
    \"URL is invalid\"\n        }\n      },\n      \"TOKEN\":{\n        \"TOOLTIP\":\"GrayLog
    Personal Access Token\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Token
    cannot be empty\"\n        }\n      }\n    },\n    \"NEWRELIC\":{\n      \"HEADER\":
    \"New Relic\",\n      \"BODY\":\"\",\n      \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User
    defined name for the New Relic account\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"APIKEY\":{\n        \"TOOLTIP\":\"NewRelic Api Key\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Token cannot be empty\"\n        }\n      },\n      \"APPLICATIONKEY\":{\n
    \       \"TOOLTIP\":\"NewRelic Application Key\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Token cannot be empty\"\n        }\n      },\n      \"ACCOUNTID\":{\n
    \       \"TOOLTIP\":\"NewRelic Account Id\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Token cannot be empty\"\n        }\n      },\n      \"QUERYKEY\":{\n
    \       \"TOOLTIP\":\"NewRelic Query Key\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Token cannot be empty\"\n        }\n      }\n    },\n    \"PROMETHEUS\":{\n
    \     \"HEADER\": \"Prometheus\",\n      \"BODY\":\"\",\n      \"ACCOUNTNAME\":{\n
    \       \"TOOLTIP\":\"User defined name for the Prometheus account\",\n        \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n      },\n      \"ENDPOINT\":{\n
    \       \"TOOLTIP\":\"Prometheus End Point\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"End Point cannot be empty\",\n          \"invalidUrl\":
    \"URL is invalid\"\n        }\n      },\n      \"USERNAME\":{\n        \"TOOLTIP\":\"Prometheus
    User Name\",\n        \"VALIDATION_MESSAGE\":{\n          \"noSpecialCharacters\":
    \"User Name cannot contain special characters other than - and _\",\n          \"cannotContainSpace\":\"User
    Name cannot contain space\",\n          \"required\":\"User Name cannot be empty\",\n
    \         \"startingFromNumber\": \"User Name cannot start with numbers\"\n        }\n
    \     },\n      \"PASSWORD\":{\n        \"TOOLTIP\":\"Prometheus Password\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Password cannot be empty\"\n        }\n      }\n    },\n
    \   \"SPLUNK\":{\n      \"HEADER\": \"Splunk\",\n      \"BODY\":\"\",\n      \"ACCOUNTNAME\":{\n
    \       \"TOOLTIP\":\"User defined name for the Splunk account\",\n        \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n      },\n      \"END_POINT\":{\n
    \       \"TOOLTIP\":\"Splunk Splunk URL\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Splunk
    Url  cannot be empty\",\n          \"invalidUrl\": \"URL is invalid\"\n        }\n
    \     },\n      \"PASSWORD\":{\n        \"TOOLTIP\":\"Splunk Password\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Password cannot be empty\"\n        }\n      },\n      \"USER_NAME\":{\n
    \       \"TOOLTIP\":\"Splunk User Name\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"DASHBOARD_ENDPOINT\":{\n        \"TOOLTIP\":\"Splunk DashBoard
    URL\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Splunk DashBoard
    Url cannot be empty\",\n          \"invalidUrl\": \"URL is invalid\"\n        }\n
    \     }\n    },\n    \"STACKDRIVER\":{\n      \"HEADER\": \"Stackdriver\",\n      \"BODY\":\"\",\n
    \     \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User defined name for the Stackdriver
    account\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"KEY_FILE\":{\n        \"TOOLTIP\":\"Stackdriver Encrypted Key
    file\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Encrypted Key
    File cannot be empty\"\n        }\n      }\n    },\n    \"SUMOLOGIC\":{\n      \"HEADER\":
    \"Sumo Logic\",\n      \"BODY\":\"\",\n      \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User
    defined name for the Sumologic account\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"ACCESSID\":{\n        \"TOOLTIP\":\"sumologic Access Id. You can
    generate Access Id (Administration > Security > Access Keys)\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Access Id cannot be empty\"\n        }\n      },\n      \"ACCESSKEY\":{\n
    \       \"TOOLTIP\":\"sumologic Access Key. You can generate Access Id (Administration
    > Security > Access Keys)\",\n        \"VALIDATION_MEeSSAGE\":{\n          \"required\":\"Access
    Key cannot be empty\"\n        }\n      },\n      \"ZONE\":{\n        \"TOOLTIP\":\"sumologic
    Zone\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Zone
    cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Zone
    cannot contain space\",\n      \"required\":\"Zone cannot be empty\",\n      \"startingFromNumber\":
    \"Zone cannot start with numbers\"\n    }\n      }\n    },\n    \n    \"VMWARETANZU\":{\n
    \     \"HEADER\": \"VMWare Tanzu Observability\",\n      \"BODY\":\"\",\n      \"ACCOUNTNAME\":{\n
    \       \"TOOLTIP\":\"User defined name for the VMWare Tanzu Observability account\",\n
    \       \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name
    cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"END_POINT\":{\n        \"TOOLTIP\":\"VMWare Tanzu Observability
    URL\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Url cannot be
    empty\",\n          \"invalidUrl\": \"URL is invalid\"\n        }\n      },\n      \"EMAIL\":{\n
    \       \"TOOLTIP\":\"VMWare Tanzu Observability Email Id\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"email\":\"Email Id is invalid\",\n          \"required\":\"Email Id
    cannot be empty\"\n        }\n      },\n      \"API_TOKEN\":{\n        \"TOOLTIP\":\"VMWare
    Tanzu Observability Personal Access Token\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Api Token cannot be empty\"\n        }\n      }\n    },\n
    \   \"MSTEAMS\":{\n      \"HEADER\": \"Microsoft Teams\",\n      \"BODY\":\"\"\n
    \   },\n    \"SLACK\":{\n      \"HEADER\": \"Slack\",\n      \"BODY\":\"\",\n      \"ACCOUNTNAME\":{\n
    \       \"TOOLTIP\":\"User defined name for the Slack account\",\n        \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n      },\n      \"BOTNAME\":{\n
    \       \"TOOLTIP\":\"Slack Bot Name\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Bot Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Bot
    Name cannot contain space\",\n      \"required\":\"Bot Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Bot Name cannot start with numbers\"\n    }\n      },\n
    \     \"TOKEN\":{\n        \"TOOLTIP\":\"Slack Personal Access Token\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Token cannot be empty\"\n        }\n      },\n      \"SPINNAKERTOGGLE\":{\n
    \       \"TOOLTIP\":\"Switch On this toggle to configure the resource in a gitops
    enabled Spinnaker instance\",\n        \"VALIDATION_MESSAGE\":{}\n      }\n    },\n
    \   \"OPA\":{\n      \"HEADER\": \"OPA\",\n      \"BODY\":\"\",\n      \"ACCOUNTNAME\":{\n
    \       \"TOOLTIP\":\"User defined name for the OPA account\",\n        \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n      },\n      \"ENDPOINT\":{\n
    \       \"TOOLTIP\":\"OPA End Point\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"End
    Point cannot be empty\",\n          \"invalidUrl\": \"URL is invalid\"\n        }\n
    \     }\n    },\n    \"AQUAWAVE\":{\n      \"HEADER\": \"Aqua Wave\",\n      \"BODY\":\"\",\n
    \     \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User defined name for the Aqua Wave
    account\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"USERNAME\":{\n        \"TOOLTIP\":\"Aqua Wave User Name\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"noSpecialCharacters\": \"User Name cannot contain special characters
    other than - and _\",\n          \"cannotContainSpace\":\"User Name cannot contain
    space\",\n          \"required\":\"User Name cannot be empty\",\n          \"startingFromNumber\":
    \"User Name cannot start with numbers\"\n        }\n      },\n      \"TOKEN\":{\n
    \       \"TOOLTIP\":\"Aqua Wave Personal Access Token\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Token cannot be empty\"\n        }\n      }\n    },\n    \"APPSCAN\":{\n
    \     \"HEADER\": \"HCL AppScan\",\n      \"BODY\":\"\",\n      \"ACCOUNTNAME\":{\n
    \       \"TOOLTIP\":\"User defined name for the HCL AppScan account\",\n        \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n      },\n      \"TOKEN\":{\n
    \       \"TOOLTIP\":\"Appscan Personal Access Token\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Token cannot be empty\"\n        }\n      }\n    },\n    \"JFROG\":{\n
    \     \"HEADER\": \"JFrog XRay Scanning\",\n      \"BODY\":\"\",\n      \"ACCOUNTNAME\":{\n
    \       \"TOOLTIP\":\"User defined name for the JFrog XRay Scanning account\",\n
    \       \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name
    cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"ENDPOINT\":{\n        \"TOOLTIP\":\"JFrog URL\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Endpoint cannot be empty\",\n          \"invalidUrl\":
    \"URL is invalid\"\n        }\n      },\n      \"TOKEN\":{\n        \"TOOLTIP\":\"JFrog
    Personal Access Token\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Token
    cannot be empty\"\n        }\n      }\n    },\n    \"PRISMACLOUD\":{\n      \"HEADER\":
    \"Prisma Cloud\",\n      \"BODY\":\"\",\n      \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User
    defined name for the Prisma Cloud account\",\n        \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n      },\n      \"HOSTURL\":{\n
    \       \"TOOLTIP\":\"Prisma Cloud Host URL\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Host URL cannot be empty\",\n          \"invalidUrl\":
    \"URL is invalid\"\n        }\n      },\n      \"APPLICATIONURL\":{\n        \"TOOLTIP\":\"Prisma
    Cloud Application URL\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Application
    URL cannot be empty\",\n          \"invalidUrl\": \"URL is invalid\"\n        }\n
    \     },\n      \"ACCESSKEYID\":{\n        \"TOOLTIP\":\"Prisma Cloud Access Key
    Id\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Access Key Id
    cannot be empty\"\n        }\n      },\n      \"SECRETKEY\":{\n        \"TOOLTIP\":\"Prisma
    Cloud Secret Key\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Secret
    Key cannot be empty\"\n        }\n      }\n    },\n    \"SONARQUBE\":{\n      \"HEADER\":
    \"SonarQube\",\n      \"BODY\":\"\",\n      \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User
    defined name for the SonarQube account\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"HOSTURL\":{\n        \"TOOLTIP\":\"Sonarqube Host URL\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Host URL cannot be empty\",\n          \"invalidUrl\":
    \"URL is invalid\"\n        }\n      },\n      \"TOKEN\":{\n        \"TOOLTIP\":\"Sonarqube
    Personal Access Token\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Token
    cannot be empty\"\n        }\n      }\n    },\n    \"AUTOPILOT\":{\n      \"HEADER\":
    \"Autopilot\",\n      \"BODY\":\"\",\n      \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User
    defined name for the Autopilot account\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"USERNAME\":{\n        \"TOOLTIP\":\" Autopilot User Name\",\n
    \       \"VALIDATION_MESSAGE\":{\n          \"noSpecialCharacters\": \"User Name
    cannot contain special characters other than - and _\",\n          \"cannotContainSpace\":\"User
    Name cannot contain space\",\n          \"required\":\"User Name cannot be empty\",\n
    \         \"startingFromNumber\": \"User Name cannot start with numbers\"\n        }\n
    \     }\n    }\n},\n  \"UNCHANGED_FORM\": \"Form is unchanged. Please make modifications
    in the form to enable the button.\",\n  \"INVALID_FORM\": \"Few fields are mandatory
    or invalid. Please fill the form to enable the button.\",\n  \"NO_WRITE_ACCESS\":
    \"You have only read permission. Please check with your administrator for updating
    permissions.\",\n  \"METRIC_TEMPLATE\": {\n    \"APM_INFRA\": {\n      \"TEMPLATE_NAME\":
    {\n        \"TOOLTIP\": \"The unique name of the template for identification\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"Template Name cannot
    be empty\",\n          \"noSpecialCharacters\": \"Template Name cannot contain special
    characters\",\n          \"cannotContainSpace\": \"Template Name cannot contain
    space\",\n          \"startingFromNumber\": \"Template Name cannot start with number\",\n
    \         \"maxlength\": \"Template name should not have more than 63 characters!\",\n
    \         \"exists\": \"Template already exists\"\n        }\n      },\n      \"APM_MONITORING_PROVIDER\":
    {\n        \"TOOLTIP\": \"Select an APM datasource provider of choice\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"APM_ACCOUNT\": {\n        \"TOOLTIP\": \"Select the account
    of interest in the configured APM datasource \",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"APM_APPLICATION\": {\n        \"TOOLTIP\": \"Select the application
    of interest that you want to monitor\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"APM_API_SELECTION\": {\n        \"TOOLTIP\": \"Select the relevant API metrics
    to monitor \",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"INFRA_MONITORING_PROVIDER\":
    {\n        \"TOOLTIP\": \"Select an INFRA metrics datasource provider of choice\",\n
    \       \"VALIDATION_MESSAGE\": {}\n      },\n      \"INFRA_ACCOUNT\": {\n        \"TOOLTIP\":
    \"Select the account of interest in the configured INFRA metrics datasource \",\n
    \       \"VALIDATION_MESSAGE\": {}\n      },\n      \"INFRA_METRIC_GROUPS\": {\n
    \       \"TOOLTIP\": \"Metrics groups organized as groups for quick overview on
    each infrastructure component\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"FILTER_KEY\": {\n        \"TOOLTIP\": \"A metric scope placeholder to filter
    the scope of the metric\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Filter Key cannot be empty\",\n          \"cannotContainSpace\": \"Filter Key
    cannot contain space\"\n        }\n      },\n      \"BASELINE\": {\n        \"TOOLTIP\":
    \"A unique metric scope to identify the baseline metric\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Baseline cannot be empty\",\n          \"cannotContainSpace\":
    \"Baseline cannot contain space\"\n        }\n      },\n      \"NEW_RELEASE\": {\n
    \       \"TOOLTIP\": \"A unique metric scope to identify the canary metric\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"New Release cannot
    be empty\",\n          \"cannotContainSpace\": \"New Release cannot contain space\"\n
    \       }\n      },\n      \"NORMALIZATION\": {\n        \"TOOLTIP\": \"The selected
    Load metric will be dividing all the metrics to make the metrics more comparable
    to each other\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"THRESHOLD\":
    {\n        \"TOOLTIP\": \"Select 'Hard' mode for a stringent analysis and 'Easy'
    mode for a more lenient analysis\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"SPECIFY_CRITICAL_WATCHLIST\": {\n        \"TOOLTIP\": \"Metrics marked as
    critical, will affect the overall verification score if they fail Metrics marked
    as in watchlist will be shown first in the metric analysis report\",\n        \"VALIDATION_MESSAGE\":
    {}\n      }\n    },\n    \"CUSTOM\": {\n      \"TEMPLATE_NAME\": {\n        \"TOOLTIP\":
    \"The unique name of the template for identification\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Template Name cannot be empty\",\n          \"noSpecialCharacters\":
    \"Template Name cannot contain special characters\",\n          \"cannotContainSpace\":
    \"Template Name cannot contain space\",\n          \"startingFromNumber\": \"Template
    Name cannot start with number\",\n          \"maxlength\": \"Template name should
    not have more than 63 characters!\",\n          \"exists\": \"Template already exists\"\n
    \       }\n      },\n      \"DATA_SOURCE\": {\n        \"TOOLTIP\": \"Select a datasource
    provider of choice\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Data source cannot be empty\"\n        }\n      },\n      \"ACCOUNT\": {\n        \"TOOLTIP\":
    \"Select the account of interest in the configured datasource \",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Account cannot be empty\"\n        }\n      },\n      \"FILTER_KEY\":
    {\n        \"TOOLTIP\": \"Metric Scope Placeholder will be replaced by Baseline
    & New Release values in the Metric Query; For example, Scope Placeholder “pod_name”
    will be replaced by Baseline & New Release values in the metric query avg(container_memory_usage_bytes{pod=~'pod_name',container!=''})
    for getting baseline & New Release metrics data respectively from the monitoring
    provider\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\": \"Filter
    Key cannot be empty\",\n          \"cannotContainSpace\": \"Filter Key cannot contain
    space\"\n        }\n      },\n      \"BASELINE\": {\n        \"TOOLTIP\": \"Unique
    metric scope to identify the baseline metric data\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Baseline cannot be empty\",\n          \"cannotContainSpace\":
    \"Baseline cannot contain space\"\n        }\n      },\n      \"NEW_RELEASE\": {\n
    \       \"TOOLTIP\": \"Unique metric scope to identify the canary metric data\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"New Release cannot
    be empty\",\n          \"cannotContainSpace\": \"New Release cannot contain space\"\n
    \       }\n      },\n      \"ADD_NEW_QUERY\": {\n        \"TOOLTIP\": \"Add New
    Query\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"QUERY_SELECTION\":
    {\n        \"TOOLTIP\": \"Select the relevant metrics to monitor \",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"QUERY_NAME\": {\n        \"TOOLTIP\": \"A meaningful name
    given to a query or a group of similar queries \",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Query Name cannot be empty\"\n        }\n      },\n
    \     \"QUERY_STRING\": {\n        \"TOOLTIP\": \"Query to fetch the metric from
    the data source provider\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Query String cannot be empty\"\n        }\n      },\n      \"RISK_DIRECTION\":
    {\n        \"TOOLTIP\": \"Direction in which the metric difference is allowed to
    expand\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"THRESHOLD\": {\n
    \       \"TOOLTIP\": \"Percentage difference beyond which the Metric is treated
    as FAIL\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"CRITICAL\": {\n
    \       \"TOOLTIP\": \"Critical\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"WATCHLIST\": {\n        \"TOOLTIP\": \"Metrics marked as in watchlist will
    be shown first in the metric analysis report\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"WEIGHT\": {\n        \"TOOLTIP\": \"Numerical importance given
    to a metric; it can range from 0 as lowest to 1 as the highest\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"CRITICALITY\": {\n        \"TOOLTIP\": \"Normal is selected
    to remove the metric from the metric group for score calculation if it has no data,
    Critical is selected to fail the entire analysis if this metric fails or has no
    data, Must Have Data is used to fail a metric if data is missing\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"NAN_STRATEGY\": {\n        \"TOOLTIP\": \"Handles NaN values
    which can occur if there is no data in a particular interval for metric data. \",\n
    \       \"VALIDATION_MESSAGE\": {}\n      }\n    }\n  },\n  \"USAGE_INSIGHTS\":
    {\n    \"APPLICATIONS\": {\n      \"TOOLTIP\": \"Application\"\n    },\n    \"PIPELINES\":
    {\n      \"TOOLTIP\": \"Pipelines\"\n    },\n    \"PIPELINES_WITH_INTELLIGENT_GATES\":
    {\n      \"TOOLTIP\": \"Pipelines with Intelligent Gates\"\n    },\n    \"INTELLIGENT_GATES_BREAKDOWN\":
    {\n      \"TOOLTIP\": \"Intelligent Gates Breakdown\"\n    },\n    \"GATES_USED\":
    {\n      \"TOOLTIP\": \"Gates Used\"\n    },\n    \"USERS\": {\n      \"TOOLTIP\":
    \"Users\"\n    }\n  },\n  \"DELIVERY_INSIGHTS\": {\n    \"PIPELINES\": {\n      \"TOOLTIP\":
    \"Number of pipeline executions over time\"\n    },\n    \"MOST_ACTIVE_PIPELINES\":
    {\n      \"TOOLTIP\": \"Pipelines which have executed most number of times\"\n    },\n
    \   \"MOST_SUCCESSFUL_PIPELINES\": {\n      \"TOOLTIP\": \"Pipelines which have
    successfully executed most number of times\"\n    },\n    \"MOST_FAILED_PIPELINES\":
    {\n      \"TOOLTIP\": \"Pipelines which have failed most number of times\"\n    },\n
    \   \"FASTEST_PIPELINES\": {\n      \"TOOLTIP\": \"Pipelines with fastest execution
    times\"\n    },\n    \"SLOWEST_PIPELINES\": {\n      \"TOOLTIP\": \"Pipelines with
    slowest execution times\"\n    },\n    \"MANUAL_JUDGMENT\": {\n      \"TOOLTIP\":
    \"Pipelines with manual judgement having slowest execution times\"\n    }\n  },\n
    \ \"ACCESS_MANAGEMENT\": {\n    \"ADMINISTRATOR\": {\n      \"INFO\": \"Super Administrator
    Groups will not appear in the dropdown since their Access Permissions cannot be
    modified. Administrators will have full Access to all Resources.\",\n      \"TOOLTIP\":
    \"Groups with Administration Permissions\"\n    },\n    \"USER_ROLE_LISTING\": {\n
    \     \"HEADER\": \"ROLE MANAGEMENT\",\n      \"BODY\": \"Users should be assigned
    user roles only if they need global access to one or more resources.\"\n    },\n
    \   \"USER_ROLE_CREATION\": {\n      \"ROLENAME\": {\n        \"TOOLTIP\": \"\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"Role Name cannot be
    empty\",\n          \"cannotContainSpace\": \"Role Name cannot contain space\",\n
    \         \"noSpecialCharacters\": \"Role Name cannot contain special character\",\n
    \         \"startingFromNumber\": \"Role Name should not start with number\"\n        }\n
    \     },\n      \"USER_GROUPS\": {\n        \"TOOLTIP\": \"\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Groups cannot be empty\"\n        }\n      },\n      \"PERMISSIONS\":
    {\n        \"VALIDATION_MESSAGE\": {\n          \"required\": \"Atleast one feature
    has to be enabled with permissions\"\n        }\n      }\n    },\n    \"FEATURE_VISIBILTY_LISTING\":
    {\n      \"HEADER\": \"FEATURE FLAG MANAGEMENT\",\n      \"BODY\": \"Feature Visibility
    is used for scenarios where one or more user groups need exclusive access to a specific
    feature. For example, the 'Compliance Team' should only access the Policy Management
    feature. Administrators can enable the feature flag for the compliance team user
    group. The feature visibility function will ensure that the policy management feature
    is not visible for all other user groups.\"\n    },\n    \"FEATURE_VISIBILTY_CREATION\":
    {\n      \"ROLENAME\": {\n        \"TOOLTIP\": \"\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Role Name cannot be empty\",\n          \"cannotContainSpace\":
    \"Role Name cannot contain space\",\n          \"noSpecialCharacters\": \"Role Name
    cannot contain special character\",\n          \"startingFromNumber\": \"Role Name
    should not start with number\"\n        }\n      },\n      \"USER_GROUPS\": {\n
    \       \"TOOLTIP\": \"\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Groups cannot be empty\"\n        }\n      },\n      \"PERMISSIONS\": {\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Atleast one feature has to be enabled\"\n        }\n
    \     }\n    }\n  },\n  \"LOG_TEMPLATE\": {\n    \"STRING_PATTERN\": {\n      \"TOOLTIP\":
    \"String Pattern\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"String
    Pattern cannot be empty\"\n      }\n    },\n    \"LOG_TOPICS\": {\n      \"TOOLTIP\":
    \"Strings that appear in logs with their characterization\"\n    },\n    \"LOG_TAGS\":
    {\n      \"TOOLTIP\": \"Create custom tags based on business logic.\"\n    },\n
    \   \"CHARACTERIZATION_TOPIC\": {\n      \"TOOLTIP\": \"Characterization Topic\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Characterization Topic
    cannot be empty\"\n      }\n    },\n    \"TYPE\": {\n      \"TOOLTIP\": \"Type\",\n
    \     \"VALIDATION_MESSAGE\": {}\n    },\n    \"ENABLE_CLUSTER_TAG\": {\n      \"TOOLTIP\":
    \"Create custom tags based on business logic.\",\n      \"VALIDATION_MESSAGE\":
    {}\n    },\n    \"CLUSTER_TAG_STRING\": {\n      \"TOOLTIP\": \"The string pattern
    that appears in logs\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Cluster Tag String cannot be empty\"\n      }\n    },\n    \"CLUSTER_TAG\": {\n
    \     \"TOOLTIP\": \"Cluster Tag\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Cluster Tag cannot be empty\"\n      }\n    },\n    \"LOG_TEMPLATE_NAME\": {\n
    \     \"TOOLTIP\": \"Log Template Name\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Template Name cannot be empty\",\n        \"noSpecialCharacters\": \"Template
    Name cannot contain special characters\",\n        \"cannotContainSpace\": \"Template
    Name cannot contain space\",\n        \"startingFromNumber\": \"Template Name cannot
    start with number\",\n        \"maxlength\": \"Template name should not have more
    than 63 characters!\",\n        \"exists\": \"Template already exists\"\n      }\n
    \   },\n    \"PROVIDER\": {\n      \"TOOLTIP\": \"Data source for Risk Analysis\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Provider cannot be empty\"\n
    \     }\n    },\n    \"LOG_ACCOUNT\": {\n      \"TOOLTIP\": \"Account of the Log
    provider; Refer Integrations tab under Setup\",\n      \"VALIDATION_MESSAGE\": {\n
    \       \"required\": \"Log Account cannot be empty\"\n      }\n    },\n    \"QUERY_FILTER_KEY\":
    {\n      \"TOOLTIP\": \"Unique Key which identify logs to be processed in the Index\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Query Filter Key cannot
    be empty\",\n        \"cannotContainSpace\": \"Query Filter Key cannot contain space\"\n
    \     }\n    },\n    \"BASELINE\": {\n      \"TOOLTIP\": \"Unique value which identify
    baseline logs in the Index\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Baseline cannot be empty\",\n        \"cannotContainSpace\": \"Baseline cannot
    contain space\"\n      }\n    },\n    \"NEW_RELEASE\": {\n      \"TOOLTIP\": \"Unique
    value which identify New Release logs in the Index\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"New Release cannot be empty\",\n        \"cannotContainSpace\":
    \"New Release cannot contain space\"\n      }\n    },\n    \"RESPONSE_KEYWORDS\":
    {\n      \"TOOLTIP\": \"Field name in the Index containing logs to be processed\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Response Keywords cannot
    be empty\",\n        \"cannotContainSpace\": \"Response Keywords cannot contain
    space\"\n      }\n    },\n    \"TIMESTAMP_KEY\": {\n      \"TOOLTIP\": \"Unique
    Key which identify the timestamp for log; this field is optional; by default, it
    is @timestamp for elasticsearch and timestamp for graylog\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"cannotContainSpace\": \"Timestamp Key cannot contain space\"\n      }\n
    \   },\n    \"AUTOBASELINE\": {\n      \"TOOLTIP\": \"ML based learning of the baseline
    from historic analysis\",\n      \"VALIDATION_MESSAGE\": {}\n    },\n    \"CONTEXTUAL_CLUSTER\":
    {\n      \"TOOLTIP\": \"Enable/disable cluster of unexpected events in similar context\",\n
    \     \"VALIDATION_MESSAGE\": {}\n    },\n    \"CONTEXTUAL_WINDOW_SIZE\": {\n      \"TOOLTIP\":
    \"Number of Log events to be seen in a Context. Allowed size in between 25 and 50\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"max\": \"Allowed size is in between 25
    to 50\",\n        \"min\": \"Allowed size is in between 25 to 50\"\n      }\n    },\n
    \   \"INFO_CLUSTER_SCORING\": {\n      \"TOOLTIP\": \"Enabling this option will
    include INFO clusters in scoring\",\n      \"VALIDATION_MESSAGE\": {}\n    },\n
    \   \"SENSITIVITY\": {\n      \"TOOLTIP\": \"Impact of Unexpected Issues on the
    log scoring\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Sensitivity
    cannot be empty\"\n      }\n    },\n    \"SCORING_ALGORITHM\": {\n      \"TOOLTIP\":
    \"Scoring Algorithm for Risk Analysis\",\n      \"VALIDATION_MESSAGE\": {}\n    },\n
    \   \"LOG_GROUP\": {\n      \"TOOLTIP\": \"Group of log streams that share the same
    retention, monitoring, and access control settings\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Log Group cannot be empty\",\n        \"cannotContainSpace\":
    \"Log Group cannot contain space\"\n      }\n    },\n    \"LOG_STREAM\": {\n      \"TOOLTIP\":
    \"Sequence of log events that share the same source\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Log Stream cannot be empty\",\n        \"cannotContainSpace\":
    \"Log Stream cannot contain space\"\n      }\n    },\n    \"REGION\": {\n      \"TOOLTIP\":
    \"Geographic area where AWS data center\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Region cannot be empty\"\n      }\n    },\n    \"INDEX_PATTERN\": {\n      \"TOOLTIP\":
    \"Index containing logs for processing\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Intex Pattern cannot be empty\",\n        \"cannotContainSpace\": \"Intex Pattern
    cannot contain space\"\n      }\n    },\n    \"CUSTOM_REGEX\": {\n      \"TOOLTIP\":
    \"Custom Regular Expression to filter the logs\",\n      \"VALIDATION_MESSAGE\":
    {}\n    },\n    \"REGULAR_EXPRESSION\": {\n      \"TOOLTIP\": \"Sequence of characters
    that specifies a search pattern\",\n      \"VALIDATION_MESSAGE\": {\n        \"cannotContainSpace\":
    \"Regular Expression cannot contain space\"\n      }\n    },\n    \"RESPONSE_KEY\":
    {\n      \"TOOLTIP\": \"Field name in the Index where regex to be searched\",\n
    \     \"VALIDATION_MESSAGE\": {}\n    },\n    \"STREAM_ID\": {\n      \"TOOLTIP\":
    \"The streams are a mechanism to route messages into categories in realtime while
    they are processed\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Stream
    ID cannot be empty\",\n        \"cannotContainSpace\": \"Stream ID cannot contain
    space\"\n      }\n    },\n    \"NAMESPACE\": {\n      \"TOOLTIP\": \"Namespace\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Namespace cannot be empty\",\n
    \       \"cannotContainSpace\": \"Namespace cannot contain space\"\n      }\n    },\n
    \   \"TEST_CASE_KEY\": {\n      \"TOOLTIP\": \"Field in the log index which holds
    the test case names\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Test
    Case Key cannot be empty\",\n        \"cannotContainSpace\": \"Test Case Key cannot
    contain space\"\n      }\n    },\n    \"TEST_SUITE_KEY\": {\n      \"TOOLTIP\":
    \"Field in the log index which  holds the test suite names\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Test Suite Key cannot be empty\",\n        \"cannotContainSpace\":
    \"Test Suite Key cannot contain space\"\n      }\n    }\n  }\n}\n\n"
kind: ConfigMap
metadata:
  name: oes-ui-config
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
---
# Source: oes/templates/configmaps/oes-ui-nginxconf.yaml
apiVersion: v1
data:
  nginx.conf: |
    # For more information on configuration, see:
    #   * Official English Documentation: http://nginx.org/en/docs/
    #   * Official Russian Documentation: http://nginx.org/ru/docs/
  
    user nginx;
    worker_processes auto;
    error_log /var/log/nginx/error.log debug;
    pid /tmp/nginx.pid;
  
    # Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.
    include /usr/share/nginx/modules/*.conf;
  
    events {
        worker_connections 1024;
    }
  
    http {
        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                          '$status $body_bytes_sent "$http_referer" '
                          '"$http_user_agent" "$http_x_forwarded_for"';
  
        access_log  /var/log/nginx/access.log  main;
  
        sendfile            on;
        tcp_nopush          on;
        tcp_nodelay         on;
        keepalive_timeout   65;
        types_hash_max_size 2048;
  
        include             /etc/nginx/mime.types;
        default_type        application/octet-stream;
  
        # Load modular configuration files from the /etc/nginx/conf.d directory.
        # See http://nginx.org/en/docs/ngx_core_module.html#include
        # for more information.
        include /etc/nginx/conf.d/*.conf;
  
        server {
            listen       8080 default_server;
            #listen       [::]:8080 default_server;
            server_name  _;
            root /var/www/html;
  
            # Load configuration files for the default server block.
            include /etc/nginx/default.d/*.conf;
  
            location ^~ /deck/gate/ {
              proxy_pass http://oes-gate:8084/ ;
            }
  
            location ^~ /deck {
              proxy_pass http://spin-deck:9000/ ;
            }
  
            location ^~ /plugin-manifest.json {
              proxy_pass http://spin-deck:9000 ;
            }
  
            location ^~ /gate/ {
              proxy_pass http://oes-gate:8084/ ;
            }
  
            location ^~ /application {
              proxy_pass http://oes-ui:8080 ;
            }
  
            location ^~ /ui {
              try_files $uri $uri/ /ui/index.html;
            }
  
            # Go to Gate if you don't know what to do
            location / {
              proxy_pass http://oes-gate:8084/ ;
            }
  
  
        }
    }

kind: ConfigMap
metadata:
  name: oes-ui-nginxconf
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
---
# Source: oes/templates/configmaps/opa-persist.yaml
apiVersion: v1
data:
  opa-persist.sh: |
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    SAPOR=$(grep oes-sapor /tmp/inst.status | awk '{print $2}')
    PLATFORM=$(grep oes-platform /tmp/inst.status | awk '{print $2}')

    wait_period=$(($wait_period+10))

    if [ "$SAPOR" == "true" ] && [ "$PLATFORM" == "true" ];
    then
      echo \"Spinnaker and OES services are Up and Ready..\"
      set -x
      sleep 5
      BASEURL=$GATEURL
      USERPASS="-u ${GATEUSER}:${GATEPASS}"
      curl $USERPASS $BASEURL/oes/v1/policies/list > listofpolicies.json
      #Get the policy NAMES
      [ -s "listofpolicies.json" ] && (cat listofpolicies.json | jq .[] | jq -r .policyName > policies) || sleep infinity
      #for each NAME
      while read -e name; do
        #Get content
        curl $USERPASS $BASEURL/oes/v1/policy/$name > tmp.json

        #Get Policy ID
        ID=`cat tmp.json|jq .response | jq '.policyId'`
        #Delete Policy ID
        cat tmp.json|jq .response | jq 'del(.policyId)'  > update.json

        #update
        curl $USERPASS -X PUT -H "Content-Type: application/json" -d @update.json $BASEURL/oes/v1/policy/$ID
      done <  policies
      sleep infinity
      #endFOR
    else
      if [ $wait_period -gt 2000 ];
      then
          echo \"Script is timed out as the OES is not ready yet.......\"
          break
      else
          echo \"Waiting for OES services to be ready\"
          sleep 1m
      fi
    fi
    done
kind: ConfigMap
metadata:
  name: opa-persist
---
# Source: oes/templates/configmaps/standard-error-codes.yaml
apiVersion: v1
data:
  standard-error-codes.csv: |-
    standardErrorCodesMapping.ISD-IsEmpty-400-01 = ISD-IsEmpty-400-01 : {0} - {1} is empty. Please provide the {1}.
    standardErrorCodesMapping.ISD-IsNull-400-02 = ISD-IsNull-400-02 : {0} - {1} is null. Please provide the {1}.
    standardErrorCodesMapping.ISD-MustBeAlphanumericName-400-03 = ISD-MustBeAlphanumericName-400-03 : {0} - {1} should be alphanumeric without any special characters !
    standardErrorCodesMapping.ISD-ExceedsMaxStringLength-400-04 = ISD-ExceedsMaxStringLength-400-04 : {0} - {1} should not have more than {2} characters.
    standardErrorCodesMapping.ISD-NotConfigured-400-05 = ISD-NotConfigured-400-05 : {0} - {1} is not configured. Please configure the {1} !
    standardErrorCodesMapping.ISD-PolicyNotProvided-400-06 = ISD-PolicyNotProvided-400-06 : {0} - Policies are mandatory for automated approval gate.
    standardErrorCodesMapping.ISD-EmptyKeyOrValueInJson-400-07 = ISD-EmptyKeyOrValueInJson-400-07 : {0} - {1} is missing in json !
    standardErrorCodesMapping.ISD-UnableToParseJSON-400-08 = ISD-UnableToParseJSON-400-08 : {0} - Unable to parse Json. Please provide a valid json with required data !
    standardErrorCodesMapping.ISD-MustBeANumber-400-09 = ISD-MustBeANumber-400-09 : {0} - {1} must be a number : {2}
    standardErrorCodesMapping.ISD-InvalidURL-400-10 = ISD-InvalidURL-400-10 : {0} - {1} is invalid - {2}
    standardErrorCodesMapping.ISD-BadRequest-400-11 = ISD-BadRequest-400-11 : {0} - {1} {2}
    standardErrorCodesMapping.ISD-Unauthorized-401-01 = ISD-Unauthorized-401-01 : {0} - {1} not authorized. {2}.
    standardErrorCodesMapping.ISD-Unauthorized-401-02 = ISD-Unauthorized-401-02 : {0} - User group not found for user : {1}.
    standardErrorCodesMapping.ISD-NotAdmin-401-03 = ISD-NotAdmin-401-03 : {0} - {1} is not an admin !
    standardErrorCodesMapping.ISD-Forbidden-403-01 = ISD-Forbidden-403-01 : {0} - {1} doesn't have {2} permission on this feature: {3}
    standardErrorCodesMapping.ISD-Forbidden-403-02 = ISD-Forbidden-403-02 : {0} - {1} is invalid.
    standardErrorCodesMapping.ISD-Forbidden-403-03 = ISD-Forbidden-403-03 : {0} - {1} : {2}.
    standardErrorCodesMapping.ISD-Forbidden-403-04 = ISD-Forbidden-403-04 : {0} - {1} namespace is not accessible for given kubeconfig account {2}.
    standardErrorCodesMapping.ISD-IsNotFound-404-01 = ISD-IsNotFound-404-01 : {0} - {1} not found : {2}
    standardErrorCodesMapping.ISD-NoData-404-02 = ISD-NoData-404-02 : {0} - No data found for {1}
    standardErrorCodesMapping.ISD-DoesNotExist-404-03 = ISD-DoesNotExist-404-03 : {0} - {1} does not exist {2}.
    standardErrorCodesMapping.ISD-IsNotFound-404-04 = ISD-IsNotFound-404-04 : {0} - {1} not found {2}.
    standardErrorCodesMapping.ISD-AlreadyExists-409-01 = ISD-AlreadyExists-409-01 : {0} - {1} already exists: {2}
    standardErrorCodesMapping.ISD-FailedToDelete-412-01 = ISD-FailedToDelete-412-01 : {0} - Unable to delete {1} as {1} is already in use !
    standardErrorCodesMapping.ISD-FailedToDeletePolicy-412-02 = ISD-FailedToDeletePolicy-412-02 : {0} - Unable to delete policy as it is already in use for {1} gate !
    standardErrorCodesMapping.ISD-FailedToUpdate-412-03 = ISD-FailedToUpdate-412-03 : {0} - Unable to update {1} as {1} is already in use !
    standardErrorCodesMapping.ISD-InvalidURL-422-01 = ISD-InvalidURL-422-01 : {0} - The requested {1} URL is invalid !
    standardErrorCodesMapping.ISD-ConnectionOrAuthenticationFailed-422-02 = ISD-ConnectionOrAuthenticationFailed-422-02 : {0} - {1} connection or authentication failed : HTTP status {2}
    standardErrorCodesMapping.ISD-InvalidCredentials-422-03 = ISD-InvalidCredentials-422-03 : {0} - {1} credentials are invalid !
    standardErrorCodesMapping.ISD-InvalidEndpoint-422-04 = ISD-InvalidEndpoint-422-04 : {0} - {1} endpoint is invalid !
    standardErrorCodesMapping.ISD-InvalidEndpointOrCredentials-422-05 = ISD-InvalidEndpointOrCredentials-422-05 : {0} - {1} endpoint or credentials are invalid !
    standardErrorCodesMapping.ISD-UsernameOrPasswordIsBlank-422-06 = ISD-UsernameOrPasswordIsBlank-422-06 : {0} - {1} is blank but {2} is supplied. Both must be present or blank.
    standardErrorCodesMapping.ISD-UnknownDatasource-422-07 = ISD-UnknownDatasource-422-07 : {0} - Unknown datasource or datasource is currently not supported : {1}
    standardErrorCodesMapping.ISD-InvalidProvider-422-08 = ISD-InvalidProvider-422-08 : {0} - {1} provider is invalid !
    standardErrorCodesMapping.ISD-InvalidPath-422-09 = ISD-InvalidPath-422-09 : {0} - {1} path is invalid !
    standardErrorCodesMapping.ISD-UnableToGenerate-422-10 = ISD-UnableToGenerate-422-10 : {0} - Unable to generate {1} !
    standardErrorCodesMapping.ISD-FailedToCreate-422-11 = ISD-FailedToCreate-422-11 : {0} - Failed to create {1}.
    standardErrorCodesMapping.ISD-EndpointIsBlank-422-12 = ISD-EndpointIsBlank-422-12 : {0} - {1} endpoint is blank. {2} must be blank.
    standardErrorCodesMapping.ISD-ConnectionOrAuthenticationFailed-422-13 = ISD-ConnectionOrAuthenticationFailed-422-13 : {0} - {1} connection or authentication failed.
    standardErrorCodesMapping.ISD-FailedToUpdate-422-14 = ISD-FailedToUpdate-422-14 : {0} - Failed to Update {1}.
    standardErrorCodesMapping.ISD-FailedToDelete-422-15 = ISD-FailedToDelete-422-15 : {0} - Failed to Delete {1}.
    standardErrorCodesMapping.ISD-DoesNotMatch-422-16 = ISD-DoesNotMatch-422-16 : {0} - {1} does not match {2}.
    standardErrorCodesMapping.ISD-DoesNotExist-422-17 =  ISD-DoesNotExist-422-17 : {0} - {1} does not exist {2}.
    standardErrorCodesMapping.ISD-DoesNotSupport-422-18 = ISD-DoesNotSupport-422-18 : {0} - {1} does not support {2}.
    standardErrorCodesMapping.ISD-UnableToVerify-422-19 = ISD-UnableToVerify-422-19 : {0} - Unable to verify {1}.
    standardErrorCodesMapping.ISD-FailedToInitialize-422-20 = ISD-FailedToInitialize-422-20 : {0} - Failed to initialize {1}.
    standardErrorCodesMapping.ISD-DoesNotHave-422-21 = ISD-DoesNotHave-422-21 : {0} - {1} does not have {2}.
    standardErrorCodesMapping.ISD-UnableToAddStage-424-01 = ISD-UnableToAddStage-424-01 : {0} - Unable to add stage in {1} !
    standardErrorCodesMapping.ISD-UnableToDelete-424-02 = ISD-UnableToDelete-424-02 : {0} - Unable to delete {1} while analysis is under process !
    standardErrorCodesMapping.ISD-UnableToDelete-424-03 = ISD-UnableToDelete-424-03 : {0} - Unable to delete {1} as already in use {2}
    standardErrorCodesMapping.ISD-UnableToDelete-424-04 = ISD-UnableToDelete-424-04 : {0} - Unable to delete {1} as it is involved in multi-service analysis !
    standardErrorCodesMapping.ISD-ShouldBeNumber-500-01 = ISD-ShouldBeNumber-500-01 : {0} - {1} should be an number !
    standardErrorCodesMapping.ISD-ShouldBePositiveNumber-500-02 = ISD-ShouldBePositiveNumber-500-02 : {0} - {1} should be an positive number !
    standardErrorCodesMapping.ISD-UnableToFetch-500-03 = ISD-UnableToFetch-500-03 : {0} - Unable to fetch {1} from database. Please try after some time !
    standardErrorCodesMapping.ISD-UnableToCreate-500-04 = ISD-UnableToCreate-500-04 : {0} - Unable to create {1} !
    standardErrorCodesMapping.ISD-UnableToDelete-500-05 = ISD-UnableToDelete-500-05 : {0} - Unable to delete {1} !
    standardErrorCodesMapping.ISD-UnableToUpdate-500-06 = ISD-UnableToUpdate-500-06 : {0} - Unable to update {1} !
    standardErrorCodesMapping.ISD-UnableToValidate-500-07 = ISD-UnableToValidate-500-07 : {0} - Unable to validate {1} !
    standardErrorCodesMapping.ISD-ServiceUnavailable-503-01 = ISD-ServiceUnavailable-503-01 : {0} - {1} : {2}
    standardErrorCodesMapping.ISD-ServiceUnavailable-503-02 = ISD-ServiceUnavailable-503-02 : {0} - {1}
    standardErrorCodesMapping.ISD-UnKnowHostException-503-03 = ISD-UnKnowHostException-503-03 : {0} - {1}
kind: ConfigMap
metadata:
  labels:
    app: oes
  name: standard-error-codes-config
---
# Source: oes/templates/customstages/ansible-config.yaml
apiVersion: v1
data:
  run.sh: |
        #!/bin/bash

        file="$inventoryfile"

        if test -z "$file"

        then

        echo "No Inventory file specified taking default values"

        exit 1

        else

        echo "Inventory file specified Manually"

        ssh-keygen -t rsa -N "" -f ~/.ssh/id_rsa

        git clone "https://"$gitusername":"$gitpassword"@"$gitrepo""

        host1=$(head -1 $file)

        ip=$(cat $file | head -2 | tail -1)

        host2=$(echo $host1 | cut -d "[" -f2 | cut -d "]" -f1)

        sshpass -p "$userpassword" ssh-copy-id -o StrictHostKeyChecking=no $nodeuser@$ip

        cat $file >> /etc/ansible/hosts

        touch /etc/ansible/group_vars/$host2

        echo "ansible_ssh_user: $nodeuser" > /etc/ansible/group_vars/$host2

        ansible -i /etc/ansible/hosts $host2 -m ping

        ansible-playbook --syntax-check "$ansiblefile"

        ansible-playbook "$ansiblefile"

        fi

kind: ConfigMap
metadata:
  name: ansible-config
---
# Source: oes/templates/customstages/custom-notification-email-config.yaml
apiVersion: v1
data:
  run.sh: |
    #!/bin/sh
    #Install SSMTP
    apk add ssmtp > /dev/null
    #Removing default file
    cat /dev/null >/etc/ssmtp/ssmtp.conf
    #Add configuration in ssmtp.conf file
    ssmtpemail=$(echo "$ssmtpemail" | tr -d [:space:])
    email=$(echo "$email"| tr -d [:space:])
    body=$(echo $body | tr -d [:space:])
    if [ -z $ssmtpemail ]
    then
    echo "not specified smtp email"
    exit 5
    else
    if [ -z $email ]
    then
    echo "not specified the sender email address"
    exit 5
    else
    if [ -z "$body" ]
    then
    echo "not specified the Email body"
    exit 5
    else
    cat <<EOT>> /etc/ssmtp/ssmtp.conf
    root=$ssmtpemail
    mailhub=smtp.gmail.com:587
    AuthUser=$ssmtpemail
    AuthPass=$emailpassword
    UserTLS=YES
    UseSTARTTLS=YES
    rewriteDomain=gmail.com
    hostname=localhost
    FromLineOverride=YES
    EOT
    #add body to file
    touch body.txt
    cat <<EOT>> body.txt
    $body
    EOT
    export MAILFROM="$ssmtpemail"
    export MAILTO="$email,$ccmail"
    export SUBJECT="$subject"
    export BODY="body.txt"
    (
    echo "From: $MAILFROM"
    echo "To: $MAILTO"
    echo "Subject: $SUBJECT"
    cat $BODY
    ) | /usr/sbin/sendmail $MAILTO
    fi
    fi
    fi
kind: ConfigMap
metadata:
  name: email-config
---
# Source: oes/templates/customstages/opsmx-terraspin-backend-config.yaml
apiVersion: v1
data:
  gcloudauth.sh: |
    #!/bin/bash
    #set -x
    jsonkey=$(ls /home/terraspin/opsmx/gcp/)
    if [ -z "$jsonkey" ]
            then
              echo "gcp service account is not configured in backend"
                exit 5
     else
        echo "Authenticating to gcp using service account"

         saemail=$(cat /home/terraspin/opsmx/gcp/$jsonkey | jq -r '.client_email')

          if [ "$?" -eq 0 ]
          then

    export GOOGLE_APPLICATION_CREDENTIALS=/home/terraspin/opsmx/gcp/$jsonkey
    gcloud auth activate-service-account $saemail --key-file=/home/terraspin/opsmx/gcp/$jsonkey > /dev/null


    bash run.sh
    else

    echo "service email is missing in the json key which you stored in backend"
    exit 5
    fi
    fi
  role.sh: "#!/bin/bash\nrole=$awsrole\nns=$namespace\nif [ -z \"$role\" ]\nthen\n
    \   echo \"not provided account name\"\n    exit 5\nelse\n    echo \"Checking
    the account validity\"\n    curl -soq GET \"http://spin-clouddriver-ro.$ns.svc.cluster.local:7002/credentials/$role\"
    --header \"Content-Type: application/json\" > roleinfo.json\n    if [ \"$?\" -eq
    0 ]\n    then\n        ##Extract the assume role from the account info Json using
    the jq\n        awsregion=$(cat roleinfo.json  | jq -r '.regions[].name')\n        awsassumeRole=$(cat
    roleinfo.json | jq -r '.assumeRole')\n        awsaccountId=$(cat roleinfo.json
    | jq -r '.accountId')\n        ##Get the Account Credentials using the Assume
    role \n        aws sts assume-role --role-arn \"arn:aws:iam::$awsaccountId:$awsassumeRole\"
    --role-session-name AWSCLI-Session > creds.json\n        ##Get the Account Credentials
    using the Assume role\n        awsaccesskey=$(cat creds.json | jq -r '.Credentials.AccessKeyId')\n
    \       awssecretkey=$(cat creds.json | jq -r '.Credentials.SecretAccessKey')\n
    \       awssessiontoken=$(cat creds.json | jq -r '.Credentials.SessionToken')\n
    \       export AWS_ACCESS_KEY_ID=$awsaccesskey\n        export AWS_SECRET_ACCESS_KEY=$awssecretkey\n
    \       export AWS_SESSION_TOKEN=$awssessiontoken\n        export AWS_REGION=$awsregion\n
    \       #aws configure list\n        bash run.sh\n    else\n        echo \"In-Valid
    account $role\"\n        exit 1\n    fi\nfi\n"
  run.sh: "#!/bin/bash \n#set -x\n\nterraformcommand=\"$command\"\nscriptact=$(echo
    \"$scriptaccount\" | tr -d [:space:])\ntfrepo=$(echo \"$repo\" | tr -d [:space:])\ntflocation=$(echo
    \"$location\" | tr -d [:space:])\noverride=$(echo \"$overridefile\" | tr -d [:space:])\nTFCMD=$(echo
    \"$terraformcommand\" | tr -d [:space:])\nstatefolder=$(echo \"$staterep\" | awk
    -F/ '{print $2}' | sed 's/\\.git\\>//g')\n\necho \"-------- Terraform Command
    ----------\"\necho \"            $TFCMD                   \"\necho \"-------------------------------------\"\n\nif
    [ -z $scriptact ]\nthen\n\techo \" Not Specified the Tf script account \"\n\texit
    1\nelse\n\tcheckaccount=$(cat /home/terraspin/opsmx/app/config/artifactaccounts.json
    | jq -r '.[][] | select (.accountname == \"'$scriptact'\")')\n\tif [ -z \"$checkaccount\"
    ]\n\tthen\n\t\techo \"Script Account is Not there artifactaccounts.json\"\n\t\texit
    1\n\telse\n\t\techo \"Script account is located in artifactaccounts.json\"\n\t\tusername=$(cat
    /home/terraspin/opsmx/app/config/artifactaccounts.json | jq -r '.[][] | select
    (.accountname == \"'$scriptact'\")|.username')\n\t\tpassword=$(cat /home/terraspin/opsmx/app/config/artifactaccounts.json
    | jq -r '.[][] | select (.accountname == \"'$scriptact'\")|.password')\n\t\thost=$(cat
    /home/terraspin/opsmx/app/config/artifactaccounts.json | jq -r '.[][] | select
    (.accountname == \"'$scriptact'\")|.host')\n                echo host $host\n\t\thosturl=$(echo
    ${host##*/})\n\t\tif [[ \"$tfrepo\" == *//* ]]\n                then\n                        echo
    \"checking the input Artifact repo  and branch\"\n                        tfbranch=$(echo
    $tfrepo | awk -F// '{print $2}')\n                        tfrepo=$(echo $tfrepo
    | awk -F// '{print $1}')\n                                if [[ \"$tfrepo\" ==
    */* ]] && [[ $tfrepo == *\".git\"* ]]\n                                then\n
    \                                       echo \"valid Artifact repo  name\"\n                                        if
    [ -z $tfbranch ]\n                                        then\n                                                 echo
    \"invalid input format of Artifact repo specify as ....> org/repo.git//branch\"\n
    \                                                exit 5\n                                         else\n
    \                                                echo \"Artifact repo Branch specified
    as $tfbranch\"\n                                         fi\n                                 else\n
    \                                        echo \"In valid repo name format of Artifact
    repo should be....> Org/repo.git \"\n                                         exit
    5\n                                 fi\n                         \n                 else\n
    \                        echo \"invalid input format of Artifact repo specify
    as ....>  org/repo.git//branch\"\n                         exit 5\n                 fi\n\tfi\nfi\n\n\n###################################################\n#TERRADORM
    COMMANDS FUNCTIONALITY \n###################################################\nif
    [ $TFCMD == \"plan\" ]\nthen\n    echo \"Plan executing............\"\n    cd
    $HOME\n    git clone https://$username:$password@$hosturl/$tfrepo workspace -b
    $tfbranch > /dev/null\n    cd workspace/$tflocation\n    TF_WORKSPACE=$TF_WORKSPACE
    terraform init\n    if [ $? -eq 0 ]; then\n       echo \"Terraform Init Completed\"\n
    \   else \n        echo \"$TF_WORKSPACE workspace does not exists... creating
    newly\"\n        terraform workspace new $TF_WORKSPACE\n        TF_WORKSPACE=$TF_WORKSPACE
    terraform init -reconfigure\n        echo \"Terraform Init Completed\"\n    fi\n
    \   terraform validate\n    if [ -z $override ]\n    then\n#\t    echo \"Not Specified
    the Override File\"\n\t    terraform plan -out=terraform.plan\n    else\n\t    terraform
    plan -var-file=$override -out=terraform.plan\n    fi\n    if [ $? -eq 0 ]; then\n\t
    \   echo \"Terraform Plan Completed\"\n    \n    else\n\t    echo Terraform Plan
    FAILED\n\t    exit 5\n    fi\n\nelif [ $TFCMD == \"apply\" ]\nthen\n    echo \"Apply
    executing...........................\"\n     cd $HOME\n     git clone https://$username:$password@$hosturl/$tfrepo
    workspace -b $tfbranch > /dev/null\n     cd workspace/$tflocation\n     TF_WORKSPACE=$TF_WORKSPACE
    terraform init\n     terraform validate\n     #terraform plan -var-file=$override
    -out terraform.plan\n\tif [ -z $override ]\n\tthen\n\t\t#echo \"Not Specified
    the Override File\"\n\t\tterraform apply -auto-approve\n\t\tif [ $? -eq 0 ]; then\n\t\t\techo
    \"------------------------------------------------\"\n\t\t\techo \"           Terraform
    Apply Completed            \"\n\t\t\techo \"------------------------------------------------\"\n\t\t\techo
    \"SPINNAKER_PROPERTY_TERRAFORMAPPLY=\"COMPLETED\"\"\n\t\t\tFILE=outputs.tf\n\t\t\tif
    test -f \"$FILE\"; then\n\t\t\t\techo \"$FILE exists.\"\n\t\t\t\tterraform output
    > outputvariables\n\t\t\t\tcat outputvariables | tr -d ' ' | tr -d '\"'\n\t\t\tfi\n\t\telse\n\t\t\techo
    Terraform Apply  FAILED\n                        echo \"SPINNAKER_PROPERTY_TERRAFORMAPPLY=\"FAILED\"\"\n
    \                       exit 5\n\t\tfi\n\n\telse\n\t\tterraform apply -var-file=$override
    -auto-approve\n\t\tif [ $? -eq 0 ]; then\n                        echo \"------------------------------------------------\"\n
    \                       echo \"           Terraform Apply Completed            \"\n
    \                       echo \"------------------------------------------------\"\n
    \                       echo \"SPINNAKER_PROPERTY_TERRAFORMAPPLY=\"COMPLETED\"\"\n\t\t\tFILE=outputs.tf\n\t\t\tif
    test -f \"$FILE\"; then\n\t\t\t\techo \"$FILE exists.\"\n\t\t\t\tterraform output
    > outputvariables\n\t\t\t\tcat outputvariables | tr -d ' ' | tr -d '\"'\n\t\t\tfi\n\t\telse\n
    \                       echo Terraform Apply  FAILED\n                        echo
    \"SPINNAKER_PROPERTY_TERRAFORMAPPLY=\"FAILED\"\"\n                        exit
    5\n                fi\n\n\n\tfi\n\nelif [ $TFCMD == \"destroy\" ]\nthen\n    echo
    \"Destroy executed\"\n\t\t     cd $HOME\n                     git clone https://$username:$password@$hosturl/$tfrepo
    workspace -b $tfbranch > /dev/null\n                     cd workspace/$tflocation\n
    \                    TF_WORKSPACE=$TF_WORKSPACE terraform init\n                     terraform
    validate\n\n                        if [ -z $override ]\n                        then\n
    \                             #  echo \"Not Specified the Override File\"\n                                terraform
    destroy -auto-approve\n\t\t\t\tif [ $? -eq 0 ]; then\n\t\t\t\t\techo \"------------------------------------------------\"\n\t\t\t\t\techo
    \"           Terraform Destroy Completed            \"\n\t\t\t\t\techo \"------------------------------------------------\"\n\t\t\t\t\techo
    \"SPINNAKER_PROPERTY_TERRAFORMDESTROY=\"COMPLETED\"\"\n\t\t\t\telse\n\t\t\t\t\techo
    \"Terraform Destroy Failed\"\n\t\t\t\t\texit 5\n\t\t\t\tfi\n\t\t\telse\n                                terraform
    destroy -var-file=$override -auto-approve\n\t\t\t\tif [ $? -eq 0 ]; then\n                                        echo
    \"------------------------------------------------\"\n                                        echo
    \"           Terraform Destroy Completed          \"\n                                        echo
    \"------------------------------------------------\"\n                                        echo
    \"SPINNAKER_PROPERTY_TERRAFORMDESTROY=\"COMPLETED\"\"\n                                else\n
    \                                       echo \"Terraform Destroy Failed\"\n\t\t\t\t\texit
    5\n                                fi\n\n                        fi\nelse\n    echo
    \"Not able to validate Terraform state \"plan\" or \"apply\" or \"destroy\" \"\nfi\n"
kind: ConfigMap
metadata:
  name: opsmx-terraspin-backend-config
---
# Source: oes/templates/customstages/updatepr-config.yaml
apiVersion: v1
data:
  run.sh: "#!/bin/sh\naccesstoken=$(echo \"$accesstoken\" | tr -d [:space:])\nmethod=$(echo
    \"$method\"| tr -d [:space:])\nurl=$(echo $url | tr -d [:space:])\nif [ -z $accesstoken
    ]\nthen\n\techo \"not specified accesstoken\"\n\texit 5\nelse\n\tif [ -z $method
    ]\n\tthen\n\t\techo \"not specified the method ....POST\"\n\t\texit 5\n\telse\n\t\tif
    [ -z \"$url\" ]\n\t\tthen\n\t\t       echo \"not specified the URL\"\n\t\t       exit
    5\n\t       else\n\t\t       curl -s -H \"Authorization: token $accesstoken\"
    -X $method -d '{\"body\":\"'\"$payload\"'\"}' \"$url\"\n\t\t       if [ $? -eq
    0 ]\n\t\t       then\n\t\t\t       echo \"curl call succeded\"\n\t\t       else\n\t\t\t
    \      echo Curl call not succeded with the URL $url\n\t\t\t       exit 5\n\t\t
    \      fi\n\t       fi\n       fi\nfi\n"
kind: ConfigMap
metadata:
  name: updatepr-config
---
# Source: oes/templates/forwarder/oes-forwarder-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: opsmx-controller-controller1
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
data:
  configFile: |
    serviceHostname: opsmx-controller-controller1
    agentHostname: controller.exampleopsmx.net
    remoteCommandHostname: controller.exampleopsmx.net
    controlHostname: opsmx-controller-controller1
    #agentAdvertisePort: "443"
    serviceAuth:
      currentKeyName: "public.pem"
      headerMutationKeyName: "public.pem"
    services:
      outgoingServices:
        - name: front50
          type: front50
          enabled: true
          config:
            url: http://spin-front50:8080
        - name: fiat
          type: fiat
          enabled: true
          config:
            url: http://spin-fiat:7003
      incomingServices:  # This part is to be automated in the next version. For now, the agent MUST be called opsmx-agent
        - name: agent-clouddriver
          serviceType: clouddriver
          port: 7002
          useHTTP: true
          destination: opsmx-agent
          destinationService: agent-clouddriver
---
# Source: oes/templates/pipeline-promotion/pipe-promot-config-cm.yaml
apiVersion: v1
data:
  repo.properties: |
    #properties file for pipeline promotion scripts

    # Common Stuff
    repo_type=git
    repo_name=repo_name
    root_folder=pipeline/
    #S3 Specific
    export AWS_ACCESS_KEY_ID=access_key
    export AWS_SECRET_ACCESS_KEY=secret_key

    #git mandatory patameters
    git_url=example.repo.com
    git_project=project_name
    git_user=username
    git_branch=samplerepo
    #git_password=
    #API
    git_api_url=https://api.github.com/repos  # bitbucket

    #Auto PR requirements
    merge_branch=false
    auto_merge=false
    git_approve_user=approver_user
    target_branch=master

    #optional
    #git_user_email=krish@company.com

    #delete pipeLine
    delete_on_sync_spin=
    delete_on_sync_repo=
    #git_approve_user_password=
    #git_secret_sshkey=
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: pipe-promot-config
---
# Source: oes/templates/pipeline-promotion/pipe-promot-scripts-cm.yaml
apiVersion: v1
data:
  bitbucket.sh: "#!/bin/bash\n\n#this script funtions only work for bitbucket central
    repository\n\n#this script funtions only work for git repo\n#env variables needed
    for this to work are as below\n#***git_url=\"example.bitbucket.com\" make sure
    you dont add http/https or / in the url\n#****git_repo=\"pipelinepromotion\" repo
    to be pushed/download pipeline json files from\n#***git_project=\"kes\" project
    key is needed to clone/push/pull merge code\n#***git_user=\"tes.user\" user is
    needed for cloning and pusing changes (stash does not support only access key)\n#***git_branch=\"testbranch\"
    the branch to which the code should be merged with\n#***merge_branch=false if
    true then provide all the below env variables\n#   git_secret_token=\"dafjaljoahfoasjoijso\"
    needed to create pull requests should be the git_users secret token\n#   git_pr_token=\"slkdfjaljoajfopaj\"
    this is approver token to approve pull requests / you can also provide approver
    password here.\n#   git_approve_user=\"test.approver\"  username of the pull request
    approver\n#   git_password=\"adjoowddaw\" make sure your password does not include
    special characters like # @*/. special characters cause git clone command to fail
    with https\n#\n#  repo_type=\"stash\" for selfhosted bitbucket server please use
    stash as repo type\n#***root_folder=\"path/to/pipeline-promotion/folder\" folder
    to be selected in the repo to which the pipeline jobs to be pushed\n#***command=upload
    for running specific job -\n#                                         upload -
    to upload spinnaker pipeline json files to repo\n#                                         download
    - to download pipeline json file from repo and apply on spinnaker\n#***spinnaker_applications=\"testapp,sampleapp\"
    application needed to collect the pipeline information\n#spinnaker_pipelines=\"\"
    provide pipelines to be collected, if nothing given, all the pipelines of the
    application are collected\n#git_secret_sshkey=\"sshkey\" ssh key if you want to
    clone repo with ssh protocol\n\n# note *** env variables are mandatory to work
    with the script\n\nsource scripts/git.sh\ngit_bitbucket_api=$git_api_url\npr_id=0\napprove_pr_bitbucket(){\n
    \ approve_req=$(curl -X POST -u $git_approve_user:$git_pr_token \\\n  $git_bitbucket_api${git_project}/${git_repo}/pullrequests/${pr_id}/approve
    -o -I -L -s -w \"%{http_code}\")\n  echo $approve_req\n  if [[ $approve_req ==
    \"200\" ]];then\n    echo \"merge request approved successfully\"\n  else\n    echo
    \"FAIL: failed to approve the request \"\n    exit 1\n  fi\n}\n\nmerge_pr_bitbucket(){\n\n
    \ merge_req=$(curl  -X POST -u $git_user:$git_secret_token   \\\n  $git_bitbucket_api${git_project}/${git_repo}/pullrequests/${pr_id}/merge
    -o -I -L -s -w \"%{http_code}\")\n  echo $merge_req\n  if [[ $merge_req == 200
    \ ]]; then\n    echo \"merged pr successfully\"\n  elif [[ $merge_req == 202 ]];
    then\n    echo \"merging is in progress will be merged in less than a min\"\n
    \ else\n    echo \"FAILED: failed to merge $merge_pr\"\n    exit 1\nfi\n}\ncreate_pr_bitbucket(){\n\n\tlocal
    output=$(curl  -X POST -H \"Content-Type: application/json\" -u $git_user:$git_secret_token
    \  $git_bitbucket_api${git_project}/${git_repo}/pullrequests -d '{\n    \"title\":
    \"merging '$git_branch' to '$target_branch'\",\n    \"source\": {\n            \"branch\":
    {\n                \"name\": \"'$git_branch'\"\n            }\n        },\n        \"destination\":
    {\n            \"branch\": {\n                \"name\": \"'$target_branch'\"\n
    \           }\n        }\n}')\n  echo $output\n  echo $output > pr_response.json\n
    \ grep  \"There are no changes to be pulled\" pr_response.json\n  if [ \"$?\"
    = 0 ]\n  then\n    echo \"master branch is already up-to-date\"\n    exit 0\n
    \ else\n    pr_id=$(cat  pr_response.json| jq '(.id)' | sed 's/\\\"//g')\n    if
    [ $? = 0 ]; then\n      echo \"successfully created pull request \"\n      #rm
    -f pr_response.json\n    else\n      echo \"ERROR: failed to raise pull request
    $output\"\n      exit 1\n  fi\nfi\n}\n\nsync_spin_to_bitbucket(){\n  setup_git\n
    \ sync_spin_to_git\n  if [[ $merge_branch == \"true\" && $target_branch != \"\"
    && ($git_branch != $target_branch)  ]];then\n    if [[ $git_api_url_port != \"\"
    ]];then\n      git_bitbucket_api=$git_bitbucket_api:$git_api_url_port\n      create_pr_bitbucket\n
    \     if [[ $auto_merge == \"true\" ]]; then\n        approve_pr_bitbucket\n        sleep
    5\n        merge_pr_bitbucket\n      fi\n    else\n      create_pr_bitbucket\n
    \     if [[ $auto_merge == \"true\" ]]; then\n        approve_pr_bitbucket\n        sleep
    5\n        merge_pr_bitbucket\n      fi\n    fi\n  fi\n}\n"
  deployer.sh: "#!/bin/bash\necho \"In deployer.sh\"\nSBASE=scripts\nsource config/repo.properties\nBRANCH_NAME_UI=$(echo
    $branch_ui | sed 's/[][]//g')\necho $BRANCH_NAME_UI\nif [ -z \"$BRANCH_NAME_UI\"
    ]\n        then\n           echo \"Not Provided the Branch in the spinnaker UI....Continuing
    with the default branch specified in configmap\"\n           echo $git_branch\n
    else\n      echo \"Provided the User defined Branch in spinnaker UI\"\n      git_branch=$BRANCH_NAME_UI\n
    \     echo $git_branch\nfi\nROOT_FOLDER_UI=$(echo $rootfolder_ui | sed 's/[][]//g')\necho
    $ROOT_FOLDER_UI\nif [ -z \"$ROOT_FOLDER_UI\" ]\n        then\n           echo
    \"Not Provided the Save Path in the spinnaker UI....Continuing with the default
    path specified in configmap\"\n           echo $root_folder\n else\n      echo
    \"Provided the User defined Branch in spinnaker UI\"\n      root_folder=$ROOT_FOLDER_UI\n
    \     echo $root_folder\nfi\n\nsource $SBASE/spin.sh\nsource $SBASE/stash.sh\nsource
    $SBASE/s3.sh\nsource $SBASE/github.sh\nsource $SBASE/bitbucket.sh\necho \"Sourcing
    complete\"\nsync_repo_from_spinnaker(){\n\tif [[ $repo_type = \"s3\" ]];\n \tthen\n\t
    \  upload_spin_to_s3\n\telif [[ $repo_type = \"stash\" ]]; then\n\t\tsync_spin_to_stash\n
    \ elif [[ $repo_type == \"bitbucket\" ]]; then\n\t\tsync_spin_to_bitbucket\n\telif
    [[ $repo_type = \"git\" ]]; then\n\t\tsync_spin_to_github\n\telif [[ $repo_type
    = \"gitea\" ]]; then\n                sync_spin_to_github\n\telse\n\t\techo \"Not
    specified Repo type\"\n\t\texit 5\n\tfi\n}\nsync_spinnaker_from_repo(){\n\tif
    [[ $repo_type = \"s3\" ]];\n \tthen\n\t   sync_from_s3_spin\n\telif [[ $repo_type
    = \"stash\" || $repo_type = \"git\" || $repo_type = \"bitbucket\" ]]; then\n\t\tsync_git_to_spin\n\telif
    [[ $repo_type = \"gitea\" ]]; then\n\t\tsync_git_to_spin\n\tfi\n}\n\nif [[ \"$command\"
    == \"download\" ]]; then\n\tsync_spinnaker_from_repo\nelif [[ \"$command\" ==
    \"upload\" ]]; then\n        echo \"executing upload\"\n\t#statement\n\tsync_repo_from_spinnaker\nelse\n\techo
    \"ERROR: unknown command\"\n\nfi\necho \"Done executing\"\n"
  git.sh: "#!/bin/bash\nsource scripts/spin.sh\n\ngit_repo=$repo_name\ntempdir=\"/tmp/\"\npull_requred=false\nif
    [[ $git_branch == \"\" ]]\nthen\n  git_branch=\"master\"\nfi\nsetup_git() {\n
    \ echo \"Setting up the Git \"\n  local name=${git_user:-spinnaker}\n  local email=${git_user_email:-phani@opsmx.io}\n
    \ git config --global user.email \"$email\"\n  git config --global user.name \"$name\"\n}\nvalidate_clone()
    {\n\tif [ $? == 0 ]\n\tthen\n\t\techo \"Cloning done ${git_repo}\"\n\telse\n\t\techo
    \"Cloning failed with repo ${git_repo}, Please check credentials and repo access....\"\n\t\texit
    5\n\tfi\n}\ngit_clone_http() {\n  echo \"cloning $git_project/$git_repo over https\"\n
    \ if [[ $repo_type == \"git\" || $repo_type == \"bitbucket\" ]]; then\n    clone_result=$(git
    clone https://$git_user:${git_secret_token}@${git_url}/${git_project}/${git_repo}.git
    $tempdir/$git_repo 2> /dev/null)\n    validate_clone\n  elif [[ $repo_type ==
    \"gitea\" ]]; then\n    clone_result=$(git clone http://$git_user:${git_secret_token}@${git_url}/${git_project}/${git_repo}.git
    $tempdir/$git_repo 2> /dev/null)\n    validate_clone\n  elif [[ $repo_type ==
    \"stash\" ]]; then\n    #statements\n    if [[ $git_url_port != \"\" ]]; then\n
    \     clone_result=$(git  clone https://$git_user:${git_secret_token}@${git_url}:$git_url_port/scm/${git_project}/$git_repo.git
    $tempdir/$git_repo 2> /dev/null)\n      validate_clone\n    else\n      clone_result=$(git
    \ clone https://$git_user:${git_secret_token}@${git_url}/scm/${git_project}/$git_repo.git
    $tempdir/$git_repo 2> /dev/null)\n      validate_clone\n    fi\n  fi\n  #echo
    $clone_result\n}\nload_ssh(){\n\tmkdir /home/opsmx/.ssh\n\tcp /etc/git-secret/git_secret_sshkey
    ~/.ssh/id_rsa\n\tchmod 400 ~/.ssh/id_rsa\n\tssh-keyscan github.com >> ~/.ssh/known_hosts\n}\ngit_clone_ssh(){\n
    \ echo \"cloning $git_project/$git_repo over ssh\"\n  if [[ $repo_type == \"git\"
    || $repo_type == \"bitbucket\" ]]\n  then\n\t  load_ssh\n\t  clone_result=$(git
    clone git@${git_url}:${git_project}/$git_repo.git $tempdir/$git_repo 2> /dev/null)\n\t
    \ validate_clone\n  elif [[ $repo_type == \"stash\" && $git_url_port != \"\" ]];
    then\n    #statements\n    clone_result=$(git clone ssh://git@${git_url}:$git_url_port/${git_project}/$git_repo.git
    $tempdir/$git_repo 2> /dev/null)\n  else\n\n    clone_result=$(git clone ssh://git@${git_url}:${git_project}/$git_repo.git
    $tempdir/$git_repo $tempdir/$git_repo 2> /dev/null)\n  fi\n  #echo $clone_result\n}\n\ngit_add_file()
    {\n  local file=$1\n  git add $file\n}\n\ngit_add_all() {\n  git add $1\n}\ngit_tag_all()
    {\n  git tag -a Backup-$TAGSTAMP -m \"$msg\"\n  git push --tags\n}\n\ngit_delete_file()
    {\n  local file=$1\n  git rm $file\n}\n\ngit_checkout_branch(){\n  all_branches=$(git
    branch -r| grep -w  origin/$git_branch)\n  echo $all_lbranches\n  if [[ $all_branches
    != \"\" ]]\n  then\n    branch_checkout_result=$(git checkout $git_branch)\n    echo
    $branch_checkout_result\n    pull_requred=true\n  else\n    git checkout -b $git_branch\n
    \ fi\n\n}\ngit_add_all(){\n\n\tgit add $1\n\n}\ngit_commit_all() {\n  local branch=$git_branch\n
    \ local msg=\"checking application and pipeline raw data\"\n if [ \"$pull_requred\"
    = true ]; then\n   git pull origin $branch --no-edit\n   if [ \"$?\" != \"0\"
    ];then\n     echo \"[ERROR]: Failed to pull $branch upstream.\"\n     exit 1\n
    \ fi\nfi\n  opts=\"\"\n  if [ \"$git_commit_sign\" == \"true\" ]; then\n    opts=\"-s\"\n
    \ fi\n  #git commit $opts -a -m $msg\n  git commit -m \"$msg\"\n  git push --set-upstream
    origin $branch\n  if [ \"$?\" != \"0\" ];then\n    echo \"[ERROR]: Failed to push
    $branch upstream.\"\n    exit 1\n  fi\n}\n\nsync_spin_to_git() {\n\n  echo \"In
    upload function which copies spinnaker application and pipeline from spinnaker
    to repo\"\n\n  local user_root_folder=$root_folder\n\n  if [ \"$git_secret_sshkey\"
    != \"\" ]; then\n    git_clone_ssh\n  elif [ \"$git_secret_token\" != \"\" ];
    then\n    git_clone_http\n  else\n    echo \"git cloning requires either a git_aws_secret_key
    to be set or git_aws_secret_token\"\n   exit 5\n  fi\n\n  projectdir=$tempdir/$git_repo\n
    \ cd $projectdir\n  #We are done, get update git\n  git_checkout_branch\n  if
    [ -z $spinnaker_applications ]\n  then\n          spin application list > app.json\n
    \         spinnaker_app=$(cat app.json | jq -r '[.[].name]| @csv' | sed 's/\",\"/,/g;
    s/^\"\\|\"$//g')\n          rm -rf app.json\n          get_pipelines_data  $spinnaker_app\n
    \ else\n          get_pipelines_data  $spinnaker_applications\n    fi\n  git_add_all
    $root_folder\n  git_commit_all\n  return 0\n}\nsync_git_to_spin(){\n  setup_git\n
    \ if [ \"$git_secret_sshkey\" != \"\" ]; then\n    git_clone_ssh\n  elif [ \"$git_secret_token\"
    != \"\" ]; then\n    git_clone_http\n  else\n    echo \"git cloning requires either
    a git_aws_secret_key to be set or git_aws_secret_token\"\n   exit 5\n  fi\n  projectdir=$tempdir/$git_repo\n
    \ cd $projectdir\n  git_checkout_branch\n  syncup_spin\n}\n"
  github.sh: |
    #!/bin/bash

    #this script funtions only work for github central repository

    #this script funtions only work for git repo
    #env variables needed for this to work are as below
    #***git_url="example.bitbucket.com" make sure you dont add http/https or / in the url
    #****git_repo="pipelinepromotion" repo to be pushed/download pipeline json files from
    #***git_project="kes" project key is needed to clone/push/pull merge code
    #***git_user="tes.user" user is needed for cloning and pusing changes (stash does not support only access key)
    #***git_branch="testbranch" the branch to which the code should be merged with
    #***merge_branch=false if true then provide all the below env variables
    #   git_secret_token="dafjaljoahfoasjoijso" needed to create pull requests should be the git_users secret token
    #   git_pr_token="slkdfjaljoajfopaj" this is approver token to approve pull requests / you can also provide approver password here.
    #   git_approve_user="test.approver"  username of the pull request approver
    #   git_password="adjoowddaw" make sure your password does not include special characters like # @*/. special characters cause git clone command to fail with https
    #
    #  repo_type="stash" for selfhosted bitbucket server please use stash as repo type
    #***root_folder="path/to/pipeline-promotion/folder" folder to be selected in the repo to which the pipeline jobs to be pushed
    #***command=upload for running specific job -
    #                                         upload - to upload spinnaker pipeline json files to repo
    #                                         download - to download pipeline json file from repo and apply on spinnaker
    #***spinnaker_applications="testapp,sampleapp" application needed to collect the pipeline information
    #spinnaker_pipelines="" provide pipelines to be collected, if nothing given, all the pipelines of the application are collected
    #git_secret_sshkey="sshkey" ssh key if you want to clone repo with ssh protocol

    # note *** env variables are mandatory to work with the script

    source scripts/git.sh
    git_hub_api_url=$git_api_url
    approve_pr_github(){
      approve_req=$(curl -o -I -L -s -w "%{http_code}" -X POST -H "Accept: application/vnd.github.v3+json" -u $git_approve_user:$git_pr_token  $git_hub_api_url/$git_user/${git_repo}/pulls/${pr_id}/reviews \
      -d '{"body": "Spinnaker says LGTM","event": "APPROVE"}')
      echo $approve_req
      if [[ $approve_req == "200" ]];then
        echo "merge request approved successfully"
      else
        echo "FAIL: failed to approve the request $"
        exit 1
      fi
    }

    merge_pr_github(){

      merge_req=$(curl -o -I -L -s -w "%{http_code}" -X PUT -H "Accept: application/vnd.github.v3+json" -u $git_user:$git_secret_token $git_hub_api_url/$git_user/${git_repo}/pulls/${pr_id}/merge)
      echo $merge_req
      if [[ $merge_req == "200" ]]; then
        echo "merged pr successfully"
      else
        echo "FAILED: failed to merge $merge_pr"
        exit 1
    fi
    }

    create_pr_github(){

      local output=$(curl  -X POST -H "Accept: application/vnd.github.v3+json" -u $git_user:$git_secret_token $git_hub_api_url/${git_user}/${git_repo}/pulls \
      -d '{"title": "pull request to merge '$git_branch' to master","body": "pull request to merge latest pipleine jobs information to '$target_branch'", "head": "'${git_branch}'","base": "'$target_branch'"}')
      if [ "$?" != 0 ]
      then
        echo "master branch is already up-to-date"
        exit 0
      else
        echo $output
        echo $output > pr_response.json
        errors=$(cat  pr_response.json| jq '(.errors)' | sed 's/\"//g')
        if [[ $errors != null ]]; then
          echo "ERROR: failed to raise pull request $errors"
          exit 1
        fi
        pr_id=$(cat  pr_response.json| jq '(.number)' | sed 's/\"//g')
        if [[  $pr_id != ""  ]]; then
          echo "successfully created pull request "
        else
          echo "ERROR: failed to raise pull request $output"
          exit 1
      fi
    fi
    }

    sync_spin_to_github(){
      setup_git
      sync_spin_to_git
      if [[ $merge_branch == "true" && $target_branch != "" && ($git_branch != $target_branch)  ]];then
        if [[ $git_api_url_port != "" ]];then
          git_hub_api_url=$git_hub_api_url:$git_api_url_port

          create_pr_github
          if [[ $auto_merge == "true" ]]; then
            approve_pr_github
            merge_pr_github
          fi
        else
          create_pr_github
          if [[ $auto_merge == "true" ]]; then
            approve_pr_github
            merge_pr_github
          fi
        fi
      fi
    }
  s3.sh: |
    #!/bin/bash
    source scripts/spin.sh
    absolute_path="$(dirname $(readlink -f $0))"

    # s3_folder=folder/in/s3/bucket if not given script uploads to root folder or the s3 bucket
    # ***bucket_name=testenvpipelinebucket "bucktet name to upload pipeline configuration"
    # ***AWS_ACCESS_KEY_ID="SKJGIHOBGIHIHOOH" access key to access s3 bucket
    # ***AWS_SECRET_ACCESS_KEY="sdfjlasj2e334234sdljflsjflsd98y9sy/0UVv6eCg" secret to access s3 bucket
    # ***repo_type=s3 provide repo type as s3
    #***command=upload for running specific job -
    #                                         upload - to upload spinnaker pipeline json files to repo
    #                                         download - to download pipeline json file from repo and apply on spinnaker
    #***spinnaker_applications="testapp,sampleapp" application needed to collect the pipeline information
    #spinnaker_pipelines="" provide pipelines to be collected, if nothing given, all the pipelines of the application are collected


    # note *** env variables are mandatory to work with the script
    s3_folder=$root_folder
    tempdir="/tmp/"
    bucket_name=$repo_name
    create_bucket(){
      #to create a bucket in s3 bucket name needed
            aws s3 mb s3://$bucket_name
            if [ $? != 0 ]; then
                    echo "[ERROR]: Failed to create s3 bucket  might be aleady existing"
            fi
    }

    list_bucket(){
      # to llst bucket objects
         aws s3 ls s3://$bucket_name/
             if [ $? != 0 ]; then
              echo "[ERROR]: Failed to list s3 bucket "
          fi
    }

    list_application_folder(){
      # to list an object folder
            aws ls s3://$bucket_name/${s_folder}/$1 | awk '{print $4}'
    }

    upload_spin_to_s3(){
      # get the pipeline data from spinnaker and store in root_folder
      echo APP $spinnaker_applications
      if [ -z $spinnaker_applications ]
      then
              spin application list > app.json
              spinnaker_app=$(cat app.json | jq -r '[.[].name]| @csv' | sed 's/","/,/g; s/^"\|"$//g')
              rm -rf app.json
              get_pipelines_data $spinnaker_app

     else
              get_pipelines_data $spinnaker_applications
     fi

    #  get_pipelines_data
      #upload spinnaker pipelines data and upload to s3 folder
      aws s3 cp $tempdir/$bucket_name/$s3_folder s3://$bucket_name/$s3_folder --recursive
      if [ "$?" != 0 ]; then
              echo "[ERROR]: Failed to upload to bucket" $bucket_name
      else
              echo "uploaded to bucket successfully"
      fi
    }
    sync_from_s3_spin(){

      echo "downloading  spinnaker application pipelines configuration"

      aws s3 sync  s3://$bucket_name/$s3_folder $tempdir$s3_folder
      #apply configuration in spinnaker
      syncup_spin
    }

    delete_s3_object(){
      #delete an object in bucket
            aws rm s3://$bucket_name/${s3_folder}/${application_name}/  --recursive
            if [ $? != 0 ]; then
                    echo "[ERROR]: Failed to delete s3 application folder "
            else
                    echo "created bucket successfully"
            fi
    }
  spin.sh: "#!/bin/bash\n#source $(dirname $0)/git.sh\ntempdir=\"/tmp/\"\n\n#spinnaker_applications=\"sampleapp\"\nget_app_pipelines(){\n\tspin
    pipeline list --application $1  > tmp.json\n\tif [ \"$?\" != \"0\" ]; then\n\t\t\techo
    \"ERROR: spin pipeline list --application $1\"\n\t\t\treturn 1\n\tfi\n\tcat tmp.json
    | jq '.[] | (.name)' | sed 's/\\\"//g' > pipelines_in_application.list\n\tcat
    tmp.json | jq '.[] | (.id)' | sed 's/\\\"//g' > pipelines_guid.list\n\trm tmp.json\n}\n\n\nlive_backup_spin()
    {\n\n#This function will backup existing spinnaker data and store it in local
    for further comparison\n\n  if [[ $repo_type = \"s3\" ]]; then\n\t\tprojectdir=$tempdir/$root_folder\n\telse\n\t\tprojectdir=$tempdir/${git_repo}/$root_folder\n
    \ fi\n\tlive_projectdir_workdir=$projectdir/live_backup\n\n  if [ -d \"$live_projectdir_workdir\"
    ]\n  then\n    echo \"given live_spinnaker_project_work_dir is present\"\n  else\n
    \   echo \"given live_spinnaker_project_work_dir is not present therefore creating
    it\"\n    mkdir -p \"$projectdir/live_backup\"\n  fi\n\n  cd $live_projectdir_workdir\n\n
    \ spinnaker_app=$spinnaker_applications\n  IFS=',' read -r -a spinnaker_app_array
    <<< \"$spinnaker_app\"\n\n\n  spinnaker_pipe=$spinnaker_pipelines\n  IFS=',' read
    -r -a spinnaker_pipe_array <<< \"$spinnaker_pipe\"\n\n  for (( m=0; m<${#spinnaker_app_array[@]};
    m++ )); do\n     sourceApp=${spinnaker_app_array[$m]}\n     echo -e \"Processing
    application $sourceApp\\n\"\n     mkdir -p $sourceApp ; cd $sourceApp\n\t\t        #
    Get into the correct directory\n     spin -k pipeline list --application $sourceApp
    \ > tmp.json\n     if [ \"$?\" != \"0\" ]; then\n         echo \"ERROR: spin pipeline
    list --application $sourceApp\"\n         return 1\n     fi\n     cat tmp.json
    | jq '.[] | (.name)' | sed 's/\\\"//g' > live_pipelines_in_application.list\n
    \    cat tmp.json | jq '.[] | (.id)' | sed 's/\\\"//g' > live_pipelines_guid.list\n
    \    rm tmp.json\n\n     spin -k application get $sourceApp  > $sourceApp.json\n
    \    if [ \"$?\" != \"0\" ]; then\n         echo \"ERROR: spin application get
    $sourceApp\"\n         return 1\n     fi\n\n     if [[ ${#spinnaker_pipe_array[@]}
    > 0 ]]; then\n         for (( p=0; p<${#spinnaker_pipe_array[@]}; p++ )); do\n
    \           pipeLine=${spinnaker_pipe_array[$p]}\n            echo -e \"    Processing
    pipeline $pipeLine\\n\"\n            # Check if pipeline exists\n            existingPipe=`grep
    \\^${pipeLine}\\$ live_pipelines_in_application.list`\n            if [[ \"$existingPipe\"
    == \"${pipeLine}\" ]]; then\n               spin -k pipeline get --application
    $sourceApp  --name \"$pipeLine\" > \"$pipeLine.json\"\n               if [ \"$?\"
    != \"0\" ]; then\n                   echo \"ERROR: spin spin pipeline get --application
    $sourceApp  --name \\\"$pipeLine\\\"\"\n                   return 1\n               fi\n
    \           else\n               echo \"WARNING: pipeline=${pipeLine} not found
    in application=$sourceApp ... skipping\"\n            fi\n         done\n     else
    # No pipelines defined, get all the pipelines\n         while read -r line; do\n
    \           echo -e \"    Processing pipeline $line\\n\"\n            spin -k
    pipeline get --application $sourceApp --name \"$line\" > \"$line.json\"\n            if
    [ \"$?\" != \"0\" ]; then\n                echo \"ERROR: spin spin pipeline get
    --application $sourceApp  --name $line\"\n                return 1\n            fi\n
    \        done < live_pipelines_in_application.list\n     fi\n      cd ..\n  done\n
    \ return 0\n}\n\ndelete_odd_pipelines() {\n  #Delete the additional pielines that
    are in spinnaker and not in git\n   for (( m=0; m<${#spinnaker_app_array[@]};
    m++ )); do\n\t   sourceApp=${spinnaker_app_array[$m]}\n\t   if [ -f \"$projectdir/live_backup/$sourceApp/odd_pipeline.txt\"
    ]; then\n             if [ ! -s \"$projectdir/live_backup/$sourceApp/odd_pipeline.txt\"
    ]; then\n\t     echo \"no new pipelines to delete\"\n             else\n           echo
    \"============ Delete pipeline in $sourceApp Application =============\"\n\n\t
    \  while IFS= read -r pipelinename; do\n           echo \"Deleting the pipeline
    $pipelinename\"\n\t   spin -k pipeline delete --name $pipelinename --application
    $sourceApp\n           done < $projectdir/live_backup/$sourceApp/odd_pipeline.txt\n\n\t
    \  rm -rf $projectdir/live_backup/$sourceApp/odd_pipeline.txt\n\n   fi\n   fi\ndone\n\n}\n#Create
    default parameterconfig-files\ncreate_default_params() {\n    targetDir=${1:-default-config}\n
    \   echo \"Processing pipelines and creating output in $targetDir\"\n    mkdir
    -p $targetDir\n    for json in *.json ; do\n      [[ -f \"$json\" ]] || continue\n
    \     echo \"\tprocessing $json\"\n      cat \"$json\" | jq '.parameterConfig
    | reduce .[] as $p  ({};.Parameters += {($p.name): $p.default})'  >  $targetDir/tmp-param.json
    2>/dev/null\n      cat \"$json\" | jq '.triggers[0] '  >  $targetDir/tmp-trig.json
    2>/dev/null\n\n      if [[ `cat $targetDir/tmp-trig.json | wc -c` -gt 5 ]]\n      then\n
    \       cat $targetDir/tmp-param.json | jq '.triggerValues=$pp' --argfile pp $targetDir/tmp-trig.json
    > $targetDir/\"$json\" 2>/dev/null\n      else\n        cp  $targetDir/tmp-param.json
    $targetDir/\"$json\"\n      fi\n    done\n    rm -f $targetDir/tmp-param.json\n
    \   rm -f $targetDir/tmp-trig.json\n    #Remove all files with zero size\n    echo
    \"Removing files that do not have any parameters defined\"\n    find $targetDir
    -type f -size -4c -delete # No parameterConfig in the file\n    #find $targetDir
    -type f -size -4c -print -delete # No parameterConfig in the file\n}\n\nequate_pipelines_in_app()
    {\n\n #This function will comapre the applications and pipelines in git and spinnaker
    and gives the additional pipelines data\n\n  IFS=',' read -r -a spinnaker_app_array
    <<< \"$spinnaker_app\"\n\n  IFS=',' read -r -a spinnaker_pipe_array <<< \"$spinnaker_pipe\"\n\n
    \ for (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do\n     sourceApp=${spinnaker_app_array[$m]}\n\n
    \    touch $projectdir/live_backup/$sourceApp/odd_pipeline_id.txt\n\n\t\t echo
    $projectdir\n\t\t echo $git_project_work_dir\n\t\t echo $sourceApp\n     diff
    $projectdir/$git_project_work_dir/$sourceApp/pipelines_guid.list $projectdir/live_backup/$sourceApp/live_pipelines_guid.list
    | awk '{print $2}' | sed 1d > $projectdir/live_backup/$sourceApp/odd_pipeline_id.txt\n\n
    \    #list all existing spinnaker pipelines with app as reference\n     spin -k
    pipeline list --application $sourceApp > $projectdir/live_backup/$sourceApp/$sourceApp-pipeline_list.json\n
    \    touch $projectdir/live_backup/$sourceApp/odd_pipeline.txt\n\n     while IFS=
    read -r id; do\n     #Extract the pipeline names using guids as reference\n     cat
    $projectdir/live_backup/$sourceApp/$sourceApp-pipeline_list.json | jq '.[] | select
    (.id==\"'$id'\") | .name' -r >> $projectdir/live_backup/$sourceApp/odd_pipeline.txt\n
    \    done < $projectdir/live_backup/$sourceApp/odd_pipeline_id.txt\n  done\n}\n\nsyncup_spin()
    {\n  echo \"In Download function that updates the spinnaker instance with the
    contents in repo\"\n\n  #Backup of existing spinnaker pipelines with guids\n  live_backup_spin\n\n
    \ #Compare guids of existing pipelines and pipelines in git and provide names
    of additional pipelines\n  equate_pipelines_in_app\n\n  #Delete the extra pipelines(pipelines
    in spinnaker and not in git)\n\tif [[ $delete_on_sync_spin == \"true\" ]]; then\n\t\tdelete_odd_pipelines\n\tfi\n\n\tif
    [[ $repo_type = \"s3\" ]]; then\n\t\tprojectdir=$tempdir/$root_folder\n\t\techo
    \"project dir at synup spin $projectdir\"\n\telse\n\n\t\tprojectdir=$tempdir/${git_repo}/$root_folder\n\tfi\n
    \ if [ -d \"$projectdir\" ]\n  then\n    echo \"given git_project_work_dir is
    present\"\n  else\n    echo \"given git_project_work_dir is not present therefore
    creating it\"\n    mkdir -p \"$projectdir/$git_project_work_dir\"\n  fi\n\n  cd
    $projectdir\n  spinnaker_app=$spinnaker_applications\n  IFS=',' read -r -a spinnaker_app_array
    <<< \"$spinnaker_app\"\n\n  spinnaker_pipe=$spinnaker_pipelines\n  #IFS=',' read
    -r -a spinnaker_pipe_array <<< \"k8s-deploy\"\n  IFS=',' read -r -a spinnaker_pipe_array
    <<< \"$spinnaker_pipe\"\n\n  echo $projectdir\n  for (( m=0; m<${#spinnaker_app_array[@]};
    m++ )); do\n     sourceApp=${spinnaker_app_array[$m]}\n     echo -e \"Processing
    application $sourceApp\\n\"\n     cd $sourceApp              # Get into the correct
    directory\n     if [ \"$?\" != \"0\" ]; then\n         echo \"ERROR: Unable to
    change to application directory: $sourceApp\"\n         return 1\n     fi\n\n
    \    #Create the application by default, we can have flag to for this later\n
    \    spin -k application save -f $sourceApp.json\n     retVal=$?\n     if [[ \"$retVal\"
    != \"0\" && \"$ignore_errors\" == \"false\" ]]; then\n         echo \"ERROR: spin
    application save $sourceApp\"\n         return 1\n     elif [[ \"$retVal\" !=
    \"0\" && \"$ignore_errors\" == \"true\" ]]; then\n         echo \"ERROR: spin
    application save $sourceApp, continuing\"\n         cd ..\n         continue\n
    \    fi\n     #sleep 30 # Give a few seconds after application creation\n\n     if
    [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then\n         for (( p=0; p<${#spinnaker_pipe_array[@]};
    p++ )); do\n            pipeLine=${spinnaker_pipe_array[$p]}\n            echo
    -e \"    Processing pipeline $pipeLine\\n\"\n            # Check if pipeline file
    \ exists\n            if [ -f \"$pipeLine.json\" ]; then\n                #Update
    parameterConfig\n                if [[ \"$pipelineconfig\" == \"true\" ]]; then\n\n
    \                   mkdir -p temp\n                    update_params \"$pipeLine.json\"\n
    \                   rm -rf temp\n                fi\n               spin -k pipeline
    save --file \"$pipeLine.json\"\n               retVal=$?\n               if [[
    \"$retVal\" != \"0\" && \"$ignore_errors\" == \"false\" ]]; then\n                   echo
    \"ERROR: spin pipeline save --file $pipeLine.json\"\n                   return
    1\n               elif [[ \"$retVal\" != \"0\" && \"$ignore_errors\" == \"true\"
    ]]; then\n                   echo \"ERROR: spin pipeline save --file $pipeLine.json,
    continuing\"\n                   continue\n               fi\n            else\n
    \              echo \"WARNING: pipeline=${pipeLine} not found in application=$sourceApp
    ... skipping\"\n            fi\n         done\n     else # No pipelines defined,
    get all the pipelines\n         while read -r line; do\n            [[ -f \"$line.json\"
    ]] || continue\n            pipeLine=$line\n            echo -e \"    Processing
    pipeline $pipeLine\\n\"\n\n            #Update parameterConfig\n            if
    [[ \"$pipelineconfig\" == \"true\" ]]; then\n\t\t\t\t\t\t\techo \"in pipelineconfig
    else\"\n                mkdir -p temp\n                update_params \"$pipeLine.json\"\n
    \               #rm -rf temp\n            fi\n\n            echo `realpath $pipeLine.json`\n\t\t\t\t\t\tif
    test -f \"$pipeLine.json\"; then\n\t\t\t\t\t\t\tspin -k pipeline save --file \"$pipeLine.json\"\n\t\t\t\t\t\tfi\n\n
    \           retVal=$?\n            if [[ \"$retVal\" != \"0\" && \"$ignore_errors\"
    == \"false\"  ]]; then\n                echo \"ERROR: spin pipeline save --file
    $pipeLine.json\"\n                return 1\n            elif [[ \"$retVal\" !=
    \"0\" && \"$ignore_errors\" == \"true\" ]]; then\n                echo \"ERROR:
    spin pipeline save --file $pipeLine.json, continuing\"\n                continue\n
    \           fi\n           sleep 10 # Slow it down\n         done < pipelines_in_application.list\n
    \    fi\n     cd ..\n  done\n\n}\nget_pipelines_data(){\n\techo $1 \t\n\tlocal
    \ spinnaker_app=$1\n        IFS=',' read -r -a spinnaker_app_array <<< \"$spinnaker_app\"\n
    \       spinnaker_pipe=$spinnaker_pipelines\n        #IFS=',' read -r -a spinnaker_pipe_array
    <<< \"k8s-deploy\"\n        IFS=',' read -r -a spinnaker_pipe_array <<< \"$spinnaker_pipe\"\n\n\t\t\t\tif
    [[ $root_folder == \"\" ]]; then\n\t\t\t\t\troot_folder=\".\"\n\t\t\t\tfi\n        for
    (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do\n     sourceApp=${spinnaker_app_array[$m]}\n
    \    echo -e \"Processing application $sourceApp\\n\"\n\n\t\t echo \"get pipelines
    data $root_folder\"\n     mkdir -p $tempdir/$git_repo/${root_folder}/$sourceApp
    ; cd $tempdir/$git_repo/${root_folder}/$sourceApp              # Get into the
    correct directory\n\n     get_app_pipelines $sourceApp\n     spin application
    get $sourceApp  > $sourceApp.json\n     if [ \"$?\" != \"0\" ]; then\n         echo
    \"ERROR: spin application get $sourceApp\"\n         return 1\n     fi\n     if
    [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then\n         for (( p=0; p<${#spinnaker_pipe_array[@]};
    p++ )); do\n            pipeLine=${spinnaker_pipe_array[$p]}\n            echo
    -e \"    Processing pipeline $pipeLine\\n\"\n            # Check if pipeline exists\n
    \           existingPipe=`grep \\^${pipeLine}\\$ pipelines_in_application.list`\n
    \           if [[ \"$existingPipe\" == \"${pipeLine}\" ]]; then\n               spin
    pipeline get --application $sourceApp  --name \"$pipeLine\" > \"$pipeLine.json\"\n\n
    \              if [ \"$?\" != \"0\" ]; then\n                   echo \"ERROR:
    spin spin pipeline get --application $sourceApp  --name \\\"$pipeLine\\\"\"\n
    \                  return 1\n               fi\n            else\n               echo
    \"WARNING: pipeline=${pipeLine} not found in application=$sourceApp ... skipping\"\n
    \           fi\n         done\n     else # No pipelines defined, get all the pipelines\n
    \        while read -r line; do\n            echo -e \"    Processing pipeline
    $line\\n\"\n            spin pipeline get --application $sourceApp --name \"$line\"
    > \"$line.json\"\n            if [ \"$?\" != \"0\" ]; then\n                echo
    \"ERROR: spin spin pipeline get --application $sourceApp  --name $line\"\n                return
    1\n            fi\n\n         done < pipelines_in_application.list\n     fi\n
    \    if [[ \"$pipelinecreateconf\" == \"true\" ]]; then\n        create_default_params\n
    \    fi\n     cd -\n  done\n}\n\ndownload_spin() {\n  echo \"In Download function
    that updates the spinnaker instance with the contents in git\"\n  local user_root_folder=$root_folder\n\n
    \ if [ \"$git_secret_sshkey\" != \"\" ]; then\n    git_clone_ssh_change $user_root_folder
    $git_repo $git_project\n  elif [ \"$git_secret_token\" != \"\" ]; then\n    git_clone_http
    $user_root_folder $git_repo $git_project\n  else\n    echo \"git cloning requires
    either a git_secret_sshkey to be set or git_secret_token\"\n   exit 5\n  fi\n\n
    \ projectdir=$HOME/$git_project\n  cd $projectdir\n\n  spinnaker_app=$spinnaker_applications\n
    \ IFS=',' read -r -a spinnaker_app_array <<< \"$spinnaker_app\"\n\n  spinnaker_pipe=$spinnaker_pipelines\n
    \ #IFS=',' read -r -a spinnaker_pipe_array <<< \"k8s-deploy\"\n  IFS=',' read
    -r -a spinnaker_pipe_array <<< \"$spinnaker_pipe\"\n\n\n  for (( m=0; m<${#spinnaker_app_array[@]};
    m++ )); do\n     sourceApp=${spinnaker_app_array[$m]}\n     echo -e \"Processing
    application $sourceApp\\n\"\n     cd $sourceApp              # Get into the correct
    directory\n     if [ \"$?\" != \"0\" ]; then\n         echo \"ERROR: Unable to
    change to application directory: $sourceApp\"\n         return 1\n     fi\n\n
    \    #Create the application by default, we can have flag to for this later\n
    \    spin application save -f $sourceApp.json\n     retVal=$?\n     if [[ \"$retVal\"
    != \"0\" && \"$ignore_errors\" == \"false\" ]]; then\n         echo \"ERROR: spin
    application save $sourceApp\"\n         return 1\n     elif [[ \"$retVal\" !=
    \"0\" && \"$ignore_errors\" == \"true\" ]]; then\n         echo \"ERROR: spin
    application save $sourceApp, continuing\"\n         cd ..\n         continue\n
    \    fi\n     sleep 30 # Give a few seconds after application creation\n\n     if
    [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then\n         for (( p=0; p<${#spinnaker_pipe_array[@]};
    p++ )); do\n            pipeLine=${spinnaker_pipe_array[$p]}\n            echo
    -e \"    Processing pipeline $pipeLine\\n\"\n            # Check if pipeline file
    \ exists\n            if [ -f \"$pipeLine.json\" ]; then\n                #Update
    parameterConfig\n                if [[ \"$pipelineconfig\" == \"true\" ]]; then\n
    \                   mkdir -p temp\n                    update_params \"$pipeLine.json\"\n
    \                   rm -rf temp\n                fi\n               spin pipeline
    save --file \"$pipeLine.json\"\n               retVal=$?\n               if [[
    \"$retVal\" != \"0\" && \"$ignore_errors\" == \"false\" ]]; then\n                   echo
    \"ERROR: spin pipeline save --file $pipeLine.json\"\n                   return
    1\n               elif [[ \"$retVal\" != \"0\" && \"$ignore_errors\" == \"true\"
    ]]; then\n                   echo \"ERROR: spin pipeline save --file $pipeLine.json,
    continuing\"\n                   continue\n               fi\n            else\n
    \              echo \"WARNING: pipeline=${pipeLine} not found in application=$sourceApp
    ... skipping\"\n            fi\n         done\n     else # No pipelines defined,
    get all the pipelines\n         while read -r line; do\n            [[ -f \"$line.json\"
    ]] || continue\n            pipeLine=$line\n            echo -e \"    Processing
    pipeline $pipeLine\\n\"\n\n            #Update parameterConfig\n            if
    [[ \"$pipelineconfig\" == \"true\" ]]; then\n                mkdir -p temp\n                update_params
    \"$pipeLine.json\"\n                #rm -rf temp\n            fi\n            spin
    pipeline save --file \"$pipeLine.json\"\n            retVal=$?\n            if
    [[ \"$retVal\" != \"0\" && \"$ignore_errors\" == \"false\"  ]]; then\n                echo
    \"ERROR: spin pipeline save --file $pipeLine.json\"\n                return 1\n
    \           elif [[ \"$retVal\" != \"0\" && \"$ignore_errors\" == \"true\" ]];
    then\n                echo \"ERROR: spin pipeline save --file $pipeLine.json,
    continuing\"\n                continue\n            fi\n            sleep 10 #
    Slow it down\n         done < pipelines_in_application.list\n     fi\n     cd
    ..\n  done\n\n}\n\nupdate_params() {\n    confDir=${pipelineconfigdir}\n    if
    [ ! -d \"$confDir\" ] ; then\n      echo \"Directory specified for configuratio
    ($confDir) not found in application directory\"\n      return\n    fi\n    if
    [ ! -f \"$confDir/$json\" ] ; then\n      echo \"INFO: No configuration found
    for $json in $confDir\"\n      return\n    fi\n    json=\"$1\"\n    echo \"Processing
    pipeline ($json) and updating pipelines as per configuration in $confDir\"\n    #Extract
    .parameterConfig\n    cat \"$json\" | jq '.parameterConfig' > temp/\"config-$json\"\n
    \   #Replace parameters\n    cat temp/\"config-$json\" | jq -f /home/opsmx/scripts/replace-params.jq
    --argfile pp $confDir/\"$json\" > temp/\"updated-config-$json\"\n\n    #Replace
    .parameterConfig\n    cat \"$json\" | jq  '.parameterConfig=$uc' --argfile uc
    temp/\"updated-config-$json\" > temp/\"$json\"\n\n    ########################################################################\n
    \   #Extract 1st trigger\n    cat  temp/\"$json\"| jq '.triggers[0]' > temp/tmp-trig.json\n
    \   #Update first trigger\n    cat temp/tmp-trig.json | jq 'if $pp.triggerValues
    != null then . * $pp.triggerValues else . end'  --argfile pp $confDir/\"$json\"
    \ > temp/updated-tmp-trig.json\n    #Update pipeline-json with updated trigger\n
    \   if [[ `cat temp/updated-tmp-trig.json | wc -c` -gt 5 ]]\n    then\n      cat
    temp/\"$json\" | jq '.triggers[0]=$pp' --argfile pp temp/updated-tmp-trig.json
    > temp/final-replaced.json\n      cp temp/final-replaced.json \"$json\"\n    else\n
    \     cp  temp/\"$json\" \"$json\"\n    fi\n    ########################################################################\n}\n"
  stash.sh: "#!/bin/bash\n\n#this script funtions only work for self hosted bitbucketserver/stash
    central repository\n#env variables needed for this to work are as below\n#***git_url=\"example.bitbucket.com\"
    make sure you dont add http/https or / in the url\n#****git_repo=\"pipelinepromotion\"
    repo to be pushed/download pipeline json files from\n#***git_project=\"kes\" project
    key is needed to clone/push/pull merge code\n#***git_user=\"tes.user\" user is
    needed for cloning and pusing changes (stash does not support only access key)\n#git_password=\"adjoowddaw\"
    make sure your password does not include special characters like # @*/. special
    characters cause git clone command to fail with https\n#***git_branch=\"testbranch\"
    the branch to which the code should be merged with\n#***merge_branch=false if
    true then provide all the below env variables\n#   git_secret_token=\"dafjaljoahfoasjoijso\"
    needed to create pull requests should be the git_users secret token\n#   git_pr_token=\"slkdfjaljoajfopaj\"
    this is approver token to approve pull requests / you can also provide approver
    password here.\n#   git_approve_user=\"test.approver\"  username of the pull request
    approver\n#\n# repo_type=\"stash\" for selfhosted bitbucket server please use
    stash as repo type\n#***root_folder=\"path/to/pipeline-promotion/folder\" folder
    to be selected in the repo to which the pipeline jobs to be pushed\n#***command=upload
    for running specific job -\n#                                         upload -
    to upload spinnaker pipeline json files to repo\n#                                         download
    - to download pipeline json file from repo and apply on spinnaker\n#***spinnaker_applications=\"testapp,sampleapp\"
    application needed to collect the pipeline information\n#spinnaker_pipelines=\"\"
    provide pipelines to be collected, if nothing given, all the pipelines of the
    application are collected\n#git_secret_sshkey=\"sshkey\" ssh key if you want to
    clone repo with ssh protocol\n\n# note *** env variables are mandatory to work
    with the script\n\nsource scripts/git.sh\ngit_repo=$repo_name\npr_id=0\npr_version=0\napprove_pr_stash(){\n
    \ approve_req=$(curl -k -o -I -L -s -w \"%{http_code}\"  -X POST -H \"Content-Type:
    application/json\" -u $git_approve_user:$git_pr_token \\\n  https://$git_api_url/${git_project}/repos/${git_repo}/pull-requests/${pr_id}/approve)\n
    \ echo $approve_req\n  if [[ $approve_req == \"200\" ]];then\n    echo \"merge
    request approved successfully\"\n  else\n    echo \"FAIL: failed to approve the
    request \"\n    exit 1\n  fi\n}\n\nmerge_pr_stash(){\n\n  merge_req=$(curl -k
    -o -I -L -s -w \"%{http_code}\"  -X POST -H \"Content-Type: application/json\"
    -u $git_user:$git_secret_token   \\\n  https://$git_api_url/${git_project}/repos/${git_repo}/pull-requests/${pr_id}/merge?version=$pr_version)\n
    \ echo $merge_req\n  if [ $merge_req == \"200\" ]; then\n    echo \"merged pr
    successfully\"\n  else\n    echo \"FAILED: failed to merge $merge_pr\"\n    exit
    1\nfi\n}\ncreate_pr_stash(){\n\n\tlocal output=$(curl -k -X POST -H \"Content-Type:
    application/json\" -u $git_user:$git_secret_token   https://$git_api_url/${git_project}/repos/${git_repo}/pull-requests
    -d '{\n    \"title\": \"merging '\"$git_branch\"' to '\"$target_branch\"'\",\n
    \   \"description\": \"changes from spinnaker pipeline jobs are to be merged to
    master\",\n    \"state\": \"OPEN\",\n    \"open\": true,\n    \"closed\": false,\n
    \   \"fromRef\": {\n        \"id\": \"refs/heads/'\"${git_branch}\"'\",\n        \"repository\":
    {\n            \"slug\": \"'\"${git_repo}\"'\",\n            \"name\": null,\n
    \           \"project\": {\n                \"key\": \"'\"${git_project}\"'\"\n
    \           }\n        }\n    },\n    \"toRef\": {\n        \"id\": \"refs/heads/'\"$target_branch\"'\",\n
    \       \"repository\": {\n            \"slug\": \"'\"${git_repo}\"'\",\n            \"name\":
    null,\n            \"project\": {\n                \"key\": \"'\"${git_project}\"'\"\n
    \           }\n        }\n    },\n    \"locked\": false\n}')\n  echo $output\n
    \ echo $output > pr_response.json\n  grep  \"is already up-to-date with branch\"
    pr_response.json\n  if [ \"$?\" = 0 ]\n  then\n    echo \"master branch is already
    up-to-date\"\n    exit 0\n  else\n    pr_id=$(cat  pr_response.json| jq '(.id)'
    | sed 's/\\\"//g')\n    pr_version=$(cat pr_response.json | jq '(.version)' |
    sed 's/\\\"//g')\n\n    if [ $? = 0 ]; then\n      echo \"successfully created
    pull request \"\n      #rm -f pr_response.json\n    else\n      echo \"ERROR:
    failed to raise pull request $output\"\n      exit 1\n  fi\nfi\n}\n\nsync_spin_to_stash(){\n
    \ #setup git configuration using email and username\n  setup_git\n  #upload spinnaker
    configuration to git\n  sync_spin_to_git\n  #check if custom port is being used
    for repo\n  if [[ $merge_branch == \"true\" && $target_branch != \"\" && ($git_branch
    != $target_branch)  ]];then\n    if [[ $git_api_url_port != \"\" ]];then\n      git_api_url=$git_api_url:$git_api_url_port\n
    \     create_pr_stash\n      if [[ $auto_merge == \"true\" ]]; then\n        approve_pr_stash\n
    \       merge_pr_stash\n      fi\n    else\n      create_pr_stash\n      if [[
    $auto_merge == \"true\" ]]; then\n        approve_pr_stash\n        merge_pr_stash\n
    \     fi\n    fi\n  fi\n}\n"

kind: ConfigMap
metadata:
  name: pipe-promot-scripts
---
# Source: oes/charts/minio/templates/pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "10Gi"
---
# Source: oes/charts/openldap/templates/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: isd-openldap
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "5Gi"
---
# Source: oes/charts/minio/templates/post-install-prometheus-metrics-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: isd-minio-update-prometheus-secret
  labels:
    app: minio-update-prometheus-secret
    chart: minio-8.0.9
    release: isd
    heritage: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - get
      - create
      - update
      - patch
    resourceNames:
      - isd-minio-prometheus
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - create
  - apiGroups:
      - monitoring.coreos.com
    resources:
      - servicemonitors
    verbs:
      - get
    resourceNames:
      - isd-minio
---
# Source: oes/charts/spinnaker/templates/rbac/spinnaker-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: spinnaker-role
rules:
  - apiGroups: ['']
    resources:
      [
        'namespaces',
        'events',
        'replicationcontrollers',
        'serviceaccounts',
        'pods/log',
      ]
    verbs: ['get', 'list']
  - apiGroups: ['']
    resources: ['pods', 'services', 'secrets', 'configmaps']
    verbs:
      [
        'create',
        'delete',
        'deletecollection',
        'get',
        'list',
        'patch',
        'update',
        'watch',
      ]
  - apiGroups: ['autoscaling']
    resources: ['horizontalpodautoscalers']
    verbs: ['list', 'get']
  - apiGroups: ['apps']
    resources: ['controllerrevisions', 'statefulsets']
    verbs: ['list']
  - apiGroups: ['extensions', 'apps']
    resources: ['deployments', 'replicasets', 'ingresses']
    verbs:
      [
        'create',
        'delete',
        'deletecollection',
        'get',
        'list',
        'patch',
        'update',
        'watch',
      ]
  # These permissions are necessary for halyard to operate. We use this role also to deploy Spinnaker itself.
  - apiGroups: ['']
    resources: ['services/proxy', 'pods/portforward']
    verbs:
      [
        'create',
        'delete',
        'deletecollection',
        'get',
        'list',
        'patch',
        'update',
        'watch',
      ]
  # These permissions are necessary for halyard to operate. We use this role also to deploy Spinnaker itself.
  - apiGroups: ['batch']
    resources: ['jobs']
    verbs:
      [
        'create',
        'delete',
        'get',
        'list',
        'update',
        'watch',
      ]
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: create-controller-secret
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get","list","create","update","patch"]
---
# Source: oes/charts/minio/templates/post-install-prometheus-metrics-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: isd-minio-update-prometheus-secret
  labels:
    app: minio-update-prometheus-secret
    chart: minio-8.0.9
    release: isd
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: isd-minio-update-prometheus-secret
subjects:
  - kind: ServiceAccount
    name: isd-minio-update-prometheus-secret
    namespace: "opsmx-isd"
---
# Source: oes/charts/spinnaker/templates/rbac/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: isd-spinnaker-halyard
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role                 # ClusterRole, if we have access to cluster resources
  name: spinnaker-role       # edit, if we have the access
subjects:
- namespace: opsmx-isd
  kind: ServiceAccount
  name: isd-spinnaker-halyard
---
# Source: oes/charts/spinnaker/templates/rbac/spinnaker-sa.yaml
# In the case of a local cluster Spinnaker needs
# to be able to deploy to all namespaces in the cluster.
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding  # ClusterRoleBinding, if we have access accross the cluster
metadata:
  name: isd-spinnaker-spinnaker
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role             # ClusteRoleBinding if we have access accross the cluster
  name: spinnaker-role   # cluster-admin if we have the access
subjects:
- namespace: opsmx-isd
  kind: ServiceAccount
  # Clouddriver does not currently allow config of its
  # service account.
  name: default
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: create-controller-secret
subjects:
- kind: ServiceAccount
  name: create-controller-secret
roleRef:
  kind: Role
  name: create-controller-secret
  apiGroup: rbac.authorization.k8s.io
---
# Source: oes/templates/rbac/oes-init-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding # ClusterRole if you have cluster access
metadata:
  name: opsmx-isd-oes-access
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: view
subjects:
- namespace: opsmx-isd
  kind: ServiceAccount
  name: default
---
# Source: oes/charts/gitea/charts/memcached/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-memcached
  namespace: opsmx-isd
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-5.9.0
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  type: ClusterIP
  ports:
    - name: memcache
      port: 11211
      targetPort: memcache
      nodePort: null
  selector:
    app.kubernetes.io/name: memcached
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/gitea/charts/postgresql/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-postgresql-headless
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
  namespace: opsmx-isd
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/gitea/charts/postgresql/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
  annotations:
  namespace: opsmx-isd
spec:
  type: ClusterIP
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: isd
    role: primary
---
# Source: oes/charts/gitea/templates/gitea/http-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-gitea-http
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
  annotations:
    null
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: http
    port: 3000
    targetPort: 3000
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/gitea/templates/gitea/ssh-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-gitea-ssh
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
  annotations:
    null
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: ssh
    port: 22
    targetPort: 22
    protocol: TCP
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/minio/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 9000
      protocol: TCP
      targetPort: 9000
  selector:
    app: minio
    release: isd
---
# Source: oes/charts/openldap/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-openldap
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
spec:
  ports:
    - name: ldap-port
      protocol: TCP
      port: 389
      targetPort: ldap-port
    - name: ssl-ldap-port
      protocol: TCP
      port: 636
      targetPort: ssl-ldap-port
  selector:
    app: openldap
    release: isd
  type: ClusterIP
---
# Source: oes/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-redis-headless
  labels:
    app: redis
    chart: redis-10.5.3
    release: isd
    heritage: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: redis
    port: 6379
    targetPort: redis
  selector:
    app: redis
    release: isd
---
# Source: oes/charts/redis/templates/redis-master-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-redis-master
  labels:
    app: redis
    chart: redis-10.5.3
    release: isd
    heritage: Helm
spec:
  type: ClusterIP
  ports:
  - name: redis
    port: 6379
    targetPort: redis
  selector:
    app: redis
    release: isd
    role: master
---
# Source: oes/charts/spinnaker/templates/services/halyard.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-spinnaker-halyard
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
    component: halyard
spec:
  ports:
  - port: 8064
    name: daemon
  clusterIP: None
  selector:
    app: isd-spinnaker
    component: halyard
---
# Source: oes/templates/forwarder/oes-forwarder-svc-agent.yaml
apiVersion: v1
kind: Service
metadata:
  name: opsmx-controller-controller1
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
spec:
  selector:
    app: opsmx-controller-controller1
  type: ClusterIP
  ports:
  - name: service-api
    port: 9002
    targetPort: service-api
  - name: control-api
    port: 9003
    targetPort: control-api
  - name: remote-command
    port: 9004
    targetPort: remote-command
---
# Source: oes/templates/forwarder/oes-forwarder-svc-agent.yaml
apiVersion: v1
kind: Service
metadata:
  name: agent-grpc
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
spec:
  selector:
    app: opsmx-controller-controller1
  type: LoadBalancer
  ports:
  - name: agent-grpc
    port: 9001
---
# Source: oes/templates/forwarder/oes-forwarder-svc-ipc.yaml
apiVersion: v1
kind: Service
metadata:
  name: opsmx-controller-controller1-interproc
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
spec:
  selector:
    app: opsmx-controller-controller1
  type: ClusterIP
  ports:
  - name: agent-grpc
    port: 9001
    targetPort: agent-grpc
---
# Source: oes/templates/sapor-gate/sapor-gate-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spin
    component: sapor-gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: sapor-gate
spec:
  type: ClusterIP
  ports:
  - name: "sapor-gate-service"
    port: 8084
    protocol: TCP
    targetPort: 8084
  selector:
    app: oes
    component: sapor-gate
---
# Source: oes/templates/services/oes-auditclient-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: auditclient
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-audit-client
spec:
  ports:
  - name: auditclient
    port: 8098
    protocol: TCP
    targetPort: 8098
  selector:
    app: oes
    component: auditclient
  type: ClusterIP
---
# Source: oes/templates/services/oes-auditservice-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: auditservice
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-audit-service
spec:
  ports:
  - name: auditservice
    port: 8097
    protocol: TCP
    targetPort: 8097
  selector:
    app: oes
    component: auditservice
  type: ClusterIP
---
# Source: oes/templates/services/oes-autopilot-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: autopilot
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-autopilot
spec:
  type: ClusterIP
  ports:
  - name: "cas-service"
    port: 8090
    targetPort: 8090
  - name: "monitoring-service"
    port: 9090
    targetPort: 9090
  selector:
    app: oes
    component: autopilot
---
# Source: oes/templates/services/oes-dashboard-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: dashboard
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-dashboard
spec:
  type: ClusterIP
  ports:
  - name: dashboard
    protocol: TCP
    port: 8094
    targetPort: 8094
  selector:
    app: oes
    component: dashboard
---
# Source: oes/templates/services/oes-datascience-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: datascience
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-datascience
spec:
  ports:
  - name: datascience
    port: 5005
    protocol: TCP
    targetPort: 5005
  selector:
    app: oes
    component: datascience
  type: ClusterIP
---
# Source: oes/templates/services/oes-db-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: db
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-db
spec:
  type: ClusterIP
  ports:
  - name: db
    protocol: TCP
    port: 5432
    targetPort: 5432
  selector:
    app: oes
    component: db
---
# Source: oes/templates/services/oes-gate-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-gate
spec:
  type: ClusterIP
  ports:
  - name: "https"
    port: 443
    targetPort: 8084
  - name: "oes-gate-service"
    port: 8084
    protocol: TCP
    targetPort: 8084
  - name: "http"
    port: 80
    targetPort: 8084
  selector:
    app: oes
    component: gate
---
# Source: oes/templates/services/oes-platform-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: platform
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-platform
spec:
  type: ClusterIP
  ports:
  - name: oes-platform
    protocol: TCP
    port: 8095
    targetPort: 8095
  selector:
    app: oes
    component: platform
---
# Source: oes/templates/services/oes-rabbitmq-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: rabbitmq
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: rabbitmq-service
spec:
  ports:
  - name: rabbitmq
    port: 5672
    protocol: TCP
    targetPort: 5672
  - name: rabbitmq-mgmt
    port: 15672
    protocol: TCP
    targetPort: 15672
  selector:
    app: oes
    component: rabbitmq
  type: ClusterIP
---
# Source: oes/templates/services/oes-sapor-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: sapor
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-sapor
spec:
  type: ClusterIP
  ports:
  - name: "sapor"
    port: 8085
    targetPort: 8085
  selector:
    app: oes
    component: sapor
---
# Source: oes/templates/services/oes-ui-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-ui
spec:
  type: ClusterIP
  ports:
  - name: "https"
    port: 443
    targetPort: 8080
  - name: "http"
    port: 8080
    targetPort: 8080
  selector:
    app: oes
    component: ui
---
# Source: oes/templates/services/oes-visibility-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: visibility 
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-visibility
spec:
  type: ClusterIP
  ports:
  - name: visibility 
    protocol: TCP
    port: 8096
    targetPort: 8096
  selector:
    app: oes
    component: visibility
---
# Source: oes/templates/services/opa-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: opa
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
spec:
  selector:
    app: opa
  ports:
  - protocol: TCP
    port: 8181
    targetPort: 8181
  type: ClusterIP
---
# Source: oes/templates/spinnaker-extra/spinsvcs.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spin
    stack: deck
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: spin-deck-lb
spec:
  type: ClusterIP
  ports:
   - name: "https"
     port: 443
     targetPort: 9000
   - name: "http"
     port: 80
     protocol: TCP
     targetPort: 9000
  selector:
    cluster: spin-deck
---
# Source: oes/templates/spinnaker-extra/spinsvcs.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spin
    stack: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: spin-gate-lb
spec:
  type: ClusterIP
  ports:
   - name: https
     port: 443
     targetPort: 8084
   - name: "http"
     port: 80
     protocol: TCP
     targetPort: 8084
  selector:
    cluster: spin-gate
---
# Source: oes/charts/gitea/charts/memcached/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: isd-memcached
  namespace: opsmx-isd
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-5.9.0
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: memcached
      app.kubernetes.io/instance: isd
  replicas: 1
  template:
    metadata:
      labels:
        app.kubernetes.io/name: memcached
        helm.sh/chart: memcached-5.9.0
        app.kubernetes.io/instance: isd
        app.kubernetes.io/managed-by: Helm
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: memcached
                    app.kubernetes.io/instance: isd
                namespaces:
                  - "opsmx-isd"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
      serviceAccountName: isd-memcached
      containers:
        - name: memcached
          image: docker.io/bitnami/memcached:1.6.9-debian-10-r114
          imagePullPolicy: "IfNotPresent"
          args:
            - /run.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
          ports:
            - name: memcache
              containerPort: 11211
          livenessProbe:
            tcpSocket:
              port: memcache
            initialDelaySeconds: 30
            timeoutSeconds: 5
            failureThreshold: 6
          readinessProbe:
            tcpSocket:
              port: memcache
            initialDelaySeconds: 5
            timeoutSeconds: 3
            periodSeconds: 5
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: tmp
              mountPath: /tmp
          securityContext:
            readOnlyRootFilesystem: false
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: oes/charts/minio/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
  selector:
    matchLabels:
      app: minio
      release: isd
  template:
    metadata:
      name: isd-minio
      labels:
        app: minio
        release: isd
      annotations:
        checksum/secrets: 0e7fab1c3058994997feaa92931063f8fc4c7f719d54fd3ef3459505a6a61533
        checksum/config: 7a7ac5513fcd53ca17fde80ebf50780809224b63001a3969ca32fcaf1caf5999
    spec:
      serviceAccountName: "isd-minio"
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: minio
          image: "minio/minio:RELEASE.2020-12-03T05-49-24Z"
          imagePullPolicy: IfNotPresent
          command:
            - "/bin/sh"
            - "-ce"
            - "/usr/bin/docker-entrypoint.sh minio -S /etc/minio/certs/ server /export"
          volumeMounts:
            - name: export
              mountPath: /export            
          ports:
            - name: http
              containerPort: 9000
          env:
            - name: MINIO_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: isd-minio
                  key: accesskey
            - name: MINIO_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: isd-minio
                  key: secretkey
          resources:
            requests:
              memory: 4Gi      
      volumes:
        - name: export
          persistentVolumeClaim:
            claimName: isd-minio
        - name: minio-user
          secret:
            secretName: isd-minio
---
# Source: oes/charts/openldap/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  name:  isd-openldap
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: openldap
      release: isd
  template:
    metadata:
      annotations:
        checksum/configmap-env: da8e0c8da82ff9254423b65018fe528f67823beb164b9f81ba49b04afd696558
        checksum/configmap-customldif: 3bf9905ca1d307472278add416a8fff6618651f0ef01b0dcaab0009017d48376
        moniker.spinnaker.io/application: spin
      labels:
        app: openldap
        release: isd
    spec:
      initContainers:
      - name: openldap-init-ldif
        image: quay.io/opsmxpublic/busybox:1.28
        command: ['sh', '-c', 'cp /customldif/* /ldifworkingdir']
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - name: customldif
          mountPath: /customldif
        - name: ldifworkingdir
          mountPath: /ldifworkingdir
        resources:
          {}
      containers:
        - name: openldap
          image: "osixia/openldap:1.2.4"
          lifecycle:
            postStart:
              exec:
                command:
                - /bin/sh
                - -c
                - until service slapd status; do sleep 10 ;done
          imagePullPolicy: IfNotPresent
          args: [--copy-service]
          ports:
            - name: ldap-port
              containerPort: 389
            - name: ssl-ldap-port
              containerPort: 636
          envFrom:
            - configMapRef:
                name: isd-openldap-env
            - secretRef:
                name: isd-openldap
          volumeMounts:
            - name: data
              mountPath: /var/lib/ldap
              subPath: data
            - name: data
              mountPath: /etc/ldap/slapd.d
              subPath: config-data
            - name: ldifworkingdir
              mountPath: /container/service/slapd/assets/config/bootstrap/ldif/custom
          env:
          livenessProbe:
            tcpSocket:
              port: ldap-port
            initialDelaySeconds: 20
            periodSeconds: 10
            failureThreshold: 10
          readinessProbe:
            tcpSocket:
              port: ldap-port
            initialDelaySeconds: 20
            periodSeconds: 10
            failureThreshold: 10
          resources:
            {}
      volumes:
        - name: customldif
          configMap:
            name: isd-openldap-customldif
        - name: ldifworkingdir
          emptyDir: {}
        - name: certs
          emptyDir:
            medium: Memory
        - name: data
          persistentVolumeClaim:
            claimName: isd-openldap
---
# Source: oes/templates/deployments/oes-audit-client.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: auditclient
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-audit-client
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: auditclient
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8098"
      labels:
        app: oes
        component: auditclient
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-audit-client:v4.0.0-ga 
        imagePullPolicy: IfNotPresent
        name: oes-audit-client
        ports:
        - containerPort: 8098
          name: backend
          protocol: TCP
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /mgmt/health
            port: 8098
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 1
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 8098
        volumeMounts:
        - mountPath: /opsmx/conf/audit-client-local.yml
          name: audit-config-volume
          subPath: audit-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
      volumes:
      - secret:
          items:
          - key: audit-local.yml
            path: audit-local.yml
          secretName: oes-audit-client-config
        name: audit-config-volume
      - name: bootstrap-config-volume
        secret:
          defaultMode: 420
          secretName: bootstrap
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-audit-service.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: auditservice
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-audit-service
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: auditservice
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "false"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8097"
      labels:
        app: oes
        component: auditservice
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-audit-service:v4.0.0-ga
        imagePullPolicy: IfNotPresent
        name: oes-audit
        ports:
        - containerPort: 8097
          name: backend
          protocol: TCP
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /mgmt/health
            port: 8097
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 1
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 8097
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /opsmx/conf/audit-service-local.yml
          name: audit-config-volume
          subPath: audit-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
      volumes:
      volumes:
      - secret:
          items:
          - key: audit-local.yml
            path: audit-local.yml
          secretName: oes-audit-service-config
        name: audit-config-volume
      - name: bootstrap-config-volume
        secret:
          defaultMode: 420
          secretName: bootstrap
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-autopilot-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  name: oes-autopilot
  labels:
    app: oes
    component: autopilot
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: autopilot
  template:
    metadata:
      labels:
        app: oes
        component: autopilot
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8090"
    spec:
      volumes:
        - name: autopilot-config-volume
          secret:
            secretName: oes-autopilot-config
        - secret:
            items:
            - key: bootstrap.yml
              path: bootstrap.yml
            secretName: bootstrap
          name: bootstrap-config-volume
        - configMap:
            defaultMode: 420
            items:
            - key: standard-error-codes.csv
              path: standard-error-codes.csv
            name: standard-error-codes-config
          name: standard-error-conf
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/postgres:9.6.5
        command: ['/bin/bash', '-c', "sleep 30;echo Waiting for oes-db to be up and running; pg_isready -h oes-db -p 5432 && echo PostgreSQL DB is ready to receive connections"]
      containers:
        - image: quay.io/opsmxpublic/ubi8-oes-autopilot:v4.0.0-ga
          imagePullPolicy: IfNotPresent
          name: oes-autopilot
          resources:
            {}
          ports:
            - containerPort: 8090
              name: backend
              protocol: TCP
            - containerPort: 9090
              name: metricfetcher
              protocol: TCP
          volumeMounts:
          - name: autopilot-config-volume
            mountPath: /opsmx/conf/autopilot.properties
            subPath: autopilot.properties
          - mountPath: /opsmx/conf/bootstrap.yml
            name: bootstrap-config-volume
            subPath: bootstrap.yml
          - mountPath: /opsmx/conf/standard-error-code.csv
            name: standard-error-conf
            subPath: standard-error-codes.csv
          readinessProbe:
            tcpSocket:
              port: 8090
            initialDelaySeconds: 60
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /mgmt/health
              port: 8090
            initialDelaySeconds: 120
            periodSeconds: 60
---
# Source: oes/templates/deployments/oes-dashboard-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: dashboard
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-dashboard
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: dashboard
  strategy: {}
  template:
    metadata:
      annotations:
        configmap/checksum: bfdbbd95b11053a548502713f0ae6f99111cd8f853d814981ca6ecf1c31231be
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8094"
      labels:
        app: oes
        component: dashboard
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-dashboard:v4.0.0-ga
        name: oes-dashboard
        ports:
        - containerPort: 8094
          protocol: TCP
        env:
        volumeMounts:
        - mountPath: /opsmx/conf/dashboard-local.yml
          name: dashboard-config
          subPath: dashboard-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8094
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8094
          initialDelaySeconds: 30
          periodSeconds: 60
      volumes:
      - name: dashboard-config
        configMap:
          name: oes-dashboard-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-datascience-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: datascience
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-datascience
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: datascience
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "false"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "5005"
      labels:
        app: oes
        component: datascience
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-datascience:v4.0.0-ga
        imagePullPolicy: IfNotPresent
        name: oes-datascience
        ports:
        - containerPort: 5005
          name: backend
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 5005
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /home/ubuntu/.aws/credentials
          name: datascience-config-volume
          subPath: minio-credentials
        - mountPath: /home/ubuntu/datascience/app_config.yaml
          name: datascience-config-volume
          subPath: app-config.yml
      volumes:
      - secret:
          secretName: oes-datascience-config
        name: datascience-config-volume
---
# Source: oes/templates/deployments/oes-gate-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-gate
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: gate
  template:
    metadata:
      annotations:
        checksum/secret: d22c48ada8d7fd174bd1f77f477f7da162a4a9d1044de79f4479d40061419156
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "false"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8084"
      labels:
        app: oes
        component: gate
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-gate:v4.0.0-ga
        name: oes-gate
        env:
        - name: spring_profiles_active
          value: vault,local
        ports:
        - containerPort: 8084
          protocol: TCP
        resources:
            {}
        volumeMounts:
        - name: gate-volume
          mountPath: /opt/spinnaker/config/gate.yml
          subPath: gate.yml
        - mountPath: /opt/spinnaker/config/bootstrap.yml
          name: bootstrap-volume
          subPath: bootstrap.yml
        readinessProbe:
          tcpSocket:
            port: 8084
          initialDelaySeconds: 60
          periodSeconds: 30
        livenessProbe:
          httpGet:
            path: /health
            port: 8084
          initialDelaySeconds: 60
          periodSeconds: 60
      volumes:
      - name: gate-volume
        secret:
          secretName: oes-gate-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-volume
---
# Source: oes/templates/deployments/oes-platform-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: platform
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-platform
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: platform
  strategy: {}
  template:
    metadata:
      annotations:
        checksum/secret: b31d775df09bdd28a2c765b4f9178fd898b56ccbf0de28b6f75ca63f7ffe031c
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8095"
      labels:
        app: oes
        component: platform
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
    spec:
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/postgres:9.6.5
        command: ['/bin/bash', '-c', "sleep 30;echo Waiting for oes-db to be up and running; pg_isready -h oes-db -p 5432 && echo PostgreSQL DB is ready to receive connections"]
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-platform:v4.0.0-ga
        name: oes-platform
        ports:
        - containerPort: 8095
          protocol: TCP
        env:
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8095
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8095
          initialDelaySeconds: 60
          periodSeconds: 60
        volumeMounts:
        - mountPath: /opsmx/conf/platform-local.yml
          name: platform-config-volume
          subPath: platform-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
      volumes:
      - name: platform-config-volume
        secret:
          secretName: oes-platform-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-rabbitmq-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: rabbitmq
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: rabbitmq
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: rabbitmq
  template:
    metadata:
      annotations:
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: rabbitmq
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
    spec:
      containers:
      - image: quay.io/opsmxpublic/rabbitmq:3-management
        imagePullPolicy: IfNotPresent
        name: rabbitmq
        ports:
        - containerPort: 5672
          protocol: TCP
        resources: {}
      restartPolicy: Always
      securityContext:
        fsGroup: 1000
---
# Source: oes/templates/deployments/oes-sapor-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: sapor
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-sapor
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: sapor
  template:
    metadata:
      annotations:
        checksum/configmap: 6c95be1ca406a7ad0e66338a5078da947d733a4304b8ab91941042bba1f82e8f
        checksum/configmap: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8085"
      labels:
        app: oes
        component: sapor
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
    spec:
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/postgres:9.6.5
        command: ['/bin/bash', '-c', "sleep 30;echo Waiting for oes-db to be up and running; pg_isready -h oes-db -p 5432 && echo PostgreSQL DB is ready to receive connections"]
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-sapor:v4.0.0-ga
        name: oes-sapor
        env:
        ports:
        - containerPort: 8085
          protocol: TCP
        volumeMounts:
        - mountPath: /opt/opsmx/controller/ca.crt	
          name: ca-certs-volume	
          subPath: tls.crt	
        - mountPath: /opt/opsmx/controller/cert/tls.crt	
          name: certs-volume	
          subPath: tls.crt	
        - mountPath: /opt/opsmx/controller/cert/tls.key	
          name: certs-volume	
          subPath: tls.key
        - name: sapor-config-volume
          mountPath: /opt/opsmx/application.yml
          subPath: application.yml
        - mountPath: /opt/opsmx/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8085
          initialDelaySeconds: 60
          periodSeconds: 10
          failureThreshold: 10
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8085
          initialDelaySeconds: 60
          periodSeconds: 10
          failureThreshold: 10
      volumes:
      - secret:
          secretName: oes-control-secret
        name: certs-volume
      - secret:
          secretName: ca-secret
        name: ca-certs-volume
      - secret:
          secretName: oes-sapor-config
        name: sapor-config-volume
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: sapor-bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-ui-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-ui
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: ui
  template:
    metadata:
      annotations:
        checksum/configmap: ec1928c046c894ea0592049ca7ba025a7b4a3760cc5ec54f4bcffe0637d0d957
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: ui
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-ui:v4.0.0-ga
        name: oes-ui
        ports:
        - containerPort: 8080
          protocol: TCP
        volumeMounts:
        - name: config-dir
          mountPath: /var/www/html/ui/assets/config/app-config.json
          subPath: app-config.json
        - name: config-dir
          mountPath: /var/www/html/ui/assets/config/help-text.json
          subPath: help-text.json
        - mountPath: /etc/nginx/nginx.conf
          name: nginx-config
          subPath: nginx.conf
        readinessProbe:
          tcpSocket:
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /ui/indexl.html
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 5
      volumes:
      - configMap:
          defaultMode: 420
          name: oes-ui-config
        name: config-dir
      - configMap:
          defaultMode: 420
          name: oes-ui-nginxconf
        name: nginx-config
---
# Source: oes/templates/deployments/oes-visibility-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: visibility
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-visibility
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: visibility
  strategy: {}
  template:
    metadata:
      annotations:
        configmap/checksum: d035e348c52a88f4d5258ca21b14324a95266f3c76451b7c3ece2c950379d26b
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8096"
      labels:
        app: oes
        component: visibility
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
    spec:
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/postgres:9.6.5
        command: ['/bin/bash', '-c', "sleep 30;echo Waiting for oes-db to be up and running; pg_isready -h oes-db -p 5432 && echo PostgreSQL DB is ready to receive connections"]
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-visibility:v4.0.0-ga
        name: oes-visibility
        ports:
        - containerPort: 8096
          protocol: TCP
        env:
        env:
        volumeMounts:
        - mountPath: /opsmx/conf/visibility-local.yml
          name: visibility-config
          subPath: visibility-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8096
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8096
          initialDelaySeconds: 30
          periodSeconds: 60
      volumes:
      - name: visibility-config
        secret:
          secretName: oes-visibility-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/opa-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: opa
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: opa
spec:
  replicas: 1
  selector:
    matchLabels:
      app: opa
  template:
    metadata:
      annotations:
        moniker.spinnaker.io/application: isd
      labels:
        app: opa
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
      name: opa
    spec:
      containers:
        - name: opa
          image: openpolicyagent/opa:latest
          args:
            - "run"
            - "--server"
        - name: opa-persist
          command: 
          - /bin/bash
          - /tmp/config/opa-persist.sh
          envFrom:
          - secretRef:
              name: oes-gate-secret
          image: quay.io/opsmxpublic/customterraformstage:v1
          imagePullPolicy: IfNotPresent
          volumeMounts:
          - mountPath: /tmp/config
            name: opa-persist
      restartPolicy: Always
      volumes:
        - configMap:
            defaultMode: 420
            name: opa-persist
          name: opa-persist
---
# Source: oes/templates/forwarder/oes-forwarder-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  name: opsmx-controller-controller1
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: opsmx-controller-controller1
  template:
    metadata:
      labels:
        app: opsmx-controller-controller1
        agent.opsmx.com/name: controller1
        agent.opsmx.com/role: controller
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
      annotations:
        pullversion: "16"
        checksum/configmap: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
    spec:
      containers:
      - name: opsmx-controller-controller1
        image: quay.io/opsmxpublic/forwarder-controller:v3.5.6
        ports:
          - containerPort: 9001
            name: agent-grpc
          - containerPort: 9002
            name: service-api
          - containerPort: 9003
            name: control-api
          - containerPort: 9004
            name: remote-command
          - containerPort: 9102
            name: metrics
        env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
        volumeMounts:
        - name: config
          mountPath: /app/config
          readOnly: true
        - name: ca-secret
          mountPath: /app/secrets/ca
          readOnly: true
        - name: jwt-secret
          mountPath: /app/secrets/serviceAuth
          readOnly: true
        resources:
          requests:
            memory: "64Mi"
            cpu: "100m"
          limits:
            memory: "128Mi"
            cpu: "250m"
      volumes:
      - name: ca-secret
        secret:
          secretName: ca-secret
      - name: jwt-secret
        secret:
          secretName: jwt-secret
      - name: config
        configMap:
          name: opsmx-controller-controller1
          items:
          - key: "configFile"
            path: "config.yaml"
---
# Source: oes/templates/sapor-gate/sapor-gate-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: sapor-gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: sapor-gate
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: sapor-gate
  template:
    metadata:
      annotations:
        checksum/secret: 68f74bcf539b143147ec93182922a9856aa8eeeaa1a0bf334cdb6b52608f954b
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: sapor-gate
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-spin-gate:v3.12.0-saporgate
        name: sapor-gate
        env:
        - name: JAVA_OPTS
          value: -XX:MaxRAMPercentage=100.0
        - name: SPRING_PROFILES_ACTIVE
          value: overrides,local
        ports:
        - containerPort: 8084
          protocol: TCP
        resources:
            {}
        volumeMounts:
        - mountPath: /opt/spinnaker/config
          name: sapor-gate-files
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: 8084
            scheme: HTTP
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
      volumes:
      - name: sapor-gate-files
        secret:
          secretName: sapor-gate-files
---
# Source: oes/charts/gitea/charts/postgresql/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: isd-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
  namespace: opsmx-isd
spec:
  serviceName: isd-postgresql-headless
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: isd
      role: primary
  template:
    metadata:
      name: isd-postgresql
      labels:
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-10.3.17
        app.kubernetes.io/instance: isd
        app.kubernetes.io/managed-by: Helm
        role: primary
        app.kubernetes.io/component: primary
    spec:      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/instance: isd
                    app.kubernetes.io/component: primary
                namespaces:
                  - "opsmx-isd"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      containers:
        - name: isd-postgresql
          image: docker.io/bitnami/postgresql:11.11.0-debian-10-r62
          imagePullPolicy: "IfNotPresent"
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: isd-postgresql
                  key: postgresql-postgres-password
            - name: POSTGRES_USER
              value: "gitea"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: isd-postgresql
                  key: postgresql-password
            - name: POSTGRES_DB
              value: "gitea"
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "gitea" -d "dbname=gitea" -h 127.0.0.1 -p 5432
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "gitea" -d "dbname=gitea" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
              subPath: 
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 1Gi
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "10Gi"
---
# Source: oes/charts/gitea/templates/gitea/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: isd-gitea
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: gitea
      app.kubernetes.io/instance: isd
  serviceName: isd-gitea
  template:
    metadata:
      annotations:
        checksum/config: 9d002fd7ae2d1eb91f8238f5d0f2896011847d3d71b8dc12d45add370e19de9c
      labels:
        helm.sh/chart: gitea-5.0.1
        app: gitea
        app.kubernetes.io/name: gitea
        app.kubernetes.io/instance: isd
        app.kubernetes.io/version: "1.15.10"
        version: "1.15.10"
        app.kubernetes.io/managed-by: Helm
    spec:
      securityContext:
        fsGroup: 1000
      initContainers:
        - name: init-directories
          image: "gitea/gitea:1.15.10"
          command: ["/usr/sbin/init_directory_structure.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
          securityContext:
            {}
        - name: init-app-ini
          image: "gitea/gitea:1.15.10"
          command: ["/usr/sbin/config_environment.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
          volumeMounts:
            - name: config
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
            - name: inline-config-sources
              mountPath: /env-to-ini-mounts/inlines/
          securityContext:
            {}
        - name: configure-gitea
          image: "gitea/gitea:1.15.10"
          command: ["/usr/sbin/configure_gitea.sh"]
          securityContext:
            runAsUser: 1000
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: GITEA_ADMIN_USERNAME
              valueFrom:
                secretKeyRef:
                  key:  username
                  name: gitea-secret
            - name: GITEA_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  key:  password
                  name: gitea-secret
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
      terminationGracePeriodSeconds: 60
      containers:
        - name: gitea
          image: "gitea/gitea:1.15.10"
          imagePullPolicy: Always
          env:
            # SSH Port values have to be set here as well for openssh configuration
            - name: SSH_LISTEN_PORT
              value: "22"
            - name: SSH_PORT
              value: "22"
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: TMPDIR
              value: /tmp/gitea
          ports:
            - name: ssh
              containerPort: 22
            - name: http
              containerPort: 3000
          livenessProbe:
            failureThreshold: 10
            initialDelaySeconds: 200
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: http
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: http
            timeoutSeconds: 1
          resources:
            {}
          securityContext:
            {}
          volumeMounts:
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
      volumes:
        - name: init
          secret:
            secretName: isd-gitea-init
            defaultMode: 110
        - name: config
          secret:
            secretName: isd-gitea
            defaultMode: 110
        - name: inline-config-sources
          secret:
            secretName: isd-gitea-inline-config
        - name: temp
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
            - "ReadWriteOnce"
        resources:
          requests:
            storage: "10Gi"
---
# Source: oes/charts/redis/templates/redis-master-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  name: isd-redis-master
  labels:
    app: redis
    chart: redis-10.5.3
    release: isd
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: redis
      release: isd
      role: master
  serviceName: isd-redis-headless
  template:
    metadata:
      labels:
        app: redis
        chart: redis-10.5.3
        release: isd
        role: master
      annotations:
        checksum/health: 36567aac6587929dc97be63c28c0aa1ec58d167572f3e5f191536195dc588d15
        checksum/configmap: 42a460f87c190197092321f0ae70720d271a2f6738150858f02b13ca057dae95
        checksum/secret: 92c3542fca96bee16e081be3a51ac49fa2ad66360cd283b768155ca7bae80c9e
        moniker.spinnaker.io/application: spin
    spec:      
      securityContext:
        fsGroup: 1001
      serviceAccountName: "default"
      containers:
      - name: isd-redis
        image: "quay.io/opsmxpublic/bitnami-redis:5.0.7-debian-10-r0"
        imagePullPolicy: "IfNotPresent"
        securityContext:
          runAsUser: 1001
        command:
        - /bin/bash
        - -c
        - |
          if [[ -n $REDIS_PASSWORD_FILE ]]; then
            password_aux=`cat ${REDIS_PASSWORD_FILE}`
            export REDIS_PASSWORD=$password_aux
          fi
          if [[ ! -f /opt/bitnami/redis/etc/master.conf ]];then
            cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
          fi
          if [[ ! -f /opt/bitnami/redis/etc/redis.conf ]];then
            cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
          fi
          ARGS=("--port" "${REDIS_PORT}")
          ARGS+=("--requirepass" "${REDIS_PASSWORD}")
          ARGS+=("--masterauth" "${REDIS_PASSWORD}")
          ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
          ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
          /run.sh ${ARGS[@]}
        env:
        - name: REDIS_REPLICATION_MODE
          value: master
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: isd-redis
              key: redis-password
        - name: REDIS_PORT
          value: "6379"
        ports:
        - name: redis
          containerPort: 6379
        livenessProbe:
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
            - sh
            - -c
            - /health/ping_liveness_local.sh 5
        readinessProbe:
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 1
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
            - sh
            - -c
            - /health/ping_readiness_local.sh 5
        resources:
          null
        volumeMounts:
        - name: health
          mountPath: /health
        - name: redis-data
          mountPath: /data
          subPath: 
        - name: config
          mountPath: /opt/bitnami/redis/mounted-etc
        - name: redis-tmp-conf
          mountPath: /opt/bitnami/redis/etc/
      volumes:
      - name: health
        configMap:
          name: isd-redis-health
          defaultMode: 0755
      - name: config
        configMap:
          name: isd-redis
      - name: redis-tmp-conf
        emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: redis-data
        labels:
          app: redis
          release: isd
          heritage: Helm
          component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
        
        selector:
  updateStrategy:
    type: RollingUpdate
---
# Source: oes/charts/spinnaker/templates/statefulsets/halyard.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    moniker.spinnaker.io/application: spin
  name: isd-spinnaker-halyard
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
spec:
  serviceName: isd-spinnaker-halyard
  replicas: 1
  selector:
    matchLabels:
      app: "isd-spinnaker"
      release: "isd"
      component: halyard
  template:
    metadata:
      annotations:
        checksum/configmap: 5a6f7f890a2803cc44c28ae081e3d6a183842c11a8df742724b4d4e023e47249
        moniker.spinnaker.io/application: spin
      labels:
        app: "isd-spinnaker"
        heritage: "Helm"
        release: "isd"
        chart: "spinnaker-2.2.3"
        component: halyard
    spec:
      serviceAccountName: isd-spinnaker-halyard
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      initContainers:
      - name: "create-halyard-local"
        image: quay.io/opsmxpublic/awsgit:v2-openssh-javalibs
        command:
        - sh
        - /tmp/initscript/init.sh
        env:
        - name: SPINNAKER_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: GITEA_USER
          valueFrom:
            secretKeyRef:
              name: gitea-secret
              key: username
        - name: GITEA_PASS
          valueFrom:
            secretKeyRef:
              name: gitea-secret
              key: password
        volumeMounts:
        - name: halyard-config
          mountPath: /tmp/config
        - name: service-settings
          mountPath: /tmp/service-settings
        - name: halyard-home
          mountPath: /tmp/spinnaker
        - name: additional-profile-config-maps
          mountPath: /tmp/additionalProfileConfigMaps
        - name: halyard-initscript
          mountPath: /tmp/initscript
      - name: "halyardconfig-update"
        command:
        - sh
        - /tmp/akv2k8s/run.sh
        image: quay.io/opsmxpublic/k8s-decoder:hal
        imagePullPolicy: IfNotPresent
        resources: {}
        volumeMounts:
        - name: halyard-home
          mountPath: /tmp/spinnaker
        - name: secret-decoder
          mountPath: /tmp/akv2k8s
      - name: "halyard-overrideurl"
        command:
        - sh
        - /tmp/autoconfig/call_overrides.sh
        env:
        - name: NODE_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.hostIP
        image: quay.io/opsmxpublic/bitnami-kubectl:1.18.5
        imagePullPolicy: IfNotPresent
        resources: {}
        volumeMounts:
        - name: halyard-config
          mountPath: /tmp/config
        - name: service-settings
          mountPath: /tmp/service-settings
        - name: halyard-home
          mountPath: /tmp/spinnaker
        - name: additional-profile-config-maps
          mountPath: /tmp/additionalProfileConfigMaps
        - name: halyard-initscript
          mountPath: /tmp/initscript
        - mountPath: /tmp/autoconfig
          name: halyard-overrideurl
      volumes:
      - name: halyard-home
        emptyDir: {}
      - name: halyard-overrideurl
        configMap:
          name: isd-spinnaker-halyard-overrideurl
      - name: secret-decoder
        configMap:
          name: isd-spinnaker-spin-secret-decoder
      - name: reg-secrets
        secret:
          secretName: isd-spinnaker-registry
      - name: additional-profile-config-maps
        configMap:
          name: isd-spinnaker-additional-profile-config-maps
      - name: halyard-config
        emptyDir: {}
      - name: service-settings
        configMap:
          name: isd-spinnaker-service-settings
      - name: halyard-initscript
        configMap:
          name: isd-spinnaker-halyard-init-script
      containers:
      - name: halyard
        image: quay.io/opsmxpublic/ubi8-spin-halyard:1.27.0-v4.0-ga
        lifecycle:
          postStart:
            exec:
              command: ["/bin/sh", "-c", "until curl http://localhost:8064/health; do sleep 10 ;done;hal deploy apply"]
        ports:
        - containerPort: 8064
          name: daemon
        volumeMounts:
        - name: halyard-home
          mountPath: /home/spinnaker
        - name: halyard-config
          mountPath: /opt/halyard/config
        - name: reg-secrets
          mountPath: /opt/registry/passwords
---
# Source: oes/templates/statefulsets/oes-db-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: db
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-db
spec:
  podManagementPolicy: OrderedReady
  replicas: 1
  serviceName: oes-db
  selector:
    matchLabels:
      app: oes
      component: db
  template:
    metadata:
      annotations:
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: db
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-db:v3.0.0
        imagePullPolicy: IfNotPresent
        name: oes-db
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - /opt/opsmx/bin/stop.sh
        ports:
        - containerPort: 5432
          protocol: TCP
        volumeMounts:
        - mountPath: "/var/lib/pgsql-pv"
          name: oes-db-postgresql
        readinessProbe:
          tcpSocket:
            port: 5432
          initialDelaySeconds: 10
          periodSeconds: 5
      securityContext:
        fsGroup: 1000
  volumeClaimTemplates:
  - metadata:
      creationTimestamp: null
      labels:
        app: oes
        component: db
      name: oes-db-postgresql
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 8Gi
      volumeMode: Filesystem
---
# Source: oes/charts/spinnaker/templates/deployments/create-sample-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: isd-create-sample-app
spec:
  template:
    spec:
      serviceAccountName: isd-spinnaker-halyard
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      restartPolicy: OnFailure
      volumes:
      - secret:
          secretName: isd-spinnaker-spin-config
        name: spin-config
      - configMap:
          defaultMode: 420
          name: isd-spinnaker-spin-pipeline-import
        name: spin-pipeline-import
      - name: spin-pipeline-config
        emptyDir: {}
      containers:
      - command:  
        - bash
        - /tmp/config/spin-pipeline-import.sh
        name: sample-pipeline-install
        image: quay.io/opsmxpublic/spin-sample-pipeline:1.0
        volumeMounts:         
        - name: spin-pipeline-config
          mountPath: /tmp/config/git
        - mountPath: /tmp/config
          name: spin-pipeline-import
        - mountPath: /tmp/config/spin
          name: spin-config
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: create-controller-secret
spec:
 template:
    spec:
       containers:
       - name: create-secret-container
         image: quay.io/opsmxpublic/create-secret:v20211127T140816
         env:
         - name: NAMESPACE
           valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
         args: 
         - "$(NAMESPACE)" 
       restartPolicy: Never
       serviceAccount: create-controller-secret
---
# Source: oes/charts/minio/templates/post-install-create-bucket-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: isd-minio-make-bucket-job
  labels:
    app: minio-make-bucket-job
    chart: minio-8.0.9
    release: isd
    heritage: Helm
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  template:
    metadata:
      labels:
        app: minio-job
        release: isd
    spec:
      restartPolicy: OnFailure      
      volumes:
        - name: minio-configuration
          projected:
            sources:
            - configMap:
                name: isd-minio
            - secret:
                name: isd-minio
      serviceAccountName: "isd-minio"
      containers:
      - name: minio-mc
        image: "minio/mc:RELEASE.2020-11-25T23-04-07Z"
        imagePullPolicy: IfNotPresent
        command: ["/bin/sh", "/config/initialize"]
        env:
          - name: MINIO_ENDPOINT
            value: isd-minio
          - name: MINIO_PORT
            value: "9000"
        volumeMounts:
          - name: minio-configuration
            mountPath: /config
        resources:
          requests:
            memory: 128Mi
---
# Source: oes/charts/spinnaker/templates/hooks/install-using-hal.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "isd-install-using-hal"
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
  annotations:
    "helm.sh/hook": "post-install,post-upgrade"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "0"
spec:
  template:
    metadata:
      annotations:
        checksum/config: b9f024c5a50e164ebc0950cf85a3fb7a12c5d63d5ca8ad7023000c7e3aad2b22
        moniker.spinnaker.io/application: spin
      labels:
        app: "isd-spinnaker"
        heritage: "Helm"
        release: "isd"
        chart: "spinnaker-2.2.3"
    spec:
      serviceAccountName: isd-spinnaker-halyard
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      restartPolicy: OnFailure
      volumes:
      - name: halyard-config
        configMap:
          name: isd-spinnaker-halyard-config
      containers:
      - name: halyard-install
        image: quay.io/opsmxpublic/ubi8-spin-halyard:1.27.0-v4.0-ga
        volumeMounts:
        - name: halyard-config
          mountPath: /opt/halyard/scripts
        command:
        - bash
        - -xe
        - "/opt/halyard/scripts/install.sh"
        env:
        - name: NODE_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.hostIP
---
# Source: oes/templates/hooks/oes-config-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
    "helm.sh/hook": "post-install,post-upgrade"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "5"
  labels:
    app: oes
    component: oes-config
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.4"
  name: oes-config
spec:
  template:
    metadata:
      annotations:
        checksum/configmap: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: oes-config
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.4"
    spec:
      containers:
      - command: ["bash", "/tmp/config/datasource-api.sh" ]
        name: datasource-creation-api
        image: quay.io/opsmxpublic/oes-pre-configure:v2
        volumeMounts:
        - mountPath: /tmp/config
          name: datasource-creation
      restartPolicy: OnFailure
      volumes:
      - configMap:
          defaultMode: 420
          name: isd-oes-datasource-creation
        name: datasource-creation
