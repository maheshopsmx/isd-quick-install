---
# Source: oes/charts/gitea/charts/memcached/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: isd-memcached
  namespace: opsmx-isd
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-5.9.0
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
---
# Source: oes/charts/minio/templates/post-install-prometheus-metrics-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: isd-minio-update-prometheus-secret
  labels:
    app: minio-update-prometheus-secret
    chart: minio-8.0.9
    release: isd
    heritage: Helm
---
# Source: oes/charts/minio/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "isd-minio"
  namespace: "opsmx-isd"
  labels:
    app: minio
    chart: minio-8.0.9
    release: "isd"
---
# Source: oes/charts/spinnaker/templates/rbac/halyard-sa.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: isd-spinnaker-halyard
  namespace: opsmx-isd
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: create-controller-secret
---
# Source: oes/charts/gitea/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
  namespace: opsmx-isd
type: Opaque
data:
  postgresql-postgres-password: "eHVUcVNIR1piag=="
  postgresql-password: "Z2l0ZWE="
---
# Source: oes/charts/gitea/templates/gitea/config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-gitea-inline-config
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  _generals_: ""
  cache: |-
    ADAPTER=memcache
    ENABLED=true
    HOST=isd-memcached.opsmx-isd.svc.cluster.local:11211
  database: |-
    DB_TYPE=postgres
    HOST=isd-postgresql.opsmx-isd.svc.cluster.local:5432
    NAME=gitea
    PASSWD=gitea
    USER=gitea
  metrics: ENABLED=false
  repository: ROOT=/data/git/gitea-repositories
  security: INSTALL_LOCK=true
  server: |-
    APP_DATA_PATH=/data
    DOMAIN=git.example.com
    ENABLE_PPROF=false
    HTTP_PORT=3000
    PROTOCOL=http
    ROOT_URL=http://git.example.com
    SSH_DOMAIN=git.example.com
    SSH_LISTEN_PORT=22
    SSH_PORT=22
---
# Source: oes/charts/gitea/templates/gitea/config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-gitea
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  config_environment.sh: |-
    #!/usr/bin/env bash
    set -euo pipefail

    function env2ini::log() {
      printf "${1}\n"
    }

    function env2ini::read_config_to_env() {
      local section="${1}"
      local line="${2}"

      if [[ -z "${line}" ]]; then
        # skip empty line
        return
      fi
      
      # 'xargs echo -n' trims all leading/trailing whitespaces and a trailing new line
      local setting="$(awk -F '=' '{print $1}' <<< "${line}" | xargs echo -n)"

      if [[ -z "${setting}" ]]; then
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      local value=''
      local regex="^${setting}(\s*)=(\s*)(.*)"
      if [[ $line =~ $regex ]]; then
        value="${BASH_REMATCH[3]}"
      else
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      env2ini::log "    + '${setting}'"

      if [[ -z "${section}" ]]; then
        export "ENV_TO_INI____${setting^^}=${value}"                           # '^^' makes the variable content uppercase
        return
      fi

      local masked_section="${section//./_0X2E_}"                            # '//' instructs to replace all matches
      masked_section="${masked_section//-/_0X2D_}"

      export "ENV_TO_INI__${masked_section^^}__${setting^^}=${value}"        # '^^' makes the variable content uppercase
    }

    function env2ini::process_config_file() {
      local config_file="${1}"
      local section="$(basename "${config_file}")"

      if [[ $section == '_generals_' ]]; then
        env2ini::log "  [ini root]"
        section=''
      else
        env2ini::log "  ${section}"
      fi

      while read -r line; do
        env2ini::read_config_to_env "${section}" "${line}"
      done < <(awk 1 "${config_file}")                             # Helm .toYaml trims the trailing new line which breaks line processing; awk 1 ... adds it back while reading
    }

    function env2ini::load_config_sources() {
      local path="${1}"

      env2ini::log "Processing $(basename "${path}")..."

      while read -d '' configFile; do
        env2ini::process_config_file "${configFile}"
      done < <(find "${path}" -type l -not -name '..data' -print0)

      env2ini::log "\n"
    }

    function env2ini::generate_initial_secrets() {
      # These environment variables will either be
      #   - overwritten with user defined values,
      #   - initially used to set up Gitea
      # Anyway, they won't harm existing app.ini files

      export ENV_TO_INI__SECURITY__INTERNAL_TOKEN=$(gitea generate secret INTERNAL_TOKEN)
      export ENV_TO_INI__SECURITY__SECRET_KEY=$(gitea generate secret SECRET_KEY)
      export ENV_TO_INI__OAUTH2__JWT_SECRET=$(gitea generate secret JWT_SECRET)

      env2ini::log "...Initial secrets generated\n"
    }

    # MUST BE CALLED BEFORE OTHER CONFIGURATION
    env2ini::generate_initial_secrets

    env2ini::load_config_sources '/env-to-ini-mounts/inlines/'
    env2ini::load_config_sources '/env-to-ini-mounts/additionals/'

    env2ini::log "=== All configuration sources loaded ===\n"

    # safety to prevent rewrite of secret keys if an app.ini already exists
    if [ -f ${GITEA_APP_INI} ]; then
      env2ini::log 'An app.ini file already exists. To prevent overwriting secret keys, these settings are dropped and remain unchanged:'
      env2ini::log '  - security.INTERNAL_TOKEN'
      env2ini::log '  - security.SECRET_KEY'
      env2ini::log '  - oauth2.JWT_SECRET'

      unset ENV_TO_INI__SECURITY__INTERNAL_TOKEN
      unset ENV_TO_INI__SECURITY__SECRET_KEY
      unset ENV_TO_INI__OAUTH2__JWT_SECRET
    fi

    environment-to-ini -o $GITEA_APP_INI -p ENV_TO_INI
---
# Source: oes/charts/gitea/templates/gitea/init.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-gitea-init
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  init_directory_structure.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail

    set -x
    chown 1000:1000 /data
    mkdir -p /data/git/.ssh
    chmod -R 700 /data/git/.ssh
    [ ! -d /data/gitea ] && mkdir -p /data/gitea/conf

    # prepare temp directory structure
    mkdir -p "${GITEA_TEMP}"
    chown 1000:1000 "${GITEA_TEMP}"
    chmod ug+rwx "${GITEA_TEMP}"

  configure_gitea.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail
    # Connection retry inspired by https://gist.github.com/dublx/e99ea94858c07d2ca6de
    function test_db_connection() {
      local RETRY=0
      local MAX=30

      echo 'Wait for database to become avialable...'
      until [ "${RETRY}" -ge "${MAX}" ]; do
        nc -vz -w2 isd-postgresql 5432 && break
        RETRY=$[${RETRY}+1]
        echo "...not ready yet (${RETRY}/${MAX})"
      done

      if [ "${RETRY}" -ge "${MAX}" ]; then
        echo "Database not reachable after '${MAX}' attempts!"
        exit 1
      fi
    }

    test_db_connection

    echo '==== BEGIN GITEA CONFIGURATION ===='

    gitea migrate
    function configure_admin_user() {
      local ACCOUNT_ID=$(gitea admin user list --admin | grep -e "\s\+${GITEA_ADMIN_USERNAME}\s\+" | awk -F " " "{printf \$1}")
      if [[ -z "${ACCOUNT_ID}" ]]; then
        echo "No admin user '${GITEA_ADMIN_USERNAME}' found. Creating now..."
        gitea admin user create --admin --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}" --email "support@opsmx.com" --must-change-password=false
        echo '...created.'
      else
        echo "Admin account '${GITEA_ADMIN_USERNAME}' already exist. Running update to sync password..."
        gitea admin user change-password --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}"
        echo '...password sync done.'
      fi
    }

    configure_admin_user

    function configure_ldap() {
        echo 'no ldap configuration... skipping.'
    }

    configure_ldap

    function configure_oauth() {
        echo 'no oauth configuration... skipping.'
    }

    configure_oauth

    echo '==== END GITEA CONFIGURATION ===='
---
# Source: oes/charts/minio/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
type: Opaque
data:
  accesskey: "c3Bpbm5ha2VyYWRtaW4="
  secretkey: "c3Bpbm5ha2VyYWRtaW4="
---
# Source: oes/charts/openldap/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-openldap
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
type: Opaque
data:
  LDAP_ADMIN_PASSWORD: "b3BzbXhhZG1pbjEyMw=="
  LDAP_CONFIG_PASSWORD: "b3BzbXhjb25maWcxMjM="
---
# Source: oes/charts/redis/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-redis
  labels:
    app: redis
    chart: redis-10.5.3
    release: "isd"
    heritage: "Helm"
type: Opaque
data:
  redis-password: "cGFzc3dvcmQ="
---
# Source: oes/charts/spinnaker/templates/secrets/registry.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-spinnaker-registry
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
    component: clouddriver
type: Opaque
data:
  dockerhub: ""
---
# Source: oes/charts/spinnaker/templates/secrets/spin-config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-spinnaker-spin-config
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
stringData:
  config: |
    auth:
      basic:
        password: saporadmin
        username: admin
      enabled: true
    gate:
      endpoint: http://sapor-gate:8084
---
# Source: oes/templates/pipeline-promotion/local-spin-cli-config-secret.yaml
apiVersion: v1
stringData:
  # Spin CLI config content used by syncToSpinnaker stage
  # It is placed under ~/.spin/config
  # endpoint should be the spinnaker gate where pipelines are created/updated
  config: |-
    auth:
      basic:
        password: saporadmin
        username: admin
      enabled: true
    gate:
      endpoint: http://sapor-gate:8084
kind: Secret
metadata:
  name: local-spin-cli-config
---
# Source: oes/templates/pipeline-promotion/spin-cli-config-secret.yaml
apiVersion: v1
stringData:
  # Spin CLI config content used by syncToGit stage
  # It is placed under ~/.spin/config
  # custom job stage runs a spin cli and fetches the application/pipeline data
  # gate endpoint should point to the spinnaker from where application/pipeline data is fetched
  config: |-
    auth:
      basic:
        password: saporadmin
        username: admin
      enabled: true
    gate:
      endpoint: http://sapor-gate:8084
kind: Secret
metadata:
  name: spin-cli-config
---
# Source: oes/templates/sapor-gate/sapor-gate-secret.yaml
apiVersion: v1
data:
  gate-local.yml:
    c2VydmVyOgogIHRvbWNhdDoKICAgIGh0dHBzU2VydmVyUG9ydDogWC1Gb3J3YXJkZWQtUG9ydAogICAgaW50ZXJuYWxQcm94aWVzOiAuKgogICAgcHJvdG9jb2xIZWFkZXI6IFgtRm9yd2FyZGVkLVByb3RvCiAgICByZW1vdGVJcEhlYWRlcjogWC1Gb3J3YXJkZWQtRm9yCnNlY3VyaXR5OgogIGJhc2ljZm9ybToKICAgIGVuYWJsZWQ6IHRydWUKICB1c2VyOgogICAgbmFtZTogYWRtaW4KICAgIHBhc3N3b3JkOiBzYXBvcmFkbWluCiAgICByb2xlczogYWRtaW4K
  gate-overrides.yml:
    IyMgV0FSTklORwojIyBUaGlzIGZpbGUgd2FzIGF1dG9nZW5lcmF0ZWQsIGFuZCBfd2lsbF8gYmUgb3ZlcndyaXR0ZW4gYnkgSGFseWFyZC4KIyMgQW55IGVkaXRzIHlvdSBtYWtlIGhlcmUgX3dpbGxfIGJlIGxvc3QuCgpzZXJ2aWNlczoKICBjbG91ZGRyaXZlcjoKICAgIGJhc2VVcmw6IGh0dHA6Ly9zcGluLWNsb3VkZHJpdmVyLXJvOjcwMDIKICAgIGVuYWJsZWQ6IHRydWUKICBlY2hvOgogICAgYmFzZVVybDogaHR0cDovL3NwaW4tZWNoby13b3JrZXI6ODA4OQogICAgZW5hYmxlZDogdHJ1ZQoKZ2xvYmFsLnNwaW5uYWtlci50aW1lem9uZTogQW1lcmljYS9Mb3NfQW5nZWxlcw==
  gate.yml:
    IyMgV0FSTklORwojIyBUaGlzIGZpbGUgd2FzIGF1dG9nZW5lcmF0ZWQsIGFuZCBfd2lsbF8gYmUgb3ZlcndyaXR0ZW4gYnkgSGFseWFyZC4KIyMgQW55IGVkaXRzIHlvdSBtYWtlIGhlcmUgX3dpbGxfIGJlIGxvc3QuCgpzcGVjdGF0b3I6CiAgYXBwbGljYXRpb25OYW1lOiAke3NwcmluZy5hcHBsaWNhdGlvbi5uYW1lfQogIHdlYkVuZHBvaW50OgogICAgZW5hYmxlZDogZmFsc2UKCnNwaW5uYWtlcjoKICBleHRlbnNpYmlsaXR5OgogICAgcGx1Z2luczoge30KICAgIHJlcG9zaXRvcmllczoge30KICAgIHBsdWdpbnMtcm9vdC1wYXRoOiAvb3B0L2dhdGUvcGx1Z2lucwogICAgc3RyaWN0LXBsdWdpbi1sb2FkaW5nOiBmYWxzZQoKc2VydmVyOgogIHNzbDoKICAgIGVuYWJsZWQ6IGZhbHNlCiAgcG9ydDogJzgwODQnCiAgYWRkcmVzczogMC4wLjAuMApzZWN1cml0eToKICBiYXNpYzoKICAgIGVuYWJsZWQ6IHRydWUKICB1c2VyOiB7fQpjb3JzOiB7fQpnb29nbGU6IHt9CgppbnRlZ3JhdGlvbnM6CiAgZ3JlbWxpbjoKICAgIGVuYWJsZWQ6IGZhbHNlCiAgICBiYXNlVXJsOiBodHRwczovL2FwaS5ncmVtbGluLmNvbS92MQoKIyBoYWxjb25maWcKCnNlcnZpY2VzOgogIGNsb3VkZHJpdmVyOgogICAgY29uZmlnOgogICAgICBkeW5hbWljRW5kcG9pbnRzOgogICAgICAgIGRlY2s6IGh0dHA6Ly9zcGluLWNsb3VkZHJpdmVyLXJvLWRlY2s6NzAwMgogIHBsYXRmb3JtOgogICAgYmFzZVVybDogaHR0cDovL29lcy1wbGF0Zm9ybTo4MDk1CiAgICB1c2VyR3JvdXBBcGlQYXRoOiAvcGxhdGZvcm1zZXJ2aWNlL3YxL3VzZXJzL3t1c2VybmFtZX0vdXNlcmdyb3Vwcy9pbXBvcnRBbmRDYWNoZQogICAgZW5hYmxlZDogdHJ1ZQo=
  spinnaker.yml:
    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
  spinnakerconfig.yml:
    I0VtcHR5IGZpbGUK
kind: Secret
metadata:
  labels:
    app: oes
    component: sapor-gate
  name: sapor-gate-files
type: Opaque
---
# Source: oes/templates/secrets/bootstrap-secret.yaml
apiVersion: v1
stringData:
  bootstrap.yml: |-
    spring:
      cloud:
        vault:
          enterprise: false
          namespace: admin/isd-platform
          uri: https://server.vaultint.opsmx.net
          token: 123132
          enabled: false
          kv:
            enabled: false
          generic:
            enabled: false
    jasypt:
      encryptor:
        password: Q7udUkHPuA3VnNlOtksSgQ
    datasource:
      secretManagement:
        source: db
kind: Secret
metadata:
  name: bootstrap
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
---
# Source: oes/templates/secrets/gitea-secret.yaml
apiVersion: v1
stringData:
  # Repo uri to fetch halyard configuration
  username: opsmx 
  password: opsmxadmin123
kind: Secret
metadata:
  name: gitea-secret
type: Opaque
---
# Source: oes/templates/secrets/oes-audit-client-secret.yaml
apiVersion: v1
stringData:
  audit-local.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/auditdb
        username: 'postgres'
        password: 'networks123'
    logging:
      level:
        com.opsmx.auditclientservice: INFO
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    oes:
      admin:
        user: admin
    feign:
      client:
        platformservice:
          name: platformservice
          url: http://oes-platform:8095
        visibilityservice:
          name: visibilityservice
          url: http://oes-visibility:8096
    
    fixedDelay:
      in:
        milliseconds: 120000
    initialDelay:
      in:
        milliseconds: 300000
    scheduler:
      threads: 16
    
kind: Secret
metadata:
  labels:
    app: oes
    component: auditclient
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-audit-client-config
---
# Source: oes/templates/secrets/oes-audit-service-secret.yaml
apiVersion: v1
stringData:
  audit-local.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/auditdb
        username: 'postgres'
        password: 'networks123'
    logging:
        level:
          com.opsmx.auditservice: INFO
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    feign:
      client:
        platformservice:
          name: platformservice
          url: http://oes-platform:8095
        auditclientservice:
          name: auditclientservice
          url: http://oes-audit-client:8098
        oes:
          url: http://oes-sapor:8085
        autopilot:
          url: http://oes-autopilot:8090
        visibilityservice:
          url: http://oes-visibility:8096
        dashboard:
          url: http://oes-dashboard:8094
    
kind: Secret
metadata:
  labels:
    app: oes
    component: auditservice
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-audit-service-config
---
# Source: oes/templates/secrets/oes-autopilot-secret.yaml
apiVersion: v1
stringData:
  autopilot.properties: |
    # Enable Build Analysis
    build.analysis=false
    # DB configuration
    secret.datasource.username=postgres
    secret.datasource.password=networks123
    secret.datasource.url=jdbc:postgresql://oes-db:5432/opsmx
    secret.platform.url=http://oes-platform:8095
    secret.ds.protocol=http://
    secret.ds.url=localhost:5005
    
    server.host.dns.name=http://oes.example.ops.com/ui
    
    gate.url=http://oes-gate:8084
    
    #datascience configuration
    oes.datascience.baseUrl=http://oes-datascience:5005
    #build.analysis=false
    ds.async.flow=true
    
    # Standard-error-path
    standardErrorCodes.filePath=/opsmx/conf/standard-error-code.csv
    
    #storage configuration
    storage.type =db_storage
    #storage.type =object_storage
    #storage.endpoint=http://isd-minio:9000
    #storage.accesskey = spinnakeradmin
    #storage.secretkey = spinnakeradmin
    #storage.region= us-east-1
    ds.seperate.service=true
    
    
    # Logging Level
    logging.level.com.opsmx.analytics=ERROR
    datasource.secretManagement.source = db
    
kind: Secret
metadata:
  name: oes-autopilot-config
  labels:
    app: oes
    component: autopilot
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
---
# Source: oes/templates/secrets/oes-datascience-secret.yaml
apiVersion: v1
stringData:
  app-config.yml: |
    # Enable Build Analysis
    APP:
       ENVIRONMENT: dev
       DEBUG: True
       # Only accept True or False
       BIND: 0.0.0.0:5005
       WORKERS: 1
       PROTOCOL: http://
       TIMEOUT: 3600
       CELERY_ENABLED: True
       # Only accept True or False
    
    OBJECT_STORAGE:
          ENDPOINT: http://isd-minio:9000
          BUCKET_NAME: autopilot
    POSTGRES:
          USERNAME: 'postgres'
          PASSWORD: 'networks123'
          HOST: oes-db
          PORT: 5432
          DB: autopilotqueue
    
    RABBITMQ:
          USERNAME: 'rabbitmq'
          PASSWORD: 'Networks123'
          HOST: rabbitmq-service
          PORT: 5672
    
  minio-credentials: |
    [default]
        aws_access_key_id = spinnakeradmin
        aws_secret_access_key = spinnakeradmin
    
    
kind: Secret
metadata:
  labels:
    app: oes
    component: datascience
  name: oes-datascience-config
---
# Source: oes/templates/secrets/oes-gate-configmap.yaml
apiVersion: v1
stringData:
  gate.yml: |
    retrofit:
      connectTimeout: 60000
      readTimeout: 60000
      callTimeout: 60000
      writeTimeout: 60000
      retryOnConnectionFailure: true
    services:
      opsmx:
        baseUrl: http://oes-sapor:8085
        enabled: true
      autopilot:
        baseUrl: http://oes-autopilot:8090
        enabled: true
      platform:
        baseUrl: http://oes-platform:8095
        userGroupApiPath: /platformservice/v1/users/{username}/usergroups/importAndCache
        enabled: true
      dashboard:
        baseUrl: http://oes-dashboard:8094
        enabled: true
      visibility:
        baseUrl: http://oes-visibility:8096
        enabled: true
      auditservice:
         baseUrl: "http://oes-audit-service:8097"
         enabled: true
      auditclient:
         baseUrl: "http://oes-audit-client:8098"
         enabled: true
      oesui:
        externalUrl: /ui/
      keel:
        enabled: false
      clouddriver:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-rw:7002
        enabled: true
      clouddriverCaching:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-caching:7002
        enabled: true
      clouddriverRo:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-ro:7002
        enabled: true
      clouddriverRoDeck:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-ro-deck:7002
        enabled: true
      clouddriverRw:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-rw:7002
        enabled: true
      deck:
        host: 0.0.0.0
        port: 9000
        baseUrl: http://oes.example.ops.com
        enabled: true
      echo:
        host: 0.0.0.0
        port: 8089
        baseUrl: http://spin-echo-worker:8089
        enabled: true
      echoScheduler:
        host: 0.0.0.0
        port: 8089
        baseUrl: http://spin-echo-scheduler:8089
        enabled: true
      echoWorker:
        host: 0.0.0.0
        port: 8089
        baseUrl: http://spin-echo-worker:8089
        enabled: true
      fiat:
        host: 0.0.0.0
        port: 7003
        baseUrl: http://spin-fiat:7003
        enabled: false
      front50:
        host: 0.0.0.0
        port: 8080
        baseUrl: http://spin-front50:8080
        enabled: true
      gate:
        host: 0.0.0.0
        port: 8084
        baseUrl: http://oes-gate.example.ops.com
        enabled: true
      igor:
        host: 0.0.0.0
        port: 8088
        baseUrl: http://spin-igor:8088
        enabled: true
      kayenta:
        host: 0.0.0.0
        port: 8090
        baseUrl: http://spin-kayenta:8090
        enabled: false
      orca:
        host: 0.0.0.0
        port: 8083
        baseUrl: http://spin-orca:8083
        enabled: true
      redis:
        host: 0.0.0.0
        port: 6379
        baseUrl: redis://:password@isd-redis-master:6379
        enabled: true
      rosco:
        host: 0.0.0.0
        port: 8087
        baseUrl: http://spin-rosco:8087
        enabled: true
      user: {}
    cors:
      allowed-origins-pattern: ^https?://(?:localhost|oes.example.ops.com|spin.example.ops.com|opsmx.com)(?::[1-9]\d*)?/?
      
    ldap:
      enabled: true
      managerDn: cn=admin,dc=example,dc=org
      groupSearchBase: ou=groups,dc=example,dc=org
      groupSearchFilter: member={0}
      userDnPattern: cn={0},dc=example,dc=org
      url: ldap://isd-openldap:389
      managerPassword: opsmxadmin123
    file:
      enabled: false
      url: /platformservice/v1/users/authenticate
    authn:
      mode: session
    google: {}
    redis:
      connection: redis://:password@isd-redis-master:6379
    server:
      session:
        timeoutInSeconds: 7200
      tomcat:
        httpsServerPort: X-Forwarded-Port
        internalProxies: .*
        protocolHeader: X-Forwarded-Proto
        remoteIpHeader: X-Forwarded-For
    gate:
      installation:
        mode: common    #Allowed values are --> oes,common
    rbac:
      feature:
        application:
          enabled: false
    spinnaker:
      extensibility:
        plugins:
        deck-proxy:
          enabled: true
          plugins:
            Opsmx.VerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.TestVerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.PolicyGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VisibilityApprovalPlugin:
              enabled: true
              version: 1.0.1
        repositories:
            opsmx-repo:
              url: file:///opt/spinnaker/plugins/plugins.json
              #url: https://raw.githubusercontent.com/OpsMx/spinnakerPluginRepository/v3.10.0/plugins.json
    
    allowUnauthenticatedAccess:
      agentAPI: false
      webhooks: true
    
    logging:
      level:
        com.netflix.spinnaker.gate.security: INFO
        org.springframework.security: INFO
        org.springframework.web: INFO
        #com.netflix.spinnaker.gate.security: DEBUG
        #org.springframework.security: DEBUG
        #org.springframework.web: DEBUG
    
    
    
kind: Secret
metadata:
  name: oes-gate-config
  labels:
    app: oes
    component: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
---
# Source: oes/templates/secrets/oes-gate-secret.yaml
apiVersion: v1
stringData:
  GATEURL: http://sapor-gate:8084
  GATEUSER: admin
  GATEPASS: saporadmin
kind: Secret
metadata:
  name: oes-gate-secret
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
---
# Source: oes/templates/secrets/oes-platform-configmap.yaml
apiVersion: v1
stringData:
  platform-local.yml: |
    
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/platformdb
        username: 'postgres'
        password: 'networks123'
    ldap.managerPassword: 'opsmxadmin123'
    redis:
        connection: redis://:password@isd-redis-master:6379
    #datasource.url: jdbc:postgresql://oes-db:5432/visibilitydb
    #postgres.password: 'networks123'
    #postgres.username: 'postgres'
    
    datasource:
      secretManagement:
        source: db
    rbacEnabled: false
    supportedFeatures:
      - deployment_verification
      - sapor
      - visibility
    userGroup:
      superAdminGroups: admin
    fixedDelay:
      in:
        milliseconds: 120000
    initialDelay:
      in:
        milliseconds: 300000
    scheduler:
      workerThreads: 50
    user:
      source: ldap
    ldap:
      enabled: true
      url: ldap://isd-openldap:389
      managerDn: cn=admin,dc=example,dc=org
      groupSearchBase: ou=groups,dc=example,dc=org
      groupSearchFilter: member={0}
      groupRoleAttributes: cn
      userDnPattern: cn={0},dc=example,dc=org
    
    oes:
      sapor:
        url: http://oes-sapor:8085
      autopilot:
        url: http://oes-autopilot:8090
      dashboard:
        url: http://oes-dashboard:8094
      visibility:
        url: http://oes-visibility:8096
      auditclient:
        url: http://oes-audit-client:8098
      gate:
        url: http://oes-gate:8084
      approvalGate:
        apiUrl: http://oes-gate:8084/visibilityservice/v5/approvalGates/{id}/trigger
    
      verificationGate:
        apiUrl: http://oes-gate:8084/autopilot/api/v3/registerCanary
    
    logging:
      level:
        com.opsmx.platformservice: INFO
        org.springframework.security: INFO
        org.springframework.web: INFO
    
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    
kind: Secret
metadata:
  name: oes-platform-config
  labels:
    app: oes
    component: platform
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
---
# Source: oes/templates/secrets/oes-sapor-configmap.yaml
apiVersion: v1
stringData:
  application.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/oesdb
        username: 'postgres'
        password: 'networks123'
    
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    
    secretManagement:
      source:
        config: db
      encryption: true
    oes:
      rbac:
        enabled: true
      admin:
        user: admin
      platform:
        url: http://oes-platform:8095
      visibility:
        url: http://oes-visibility:8096
      auditservice:
        enabled: true
        url: "http://oes-audit-service:8097" 
      dashboard:
        url: http://oes-dashboard:8094
      commongateurl: http://oes-gate:8084
    pipeline-promotion:
      github:
        
        enabled: true
        
        username:  opsmx
        token: opsmxadmin123
        branch: master
        cloneUrl: http://opsmx:opsmxadmin123@isd-gitea-http.opsmx-isd:3000/opsmx/gitea-standard-repo
      bitbucket:
        
        enabled: false
        
        username:  git/stash_username
        token: git/stash_token
        branch: master
        cloneUrl: https://git/stash_username:git/stash_token@github.com/OpsMx//standard-gitops-repo
      amazonS3:
        
        enabled: false
        
        accessKeyId: AWS_ACCESS_KEY_ID
        secretAccessKey: AWS_SECRET_ACCESS_KEY
        region: regionofbucket
        bucketName: bucket name.e.g-testbucket 
    spinnaker:
      restart:
        endPoint: /webhooks/webhook/restartSpinnaker
      encrypt:
        enabled: false
      sync:
        permission:
          enabled: true
    
    datasources:
      platform: true
      
    ## Set the below field to true if agent for kubernetes
    kubernetes:
      kinds:
      omitKinds:
      - podPreset
      agent:
        enabled: true
        serverInternalHostName: opsmx-controller-controller1
        serverPort: 9003
        caCertfile: /opt/opsmx/controller/ca.crt
        certFile: /opt/opsmx/controller/cert/tls.crt
        keyFile: /opt/opsmx/controller/cert/tls.key
        image: quay.io/opsmxpublic/forwarder-agent:v3.12.0
      template:
        path: /opt/opsmx/controller
        kubectlTemplateFileName: kubeconfig.template
        manifestTemplateFileName: deploy-agent.template
    
  client.p12: |
    
kind: Secret
metadata:
  name: oes-sapor-config
  labels:
    app: oes
    component: sapor
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
---
# Source: oes/templates/secrets/oes-visibility-secret.yaml
apiVersion: v1
stringData:
  visibility-local.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/visibilitydb
        username: 'postgres'
        password: 'networks123'
        #sslmode: require
      visiblity:
        connectors:
          configured: JIRA,GIT,AUTOPILOT,SONARQUBE,JENKINS,AQUAWAVE
      logging:
        level:  
          io:     
            swagger:
              models: 
                parameters:
                  AbstractSerializableParameter: ERROR
    
    management:
      endpoints:
        web:
          base-path: /mgmt
          exposure:
            include: health,info,metrics,prometheus
      endpoint:
        health:
          show-details: always
          show-components: always
      health:
        elasticsearch:
          enabled: false
        ldap:
          enabled: false
    
    ui:
      approval:
        url: http://oes.example.ops.com/ui/application/visibility/{applicationId}/{serviceId}/{approvalGateId}  
    
    gate:
      url: http://oes-gate:8084
    
    jira:
      api:
        url: /rest/api/2/search
      navigate:
        url: hosturl/browse/{issue_Id}
    
    git:
      apiurl: /repos/{account}/{repo}/commits/{commitId}
      userurl: /user
      navigate.url: https://github.com/{account}/{repo_name}/commit/{commit_Id}
    
    jenkins:
      api:
        url: /job/{jobname}/{buildId}/api/json
      navigate:
        url: hosturl/job/{jobname}/{buildId}
    
    sonar:
      navigate:
        Url: hosturl/dashboard?id={projectKey}
    
    aquawave:
      api:
        url: https://api.aquasec.com/v2/images/{id}
      navigate:
        url: https://cloud.aquasec.com/vs/#/images/{id}
    
    autopilot:
      api:
        url: http://oes-autopilot:8090
    
    platform:
      service:
        url: http://oes-platform:8095
    
    datasource:
      secretManagement:
        source: db
    
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    
    
kind: Secret
metadata:
  name: oes-visibility-config
  labels:
    app: oes
    component: visibility
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
---
# Source: oes/templates/secrets/opsmx-gitops-secret.yaml
apiVersion: v1
stringData:
  # Repo uri to fetch halyard configuration
  gitcloneparam: https://git/stash_username:git%2Fstash_token@github.com/OpsMx/standard-gitops-repo.git

  # Repo details to fetch dynamic configuration
  dynamicaccountsgituri: https://github.com/OpsMx/standard-gitops-repo.git
  gituser: git/stash_username
  gittoken: git/stash_token
  dynamicAccRepository: standard-gitops-repo

kind: Secret
metadata:
  name: opsmx-gitops-auth
type: Opaque
---
# Source: oes/templates/secrets/sapor-bootstrap-secret.yaml
apiVersion: v1
stringData:
  bootstrap.yml: |-
    spring:
      cloud:
        config:
          server:
            composite:
              - type: native
                search-locations: ${user.home}/config
        vault:
          enterprise: false
          namespace: admin/isd-platform
          uri: https://server.vaultint.opsmx.net
          token: 123132
          enabled: false
          kv:
            enabled: false
          generic:
            enabled: false
    jasypt:
      encryptor:
        password: Q7udUkHPuA3VnNlOtksSgQ
kind: Secret
metadata:
  name: sapor-bootstrap
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
---
# Source: oes/charts/minio/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
data:
  initialize: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"
    
    # connectToMinio
    # Use a check-sleep-check loop to wait for Minio service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/accesskey) ; SECRET=$(cat /config/secretkey) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to Minio server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} config host add myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }
    
    # checkBucketExists ($bucket)
    # Check if the bucket exists, by using the exit code of `mc ls`
    checkBucketExists() {
      BUCKET=$1
      CMD=$(${MC} ls myminio/$BUCKET > /dev/null 2>&1)
      return $?
    }
    
    # createBucket ($bucket, $policy, $purge)
    # Ensure bucket exists, purging if asked to
    createBucket() {
      BUCKET=$1
      POLICY=$2
      PURGE=$3
      VERSIONING=$4
    
      # Purge the bucket, if set & exists
      # Since PURGE is user input, check explicitly for `true`
      if [ $PURGE = true ]; then
        if checkBucketExists $BUCKET ; then
          echo "Purging bucket '$BUCKET'."
          set +e ; # don't exit if this fails
          ${MC} rm -r --force myminio/$BUCKET
          set -e ; # reset `e` as active
        else
          echo "Bucket '$BUCKET' does not exist, skipping purge."
        fi
      fi
    
      # Create the bucket if it does not exist
      if ! checkBucketExists $BUCKET ; then
        echo "Creating bucket '$BUCKET'"
        ${MC} mb myminio/$BUCKET
      else
        echo "Bucket '$BUCKET' already exists."
      fi
    
    
      # set versioning for bucket
      if [ ! -z $VERSIONING ] ; then
        if [ $VERSIONING = true ] ; then
            echo "Enabling versioning for '$BUCKET'"
            ${MC} version enable myminio/$BUCKET
        elif [ $VERSIONING = false ] ; then
            echo "Suspending versioning for '$BUCKET'"
            ${MC} version suspend myminio/$BUCKET
        fi
      else
          echo "Bucket '$BUCKET' versioning unchanged."
      fi
    
      # At this point, the bucket should exist, skip checking for existence
      # Set policy on the bucket
      echo "Setting policy of bucket '$BUCKET' to '$POLICY'."
      ${MC} policy set $POLICY myminio/$BUCKET
    }
    
    # Try connecting to Minio instance
    scheme=http
    connectToMinio $scheme
    # Create the bucket
    
    # Create the buckets
    createBucket spinnaker none false 
    createBucket autopilot none false
---
# Source: oes/charts/openldap/templates/configmap-customldif.yaml
#
# A ConfigMap spec for openldap slapd that map directly to files under
# /container/service/slapd/assets/config/bootstrap/ldif/custom
#
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-openldap-customldif
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
data:
  01-memberof.ldif: |-
    dn: cn=module,cn=config
    cn: module
    objectClass: olcModuleList
    olcModuleLoad: memberof.la
    olcModulePath: /usr/lib/ldap
    
    dn: olcOverlay={0}memberof,olcDatabase={1}hdb,cn=config
    objectClass: olcConfig
    objectClass: olcMemberOf
    objectClass: olcOverlayConfig
    objectClass: top
    olcOverlay: memberof
    olcMemberOfDangling: ignore
    olcMemberOfRefInt: TRUE
    olcMemberOfGroupOC: groupOfNames
    olcMemberOfMemberAD: member
    olcMemberOfMemberOfAD: memberOf
  02-refint1.ldif: |-
    dn: cn=module{1},cn=config
    changetype: modify
    add: olcmoduleload
    olcmoduleload: refint.la
  03-refint2.ldif: |-
    dn: olcOverlay={1}refint,olcDatabase={1}hdb,cn=config
    objectClass: olcConfig
    objectClass: olcOverlayConfig
    objectClass: olcRefintConfig
    objectClass: top
    olcOverlay: {1}refint
    olcRefintAttribute: memberof member manager owner
  04-add_ou.ldif: |-
    dn: ou=groups,dc=example,dc=org
    objectClass: organizationalUnit
    ou: Groups
  05-admin.ldif: |-
    dn: cn=admin,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: admin
    description: read write and execute group
    member: cn=admin,dc=example,dc=org
  06-developer.ldif: |-
    dn: cn=developers,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: developers
    description: read only users
    member: cn=admin,dc=example,dc=org
    member: cn=developer,dc=example,dc=org
  07-qa.ldif: |-
    dn: cn=QA,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: QA
    description: read only users
    member: cn=admin,dc=example,dc=org
    member: cn=qa,dc=example,dc=org
  08-manager.ldif: |-
    dn: cn=managers,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: managers
    description: read and execute group
    member: cn=admin,dc=example,dc=org
    member: cn=manager,dc=example,dc=org
  09-IT-manager.ldif: |-
    dn: cn=ITManagers,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: ITManagers
    description: read and execute group
    member: cn=admin,dc=example,dc=org
    member: cn=ITManager,dc=example,dc=org
  10-users.ldif: |-
    dn: cn=user1,dc=example,dc=org
    objectClass: simpleSecurityObject
    objectClass: organizationalRole
    cn: user1
    userpassword: {SSHA}Y9L4AsYL16WLK10qDZ62pTScFnaWb0nz
    
    dn: cn=user2,dc=example,dc=org
    objectClass: simpleSecurityObject
    objectClass: organizationalRole
    cn: user2
    userpassword: {SSHA}DasTBI0eut1F83Bh1F1HXmDT8juJj3pY
    
    dn: cn=user3,dc=example,dc=org
    objectClass: simpleSecurityObject
    objectClass: organizationalRole
    cn: user3
    userpassword: {SSHA}Qu1FW7BdLMndwM/Gf+zc3a8VIMAymbuv
    
    dn: cn=developers,ou=groups,dc=example,dc=org
    changetype: modify
    add: member
    member: cn=user1,dc=example,dc=org
    member: cn=user3,dc=example,dc=org
    
    dn: cn=QA,ou=groups,dc=example,dc=org
    changetype: modify
    add: member
    member: cn=user2,dc=example,dc=org
    member: cn=user3,dc=example,dc=org
---
# Source: oes/charts/openldap/templates/configmap-env.yaml
#
# A ConfigMap spec for openldap slapd that map directly to env variables in the Pod.
# List of environment variables supported is from the docker image:
# https://github.com/osixia/docker-openldap#beginner-guide
# Note that passwords are defined as secrets
#
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-openldap-env
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
data:
  LDAP_BACKEND: hdb
  LDAP_DOMAIN: example.org
  LDAP_ORGANISATION: Example Inc.
  LDAP_REMOVE_CONFIG_AFTER_SETUP: "false"
  LDAP_TLS: "true"
  LDAP_TLS_ENFORCE: "false"
---
# Source: oes/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-redis
  labels:
    app: redis
    chart: redis-10.5.3
    heritage: Helm
    release: isd
data:
  redis.conf: |-
    # User-supplied configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly no
    # Disable RDB persistence, AOF persistence already enabled.
    save 60 1000
  master.conf: |-
    dir /data
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
  replica.conf: |-
    dir /data
    slave-read-only yes
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
---
# Source: oes/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-redis-health
  labels:
    app: redis
    chart: redis-10.5.3
    heritage: Helm
    release: isd
data:
  ping_readiness_local.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_PASSWORD --no-auth-warning \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_PASSWORD --no-auth-warning \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_MASTER_PASSWORD --no-auth-warning \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_MASTER_PASSWORD --no-auth-warning \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: oes/charts/spinnaker/templates/configmap/additional-profile-configmaps.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-additional-profile-config-maps
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  echo-local.yml: |-
    microsoftteams:
      enabled: true
    rest:
      enabled: true
      endpoints:
      - url: http://oes-audit-service:8097/auditservice/v1/echo/events/data
        wrap: false
      - url: http://oes-sapor:8085/oes/echo
        wrap: false
  fiat-local.yml: |-
    auth:
      groupMembership:
        ldap:
          groupRoleAttributes: cn
          groupSearchBase: ou=groups,dc=example,dc=org
          groupSearchFilter: member={0}
          managerDn: cn=admin,dc=example,dc=org
          managerPassword: opsmxadmin123
          url: ldap://RELEASE_NAME-openldap:389
          userDnPattern: cn={0},dc=example,dc=org
        service: ldap
  front50-local.yml: |-
    policy:
      opa:
        enabled: true
        url: http://oes-sapor.opsmx-isd:8085
    spinnaker:
      s3:
        versioning: false
  gate-local.yml: |-
    server:
      tomcat:
        httpsServerPort: X-Forwarded-Port
        internalProxies: .*
        protocolHeader: X-Forwarded-Proto
        remoteIpHeader: X-Forwarded-For
    spinnaker:
      extensibility:
        deck-proxy:
          enabled: true
          plugins:
            Opsmx.CustomStagePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.PolicyGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.TestVerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VisibilityApprovalPlugin:
              enabled: true
              version: 1.0.1
        plugins: null
        repositories:
          opsmx-repo:
            url: https://raw.githubusercontent.com/opsmx/spinnakerPluginRepository/v3.9.0/plugins.json
  # Custom stage for pipeline promotion;
  # same configuration can be put in a repo for gitops style
  orca-local.yml: |-
    
    policy:
      opa:
        enabled: true
        url: http://oes-sapor:8085
    pollers:
      oldPipelineCleanup:
        enabled: true                  # This enables old pipeline execution cleanup (default: false)
        intervalMs: 3600000            # How many milliseconds between pipeline cleanup runs (default: 1hr or 3600000)
        thresholdDays: 30              # How old a pipeline execution must be to be deleted (default: 30)
        minimumPipelineExecutions: 5   # How many executions to keep around (default: 5)
    
    tasks:
      daysOfExecutionHistory: 180      # How many days to keep old task executions around.
    
    job:
      preconfigured:
        kubernetes:
          - label: pipelineSyncToGit
            cloudProvider: kubernetes
            credentials: default
            description: Update git with pipelines in Spinnaker
            account: default
            application: sampleapp
            type: pipelineSyncToGit
            waitForCompletion: true
            parameters:
              - defaultValue: "app1,app2,..."
                description: "Please enter spinnaker applications separated by comma"
                label: spinnaker applications
                mapping: 'manifest.spec.template.spec.containers[0].env[0].value'
                name: spinnaker_applications
              - defaultValue: "pipeline1,pipeline2..."
                description: "Please enter spinnaker pipelines separated by comma"
                label: pipieline names
                mapping: 'manifest.spec.template.spec.containers[0].env[1].value'
                name: spinnaker_pipelines
            manifest:
                apiVersion: batch/v1
                kind: Job
                metadata:
                  generateName: pipepromot-
                  namespace: SPINNAKER_NAMESPACE
                  labels:
                     stage: opsmx-custom
                     stagetype: pipelinepromotion
                spec:
                  backoffLimit: 0
                  template:
                    spec:
                      containers:
                      - command: ["bash", "scripts/deployer.sh"]
                        image: 'opsmxdev/pipepromot:1.0'
                        imagePullPolicy: IfNotPresent
                        name: pipepromot
                        volumeMounts:
                        - mountPath: /home/opsmx/scripts
                          name: pipe-promot-scripts
                        - mountPath: /home/opsmx/config
                          name: pipe-promot-config
                        - mountPath: /home/opsmx/.spin
                          name: spin-cli-config
                        env:
                          - name: spinnaker_applications
                            value: 'will be replaced'
                          - name: spinnaker_pipelines
                            value: 'will be replaced'
                          - name: command
                            value: 'upload'
                          - name: git_secret_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_secret_token
                          - name: git_pr_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_pr_token
                      volumes:
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-config
                        name: pipe-promot-config
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-scripts
                        name: pipe-promot-scripts
                      - name: spin-cli-config
                        secret:
                          defaultMode: 420
                          secretName: spin-cli-config
                      restartPolicy: Never
                      serviceAccountName: default
          - label: pipelineSyncToSpinnaker
            cloudProvider: kubernetes
            credentials: default
            description: Sync Spinnaker pipelines from git
            account: default
            application: sampleapp
            type: pipelineSyncToSpinnaker
            waitForCompletion: true
            parameters:
              - defaultValue: "app1,app2,..."
                description: "Please enter spinnaker applications separated by comma"
                label: spinnaker applications
                mapping: 'manifest.spec.template.spec.containers[0].env[0].value'
                name: spinnaker_applications
              - defaultValue: "pipeline1,pipeline2..."
                description: "Please enter spinnaker pipelines separated by comma"
                label: pipieline names
                mapping: 'manifest.spec.template.spec.containers[0].env[1].value'
                name: spinnaker_pipelines
            manifest:
                apiVersion: batch/v1
                kind: Job
                metadata:
                  generateName: pipepromot-
                  namespace: SPINNAKER_NAMESPACE
                  labels:
                     stage: opsmx-custom
                     stagetype: pipelinepromotion
                spec:
                  backoffLimit: 0
                  template:
                    spec:
                      containers:
                      - command: ["bash", "scripts/deployer.sh"]
                        image: 'opsmxdev/pipepromot:1.0'
                        imagePullPolicy: IfNotPresent
                        name: pipepromot
                        volumeMounts:
                        - mountPath: /home/opsmx/scripts
                          name: pipe-promot-scripts
                        - mountPath: /home/opsmx/config
                          name: pipe-promot-config
                        - mountPath: /home/opsmx/.spin
                          name: spin-cli-config
                        env:
                          - name: spinnaker_applications
                            value: 'will be replaced'
                          - name: spinnaker_pipelines
                            value: 'will be replaced'
                          - name: command
                            value: 'download'
                          - name: git_secret_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_secret_token
                          - name: git_pr_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_pr_token
                      volumes:
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-config
                        name: pipe-promot-config
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-scripts
                        name: pipe-promot-scripts
                      - name: spin-cli-config
                        secret:
                          defaultMode: 420
                          secretName: local-spin-cli-config
                      restartPolicy: Never
                      serviceAccountName: default
    webhook:
      preconfigured:
      - label: "JIRA: Wait for state"
        type: waitJiraState
        enabled: true
        description: Custom stage that waits for a specific state on a Jira Issue
        method: GET
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        failPipeline: true
        progressJsonPath: "fields.status.name"
        payload: ""
        retryStatusCodes:
          - 200
        statusJsonPath: "fields.status.name"
        statusUrlResolution: "getMethod"
        successStatuses: ${parameterValues['success']}
        retryStatuses: ${parameterValue['retry']}
        terminalStatuses: ${parameterValues['terminate']}
        canceledStatuses: ${parameterValues['cancel']}
        waitBeforeMonitor: "1"
        waitForCompletion: true
        parameters:
        - label: JIRA Issue ID
          name: issue
          description: "The JIRA issue, the default relies on JIRA issue ID extraction"
          type: string
          defaultValue: ${jira_issue}
        - label: JIRA Retry States
          name: retry
          description: "JIRA issue states that Retry the stage e.g,: To Do, In Progress, etc."
          type: string
          defaultValue: To Do, In Progress
        - label: JIRA Success States
          name: success
          description: "JIRA issue States that progress the pipeline, e.g,: In Verificaiton etc."
          type: string
          defaultValue: In Verification
        - label: JIRA Temination States
          name: terminate
          description: "JIRA issue states that terminates the pipeline, e.g,: PR Raised etc."
          type: string
          defaultValue: PR Raised
        - label: JIRA Canceled States
          name: cancel
          description: "JIRA issue states that cancel the pipeline e.g,: Done, etc."
          type: string
          defaultValue: Done
      - label: "JIRA: Create Issue"
        type: addJiraIss
        enabled: true
        description: Custom stage that add an Issue in Jira
        method: POST
        url: https://<DOMAIN>/rest/api/2/issue/
        customHeaders:
         ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
         Authorization: Basic base64{<<USER>>:<<Jira-token>>}
         Content-Type: application/json
        payload: |-
          {
            "fields": {
               "project":
                {
                  "key": "${parameterValues['projectid']}"
                },
                "summary": "${parameterValues['summary']}",
                "description": "${parameterValues['description']}",
                "issuetype": {
                  "name": "${parameterValues['issuetype']}"
                },
                "components": [
                    {
                  "id": "${parameterValues['components']}"
                }
                ],
                "priority": {
                  "name": "${parameterValues['priority']}"
                }
            }
          }
        parameters:
        - label: Project ID ("ENG" or "DOCS")
          name: projectid
          description: Which JIRA project do you want to create an item in?
          type: string
        - label: Issue Type ("Improvement", "Task", "New Feature", or "Bug")
          name: issuetype
          description: issuetype
          type: string
        - label: Priority ("Low", "Medium", or "High")
          name: priority
          description: priority
          type: string
        - label: Components ("10103")
          name: components
          description: component of the project
        - label: Issue Summary
          name: summary
          description: summary
          type: string
        - label: Description
          name: description
          description: description
          type: string
      - label: "JIRA: Comment on Issue"
        type: comJiraIss
        enabled: true
        description: Custom stage that posts a comment in a Jira Issue
        method: POST
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}/comment
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        payload: |-
          {
            "body": "${parameterValues['message']}"
          }
        parameters:
        - label: Issue ID
          name: issue
          description: Issue
          type: string
        - label: Message
          name: message
          description: message
          type: string
      - label: "JIRA: Update Issue"
        type: updJiraIss
        enabled: true
        description: Custom stage that updates an Issue in Jira
        method: PUT
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        payload: |-
          {
            "update": {
                "summary": [
                    {
                        "set": "${parameterValues['summary']}"
                    }
                ],
                "description": [
                    {
                       "set": "${parameterValues['description']}"
                    }
                ]
            }
          }
        parameters:
        - label: Issue ID
          name: issue
          description: Issue
          type: string
        - label: Summary
          name: summary
          description: summary
          type: string
        - label: Description
          name: description
          description: description
      - label: "JIRA: Transition Issue"
        type: transJiraIss
        enabled: true
        description: Custom stage that transitions an Issue in Jira
        method: POST
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}/transitions
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        payload: |-
          {
            "transition": {
              "id": "${parameterValues['targetStageID']}"
            }
          }
        parameters:
        - label: Issue ID
          name: issue
          description: Issue
          type: string
        - label: Target Stage ID
          name: targetStageID
          description: Target Stage ID (11 is "To Do", 21 is "In Progress", 31 is "In Review", 41 is "Done")
          type: string
    spinnaker:
      extensibility:
        plugins-root-path: /tmp/plugins
        plugins:
          Opsmx.VerificationGatePlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.VisibilityApprovalPlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.TestVerificationGatePlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.PolicyGatePlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.RbacPlugin:
            enabled: true
            version: 1.0.1
            config:
        repositories:
          opsmx-repo:
            id: opsmx-repo
            url: file:///opt/spinnaker/plugins/plugins.json
            #url: https://raw.githubusercontent.com/opsmx/spinnakerPluginRepository/v3.10.0/plugins.json
    

  echo-local.yml: |-
    rest:
      enabled: true
      endpoints:
       -
        wrap: false
        url: http://oes-sapor.opsmx-isd:8085/oes/echo
---
# Source: oes/charts/spinnaker/templates/configmap/halyard-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-halyard-config
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  install.sh: |
    #!/bin/bash

    # Wait for the Hal daemon to be ready
    export DAEMON_ENDPOINT=http://isd-spinnaker-halyard:8064
    export HAL_COMMAND="hal --daemon-endpoint $DAEMON_ENDPOINT"
    until $HAL_COMMAND --ready; do sleep 10 ; done # end of if not gitops

    # This is performed by post-start script in halyard pod
    # in case gitopsHalyard is enabled
  clean.sh: |
    export HAL_COMMAND='hal --daemon-endpoint http://isd-spinnaker-halyard:8064'
    if $HAL_COMMAND --ready; then
      $HAL_COMMAND deploy clean -q
    fi
  config.sh: |
    # Spinnaker version
    
    $HAL_COMMAND config version edit --version 1.26.6
    

    # Storage
    
    echo spinnakeradmin | $HAL_COMMAND config storage s3 edit \
        --endpoint http://isd-minio:9000 \
        --access-key-id spinnakeradmin \
        --secret-access-key --bucket spinnaker \
        --path-style-access true
    $HAL_COMMAND config storage edit --type s3
    
    
    
    

    # Docker Registry
    $HAL_COMMAND config provider docker-registry enable

    if $HAL_COMMAND config provider docker-registry account get dockerhub; then
      PROVIDER_COMMAND='edit'
    else
      PROVIDER_COMMAND='add'
    fi

    $HAL_COMMAND config provider docker-registry account $PROVIDER_COMMAND dockerhub --address index.docker.io \
       \
      --repositories library/alpine,library/ubuntu,library/centos,library/nginx

    $HAL_COMMAND config provider kubernetes enable

    if $HAL_COMMAND config provider kubernetes account get default; then
      PROVIDER_COMMAND='edit'
    else
      PROVIDER_COMMAND='add'
    fi

    $HAL_COMMAND config provider kubernetes account $PROVIDER_COMMAND default --docker-registries dockerhub \
                --context default --service-account true \
                 \
                --only-spinnaker-managed true \
                 \
                 \
                --omit-namespaces=kube-system,kube-public \
                 \
                 \
                 \
                --provider-version v2
    $HAL_COMMAND config deploy edit --account-name default --type distributed \
                           --location opsmx-isd
    $HAL_COMMAND config deploy ha clouddriver enable
    $HAL_COMMAND config deploy ha echo enable

    
    



    # Enable Authentication by default
    $HAL_COMMAND config security authn ldap edit --url ldap://isd-openldap:389 --user-dn-pattern  'cn={0},dc=example,dc=org'
    $HAL_COMMAND config security authn ldap enable

    # Enable Authorization
    $HAL_COMMAND config security authz disable


    # Use Deck to route to Gate
---
# Source: oes/charts/spinnaker/templates/configmap/halyard-init-script.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-halyard-init-script
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  init.sh: |

    echo \"Checking for Gitea services\"
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    GITEA=$(grep gitea-0 /tmp/inst.status |grep -v deck | awk '{print $2}')

    wait_period=$(($wait_period+10))
    if [ "$GITEA" == "true" ];
    then
        echo \"Gitea Pod is ready\"
        break
    else
        if [ $wait_period -gt 1800 ];
        then
            echo \"Script is timed out as the Gitea is not ready in 30 min.......\"
            break
        else
            echo \"Waiting for Gitea to be ready\"
            sleep 1m
        fi
    fi
    done
    rm -rf /tmp/spinnaker/repo.json
    gitea_user=`echo $GITEA_USER | sed 's/ *$//g'`
    gitea_pass=`echo $GITEA_PASS | sed 's/ *$//g'`
    basic_auth=$(echo -n $gitea_user:$gitea_pass |base64)
    DYNAMIC_ACCOUNTS_REPO=http://isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git
    GIT_USER=$gitea_user
    GIT_TOKEN=$gitea_pass

    echo "Checking if the local gitea repo exists....." 
    curl -k -X GET "http://isd-gitea-http.$SPINNAKER_NAMESPACE:3000/api/v1/users/$gitea_user/repos" >/tmp/spinnaker/repo.json
    checkrepo=$(cat /tmp/spinnaker/repo.json | jq '.[] | select(.name=="gitea-standard-repo")')

        if [ -z "$checkrepo" ]
        then
                echo "Creating a New Local Gitea Repo gitea-standard-repo......."
                curl -k -X POST "http://isd-gitea-http.$SPINNAKER_NAMESPACE:3000/api/v1/user/repos" -H "content-type: application/json" -H "Authorization: Basic $basic_auth" --data '{"name":"'gitea-standard-repo'"}'
                git clone https://github.com/OpsMx/standard-gitops-repo.git -b 3.12 /tmp/spinnaker/test/standard-gitops-repo/
                git clone http://$gitea_user:$gitea_pass@isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git /tmp/spinnaker/test/gitea-standard-repo/
                cp -pr /tmp/spinnaker/test/standard-gitops-repo/* /tmp/spinnaker/test/gitea-standard-repo/
                cd /tmp/spinnaker/test/gitea-standard-repo/
                git status
                git add .
                git config user.email support@opsmx.com
                git config user.name $gitea_user
                git commit -m "cloned standard-gitops-repo content"
                git push
                cd
                rm -rf /tmp/spinnaker/test/gitea-standard-repo
                rm -rf /tmp/spinnaker/test/standard-gitops-repo
                rm -rf /tmp/spinnaker/test
                git clone http://$gitea_user:$gitea_pass@isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git /tmp/spinnaker/test/

        else
                echo "Local Repo exits...."
                rm -rf /tmp/spinnaker/test/gitea-standard-repo
                git clone http://$gitea_user:$gitea_pass@isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git /tmp/spinnaker/test
        fi
        #override the repotye to gitea in order to support pipelin-promotion
        sed -i  s/repo_type=git/repo_type=gitea/ /tmp/spinnaker/test/pipeline-promotion/pipe-promot-config-cm.yaml
        sed -i  s/git_user=/git_user=${GIT_USER}/ /tmp/spinnaker/test/pipeline-promotion/pipe-promot-config-cm.yaml
        sed -i  s/root_folder=/root_folder=pipeline-promotion/ /tmp/spinnaker/test/pipeline-promotion/pipe-promot-config-cm.yaml
    #!/bin/bash -x
    rm -rf /tmp/spinnaker/.hal


    cp -r /tmp/spinnaker/test// /tmp/spinnaker/.hal
    if [ -d "/tmp/spinnaker/test/pipeline-promotion/" ]
    then
       cp -r /tmp/spinnaker/test/pipeline-promotion /tmp/spinnaker/pipeline-promotion
    fi
    if [ -d "/tmp/spinnaker/test/clusterconfig/" ]
    then
       cp -r /tmp/spinnaker/test/clusterconfig /tmp/spinnaker/clusterconfig
    fi
    rm -rf /tmp/spinnaker/test
    DYNAMIC_ACCOUNTS_REPO=`echo $DYNAMIC_ACCOUNTS_REPO | sed 's/ *$//g'`
    sed -i  s/SPINNAKER_NAMESPACE/${SPINNAKER_NAMESPACE}/ /tmp/spinnaker/.hal/config
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/config
    sed -i  s/GIT_USER/${GIT_USER}/g /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s/GIT_TOKEN/${GIT_TOKEN}/g /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  's|DYNAMIC_ACCOUNTS_REPO|'"${DYNAMIC_ACCOUNTS_REPO}"'|' /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s%DYN_ACCNT_CONFG_PATH%/%g /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/default/profiles/rosco-local.yml
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/default/service-settings/redis.yml
    yq e '.deploymentConfigurations.[].security.authz.enabled = "false"' /tmp/spinnaker/.hal/config > /tmp/spinnaker/.hal/config1
    mv /tmp/spinnaker/.hal/config1 /tmp/spinnaker/.hal/config
    if [ -f /tmp/spinnaker/.hal/default/profiles/fiat-local.yml ]; then
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/default/profiles/fiat-local.yml
    fi
    sed -i  s/SPINNAKER_NAMESPACE/${SPINNAKER_NAMESPACE}/ /tmp/spinnaker/.hal/default/profiles/orca-local.yml
    printf 'server.address: 0.0.0.0\n' > /tmp/config/halyard-local.yml
    if [ -f /tmp/spinnaker/.hal/halyard.yaml ]; then
    cp /tmp/spinnaker/.hal/halyard.yaml /tmp/config
    fi
    yq e '.deploymentConfigurations.[].security.authn.saml.enabled = "false"' /tmp/spinnaker/.hal/config > /tmp/spinnaker/.hal/config1
    mv /tmp/spinnaker/.hal/config1 /tmp/spinnaker/.hal/config  # git or stash  # Enabled  # End of S3
    # pipeline promotion configuration setup
    #
    ls -lart /home/spinnaker/java-lib/
    if [ -d "/tmp/spinnaker/pipeline-promotion/" ]
    then
      #decrypt_key=$(kubectl get cm bootstrap -o yaml  -n ${SPINNAKER_NAMESPACE}| grep 'password:' | awk '{ print $2}')
      #decrypt_key=$(kubectl get secret bootstrap -o jsonpath='{.data.bootstrap\.yml}' -n ${SPINNAKER_NAMESPACE} | base64 -d | grep 'password:' | awk '{ print $2}')
      kubectl get secret bootstrap -o jsonpath='{.data.bootstrap\.yml}' -n ${SPINNAKER_NAMESPACE} | base64 -d > /tmp/decryptkry.txt
      decrypt_key=$(yq e '.jasypt.encryptor.password' /tmp/decryptkry.txt)
      if [[ $decrypt_key != "" ]];
      then
        for filename in /tmp/spinnaker/pipeline-promotion/*; do
          java -cp "Decryptor.jar:/home/spinnaker/java-lib/*" Decryptor $decrypt_key "$filename"
        done
      mkdir /tmp/spinnaker/pipeline-decrypted/
      mv /tmp/spinnaker/pipeline-promotion/*decrypted.yaml /tmp/spinnaker/pipeline-decrypted/
      kubectl apply -f /tmp/spinnaker/pipeline-promotion/pipe-promot-config-cm.yaml -n ${SPINNAKER_NAMESPACE}
      kubectl apply -f /tmp/spinnaker/pipeline-decrypted/ -n ${SPINNAKER_NAMESPACE}
     fi
    fi
   
    ############# Auto Configuration for Custom Stages in ORCA #############

    if [ -d "/tmp/spinnaker/clusterconfig/" ]
    then
      #decrypt_key=$(kubectl get secret bootstrap -o jsonpath='{.data.bootstrap\.yml}' -n ${SPINNAKER_NAMESPACE} | base64 -d | grep 'password:' | awk '{ print $2}')
      kubectl get secret bootstrap -o jsonpath='{.data.bootstrap\.yml}' -n ${SPINNAKER_NAMESPACE} | base64 -d > /tmp/decryptkry.txt
      decrypt_key=$(yq e '.jasypt.encryptor.password' /tmp/decryptkry.txt)
      if [[ $decrypt_key != "" ]];
      then
        for filename in /tmp/spinnaker/clusterconfig/*; do
          java -cp "Decryptor.jar:/home/spinnaker/java-lib/*" Decryptor $decrypt_key "$filename"
        done
      mkdir /tmp/spinnaker/clusterconfig-decrypted/
      mv /tmp/spinnaker/clusterconfig/*decrypted.yaml /tmp/spinnaker/clusterconfig-decrypted/
      kubectl apply -f /tmp/spinnaker/clusterconfig-decrypted/ -n ${SPINNAKER_NAMESPACE}
        if [ -r "/tmp/spinnaker/clusterconfig/servicenow-secret.yaml" ]
        then
           #### Extracting the Service NOW information from secret ####
           SERVICENOW_USER=$(kubectl get secret servicenow-secret -o jsonpath='{.data.SERVICENOW_USERNAME}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           SERVICENOW_DNS=$(kubectl get secret servicenow-secret -o jsonpath='{.data.SERVICENOW_URL}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           SERVICENOW_PASSWD=$(kubectl get secret servicenow-secret -o jsonpath='{.data.SERVICENOW_PASSWORD}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           SERVICENOW_BASE64_USR_PASSWD=$(echo -n "$SERVICENOW_USER:$SERVICENOW_PASSWD" | base64)
           sed -i s%SERVICENOW_URL%${SERVICENOW_DNS}%g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
           sed -i  s/SERVICENOW_BASE64_USR_PASSWD/${SERVICENOW_BASE64_USR_PASSWD}/g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
        else
           echo "Not able to find the ServiceNow secret file"
        fi
        if [ -r "/tmp/spinnaker/clusterconfig/jira-secret.yaml" ]
        then
           #### Extracting the JIRA information from secret ####
           JIRA_USER=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_USERNAME}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           JIRA_DNS=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_URL}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           JIRA_TOKN=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_TOKEN}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           JIRA_BASE64_USR_PASSWD=$(echo -n "$JIRA_USER:$JIRA_TOKN" | base64)
           sed -i s%JIRA_URL%${JIRA_DNS}%g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
           sed -i  s/JIRA_BASE64_USR_PASSWD/${JIRA_BASE64_USR_PASSWD}/g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
        else
           echo "Not able to find the ServiceNow secret file"
        fi
     fi
    fi
---
# Source: oes/charts/spinnaker/templates/configmap/halyard-overrideurl.yaml
apiVersion: v1
data:
  call_overrides.sh: |
    echo $SPINNAKER_NAMESPACE
    sh /tmp/autoconfig/config_overrideurl.sh spin-gate-overrideurl-gitops
    sh /tmp/autoconfig/config_overrideurl.sh spin-deck-overrideurl-gitops
  config_overrideurl.sh: |
    #!/bin/bash -x

    if [ $# -gt 1 ]
    then
       echo "Invalid input, only one argument expected"
       exit
    fi

    COMPONENT=$1
    EXTERNAL_IP_CHECK_DELAY=1

    check_for_loadBalancer()
    {
        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        iter=0
        lapsedTime=0
        while [ $iter -lt 100 ]
        do
          ENDPOINT_IP=$(kubectl get svc $1 -o jsonpath="{.status.loadBalancer.ingress[].ip}")
          if [ ! -z "$ENDPOINT_IP" ];
          then
            echo "Found LoadBalancer IP for" $1
            break
          fi
          sleep 5
          lapsedTime=`expr $lapsedTime + 5`
          if [ $lapsedTime -gt $EXTERNAL_IP_CHECK_DELAY ];
          then
    	echo "Time Lapsed" $lapsedTime
            echo "Timeout! Fetching nodeport IP alternatively"
            break
          fi
          echo "Time Lapsed" $lapsedTime
          iter=`expr $iter + 1`
        done
    }

    case "$COMPONENT" in
      spin-gate)
        ENDPOINT_IP=""
        PORT=8084

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-gate-lb

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort IP and replace in spinnaker.yaml
          #ENDPOINT_IP=$(kubectl get ep kubernetes -n default -o jsonpath="{.subsets[].addresses[].ip}")
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-gate-np -o jsonpath="{.spec.ports[].nodePort}")
          sed -i  s/OVERRIDE_API_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        else
          ## Substitute spin-gate external IP in hal config
          sed -i  s/OVERRIDE_API_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        fi
        ;;

      spin-deck)
        ENDPOINT_IP=""
        PORT=9000

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-deck-lb

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort & nodeport and replace in app-config.js
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-deck-np -o jsonpath="{.spec.ports[].nodePort}")
          sed -i  s/OVERRIDE_DECK_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        else
          ## Substitute spin-deck external IP in hal config
          sed -i  s/OVERRIDE_DECK_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        fi
        ;;
      override-gate-url)
        ENDPOINT_IP=""
        PORT=8084

        export DAEMON_ENDPOINT=http://isd-spinnaker-halyard:8064
        export HAL_COMMAND="hal --daemon-endpoint $DAEMON_ENDPOINT"

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-gate-np

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort IP and replace in spinnaker.yaml
          #ENDPOINT_IP=$(kubectl get ep kubernetes -n default -o jsonpath="{.subsets[].addresses[].ip}")
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-gate-np -o jsonpath="{.spec.ports[].nodePort}")
          $HAL_COMMAND config security api edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        else
          ## Run hal config edit command to override gate url
          $HAL_COMMAND config security api edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        fi
        ;;
      override-deck-url)
        ENDPOINT_IP=""
        PORT=9000

        export DAEMON_ENDPOINT=http://isd-spinnaker-halyard:8064
        export HAL_COMMAND="hal --daemon-endpoint $DAEMON_ENDPOINT"

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-deck-np

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort & nodeport and replace in app-config.js
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-deck-np -o jsonpath="{.spec.ports[].nodePort}")
          $HAL_COMMAND config security ui edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        else
          ## Run hal config edit command to override deck url
          $HAL_COMMAND config security ui edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        fi
        ;;
      spin-gate-overrideurl-gitops)
        ## Configured ingress host url as override url
          echo "Substituting gate url"
          sed -i 's,PROTOCOL,http,g' /tmp/spinnaker/.hal/config
          sed -i 's,OVERRIDE_API_URL,oes-gate.example.ops.com,g' /tmp/spinnaker/.hal/config
        ;;
      spin-deck-overrideurl-gitops)
        ## Configured ingress host url as override url
          echo "Substituting deck url"
          sed -i 's,OVERRIDE_DECK_URL,spin.example.ops.com,g' /tmp/spinnaker/.hal/config
        ;;
      *)
        echo  COMP=$COMPONENT
        echo "Invalid input:$COMPONENT"
        ;;
    esac

kind: ConfigMap
metadata:
  name: isd-spinnaker-halyard-overrideurl
---
# Source: oes/charts/spinnaker/templates/configmap/secret-decoder.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-spin-secret-decoder
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  run.sh: |-
    #!/bin/bash
    echo "##########Replacing Secret#########"
    grep -ir encrypted: /tmp/spinnaker/.hal | sort -t: -u -k1,1 |cut -d : -f1 > tmp.list
    while IFS= read -r file; do
    grep encrypted: $file > tmp1.list
    while read line ; do
    echo ${line#*encrypted:} ;
    done < tmp1.list > secret-strings.list
    while read secret ; do
    secretName=${secret%%:*}
    echo "---------$secretName---"
    keyName=${secret#*:}
    keyName=${keyName%%\"*}
    keyName=${keyName%% *}
    echo "----------$keyName--"
    #echo "secret Name= $secretName and key is = $keyName"
    #kubectl get secret -o jis
    #echo kubectl --kubeconfig /home/srini/ibm-cloud/staging/ibmstaging.config -n ninja-srini get secret $secretName -o json  jq -r ".data.$keyName"
    jqParam=".data.\"$keyName\""
    value=$(kubectl get secret $secretName -o json | jq -r $jqParam | base64 -d)
    value=$(echo $value | sed -e 's`[][\\/.*^$]`\\&`g')
    #echo "-----------$value---"
    #echo "secret Name= $secretName and key is = $keyName and value is $value"
    sed -i s/encrypted:$secretName:$keyName/$value/g $file
    done < secret-strings.list
    done < tmp.list

    echo "########### Replacing Kubeconfigs ############"
    grep encryptedFile /tmp/spinnaker/.hal/config > tmp.list
    while read line ; do
    echo ${line#*encryptedFile:} ;
    done < tmp.list  > secret-files.list

    while read secret ; do
    secretName=${secret%%:*}
    keyName=${secret#*:}
    keyName=${keyName%%\"*}
    keyName=${keyName%% *}
    echo "secret Name= $secretName and key is = $keyName"
    jqParam=".data.\"$keyName\""
    mkdir -p /tmp/spinnaker/kubeconfigdir
    kubectl get secret $secretName -o json | jq -r $jqParam | base64 -d > /tmp/spinnaker/kubeconfigdir/$keyName
    #echo "secret Name= $secretName and key is = $keyName and value is in $keyName"
    old_value="encryptedFile:$secretName:$keyName"
    new_value="/home/spinnaker/kubeconfigdir/$keyName"
    #echo $old_value
    #echo $new_value
    sed -i "s/${old_value}/$(echo $new_value | sed 's_/_\\/_g')/g" /tmp/spinnaker/.hal/config
    done < secret-files.list
    rm -rf secret-files.list secret-strings.list tmp.list
---
# Source: oes/charts/spinnaker/templates/configmap/service-settings.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-service-settings
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"

data:
  clouddriver-caching.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver-ro-deck.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver-ro.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver-rw.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  deck.yml: |-
    artifactId: quay.io/opsmxpublic/ubi8-oes-deck:3.5.1
    env:
      API_HOST: http://spin-gate:8084
  echo-scheduler.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1'
  echo-worker.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1'
  echo.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1'
  fiat.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-fiat:1.16.0'
  front50.yml: 'artifactId: quay.io/opsmxpublic/ubi8-oes-front50:0.27.1-opa'
  gate.yml: |-
    artifactId: quay.io/opsmxpublic/ubi8-oes-spin-gate:1.22.1
    healthEndpoint: /health
    kubernetes:
      useExecHealthCheck: false
  igor.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-igor:1.16.0'
  kayenta.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-kayenta:0.21.0'
  orca.yml: 'artifactId: quay.io/opsmxpublic/ubi8-oes-orca:2.20.4'
  redis.yml: |-
    overrideBaseUrl: redis://<EXTERNAL-REDIS-HOST-NAME>:6379
    skipLifeCycleManagement: true
  rosco.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-rosco:0.25.0'
---
# Source: oes/charts/spinnaker/templates/configmap/spin-pipeline-import.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-spin-pipeline-import
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  spin-pipeline-import.sh: |-
    #!/bin/bash
    echo \"Waiting for all Spinnaker Services to come-up\"
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    CLOUDRO=$(grep spin-clouddriver-ro /tmp/inst.status |grep -v deck | awk '{print $2}')
    CLOUDRODECK=$(grep spin-clouddriver-ro-deck /tmp/inst.status | awk '{print $2}')
    CLOUDRW=$(grep spin-clouddriver-rw /tmp/inst.status | awk '{print $2}')
    CLOUDCACHING=$(grep spin-clouddriver-caching /tmp/inst.status | awk '{print $2}')
    DECK=$(grep spin-deck /tmp/inst.status | awk '{print $2}')
    ECHOWORKER=$(grep spin-echo-worker /tmp/inst.status | awk '{print $2}')
    ECHOSCHEDULER=$(grep spin-echo-scheduler  /tmp/inst.status | awk '{print $2}')
    FRONT=$(grep spin-front /tmp/inst.status  | awk '{print $2}')
    GATE=$(grep spin-gate /tmp/inst.status | awk '{print $2}')
    FIAT=$(grep spin-fiat /tmp/inst.status | awk '{print $2}')
    ORCA=$(grep spin-orca /tmp/inst.status | awk '{print $2}')
    SAPORGATE=$(grep sapor-gate /tmp/inst.status | awk '{print $2}')
    OESGATE=$(grep oes-gate /tmp/inst.status | awk '{print $2}')
    wait_period=$(($wait_period+10))
    if [ "$DECK" == "true" ] && [ "$CLOUDCACHING" == "true" ] && [ "$CLOUDRO" == "true" ] && [ "$CLOUDRW" == "true" ] && [ "$CLOUDRODECK" == "true" ] && [ "$FRONT" == "true" ] && [ "$GATE" == "true" ] && [ "$ORCA" == "true" ] && [ "$ECHOWORKER" == "true" ] && [ "$ECHOSCHEDULER" == "true" ] && [ "$SAPORGATE" == "true" ] && [ "$OESGATE" == "true" ];
    then
        echo \"Spinnaker and OES is Installed and ready\"
        mkdir -p /tmp/config/git/
        git -c http.sslVerify=false clone https://github.com/OpsMx/sample-pipelines.git /tmp/config/git/
        cd /tmp/config/git
        cp -p /tmp/config/spin/config .
        sed 's/$/ --config config/' create-app.sh >create-app1.sh
        bash -xe create-app1.sh
        break
    else
        if [ $wait_period -gt 1800 ];
        then
            echo \"Script is timed out as the Spinnaker is not ready in 30 min.......\"
            break
        else
            echo \"Waiting for Spinnaker services to be ready\"
            sleep 1m
        fi
    fi
    done
---
# Source: oes/templates/clouddriver-sidecar/k8sconfig-sync.yaml
apiVersion: v1
data:
  k8config-sync.sh: |
    #!/bin/bash
    export GIT_CLONE_PARAM=$(cat /tmp/secret/gitcloneparam)
    export GIT_URL=$(cat /tmp/secret/dynamicaccountsgituri)
    export DYNAMIC_ACCOUNTS_REPO=$(cat /tmp/secret/dynamicAccRepository)
    rm -rf $DYNAMIC_ACCOUNTS_REPO
    mkdir -p /opsmx
    echo " ####### Cloning the Dynamic Account Repo #################"
    git clone -c http.sslVerify=false $GIT_CLONE_PARAM
    #cd $DYNAMIC_ACCOUNTS_REPO/
    cat $DYNAMIC_ACCOUNTS_REPO///clouddriver-local.yml |grep -i opsmx |awk '{print $2}' |tr -d '"' | awk 'BEGIN{FS="/opsmx/"}{print $2}' > /opsmx/config_files.txt
    for config in $(cat /opsmx/config_files.txt)
    do
    kubectl get secrets $config -o=jsonpath='{.data.*}'|base64 -d > /opsmx/$config
    done
kind: ConfigMap
metadata:
  name: k8config-sync
---
# Source: oes/templates/configmaps/datasource-creation.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-oes-datasource-creation
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
data:
  datasource-api.sh: |-
    #!/bin/bash
    set -x
    echo \"Waiting for all Spinnaker and OES Services to come-up\"
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    CLOUDRO=$(grep spin-clouddriver-ro /tmp/inst.status |grep -v deck | awk '{print $2}')
    CLOUDRODECK=$(grep spin-clouddriver-ro-deck /tmp/inst.status | awk '{print $2}')
    CLOUDRW=$(grep spin-clouddriver-rw /tmp/inst.status | awk '{print $2}')
    CLOUDCACHING=$(grep spin-clouddriver-caching /tmp/inst.status | awk '{print $2}')
    DECK=$(grep spin-deck /tmp/inst.status | awk '{print $2}')
    ECHOWORKER=$(grep spin-echo-worker /tmp/inst.status | awk '{print $2}')
    ECHOSCHEDULER=$(grep spin-echo-scheduler  /tmp/inst.status | awk '{print $2}')
    FRONT=$(grep spin-front /tmp/inst.status  | awk '{print $2}')
    GATE=$(grep spin-gate /tmp/inst.status | awk '{print $2}')
    IGOR=$(grep spin-igor /tmp/inst.status | awk '{print $2}')
    ORCA=$(grep spin-orca /tmp/inst.status | awk '{print $2}')
    #ROSCO=$(grep spin-rosco /tmp/inst.status | awk '{print $2}')
    SAPOR=$(grep oes-sapor /tmp/inst.status | awk '{print $2}')
    PLATFORM=$(grep oes-platform /tmp/inst.status | awk '{print $2}')
    AUTOPILOT=$(grep oes-autopilot /tmp/inst.status | awk '{print $2}')
    FIAT=$(grep spin-fiat /tmp/inst.status | awk '{print $2}')

    wait_period=$(($wait_period+10))
    if [ "$DECK" == "true" ] && [ "$CLOUDCACHING" == "true" ] && [ "$CLOUDRO" == "true" ] && [ "$CLOUDRW" == "true" ] && [ "$CLOUDRODECK" == "true" ] && [ "$FRONT" == "true" ] && [ "$ORCA" == "true" ]  && [ "$ECHOWORKER" == "true" ] && [ "$ECHOSCHEDULER" == "true" ] && [ "$SAPOR" == "true" ] && [ "$PLATFORM" == "true" ] && [ "$AUTOPILOT" == "true" ] && [ "$GATE" == "true" ] && [ "$IGOR" == "true" ];
        then
            echo \"Spinnaker and OES services are Up and Ready..\"
            sleep 5
            curl -X POST "http://sapor-gate:8084/login?username=admin&password=saporadmin&submit=Login"
            curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "OPA", "name": "OPA", "configurationFields": {"endPoint": "opa:8181"}}'   http://oes-platform:8095/platformservice/v2/datasources
            curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "AUTOPILOT", "name": "Autopilot", "configurationFields": {"username": "admin"} }'   http://oes-platform:8095/platformservice/v2/datasources
            #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "ELASTICSEARCH", "name": "elastic-default", "configurationFields": {"endPoint": "https://newoeselastic.opsmx.com", "username": "opsmxuser", "password": "OpsMx@123", "kibanaEndPoint": "https://newoeskibana.opsmx.com", "kibanaPassword": "OpsMx@123", "kibanaUsername": "opsmxuser" }}'   http://oes-platform:8095/platformservice/v2/datasources
            #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "PROMETHEUS", "name": "prometheus-default", "configurationFields": {"endPoint": "http://prometheus:9090"} }'   http://oes-platform:8095/platformservice/v2/datasources
            echo "Creating OPA Policies"
            curl --header 'Content-Type: application/json' --header 'x-spinnaker-user: admin' --request POST http://oes-sapor:8085/oes/v2/policy/save --data '{"name":"AppMustHaveRbac","type":"Static","accountType":"OPA","accountName":"OPA","description":"Enforce Application in Spinnakr to have Roles defined.","status":"INACTIVE","rego":"# Static Policy to enforce assigning roles when creating an application\n# Once enforced, it is not possible to create an application that is visible to all\n# by mistake\n\npackage opsmx.spinnaker.authorization\n\ndeny[\"Permissions must be specified\"] {\n   not(appHasWritePermissions)\n   input.new.job[_].type==\"updateApp\"\n }{\n   not(appHasWritePermissions)\n   input.new.job[_].type==\"createApp\"\n}\nappHasWritePermissions {\n  count(input.new.job[0].application.permissions.WRITE) > 0\n}"}'
            curl --header 'Content-Type: application/json' --header 'x-spinnaker-user: admin' --request POST http://oes-sapor:8085/oes/v2/policy/save --data '{"name":"StageLevelRBAC","type":"Static","accountType":"OPA","accountName":"OPA","description":"Restrict a group of users from modifying certain stages","status":"INACTIVE","rego":"package opsmx.spinnaker.stage_rbac\nimport future.keywords.in\n\n# The permissions json is to be defined to restrict some users from making changes to a specific stage\n# in the pipeline. The parameters for each stage are \"name\" of the pipeline, \"type\" of the pipeline and \"grant\" privilege\n# which can hold 2 values: allow and deny\npermissions = {\n  \"role_grants\": {\n    \"demo-users\": [\n      {\n        \"name\": \"Build\",\n        \"type\": \"jenkins\",\n        \"grant\": \"deny\"\n      },\n      { \n        \"name\": \"Deploy \",\n        \"type\": \"deployManifest\",\n        \"grant\": \"deny\"\n      },\n      { \n        \"name\": \"Manual Judgment \",\n        \"type\": \"manualJudgment\",\n        \"grant\": \"deny\"\n      },\n      {\n        \"name\": \"Wait\",\n        \"type\": \"wait\",\n        \"grant\": \"deny\"\n      }\n    ]\n  }\n}\n\n\n# modified_stages is the set of stages which carry \"modified\", \"new\" and \"deleted\" stageStatus. \n# only the stages with stageStatus = unmodified are excluded.\n\nmodified_stages = [input.pipeline.stages[idx] | input.pipeline.stages[idx].stageStatus != \"unmodified\"]\n#modified_stage_name = [input.pipeline.stages[idx].name | input.pipeline.stages[idx].stageStatus != \"unmodified\"]\n\n\n# The operation is denied if there is no modified/new/deleted stage in the pipeline\ndeny[\"No modified stages found\"]{\n  count(input.pipeline.stages) > 0         # only because we still have fron50 plugin; this will be removed in 3.12.x release\n  count(modified_stages) <= 0\n}\n\n# If there are modifications in the pipeline, the privileges of users to operate on a set of stages\n# is evaluated on the basis of\n\n# 1. If the user is admin, allow the user to do anything\n# 2. If the permissions json does not carry definition of privileges for any group assigned to the user,\n# then the user is to be allowed to make any changes\n# 3. If there are no denials in the permissions definition, then the user is to be allowed to make any changes\n# 4. If there are denials for some stages in any of the role assigned to user, then\n#\t4a. Checking if the same stages is allowed for any other role assigned to user\n#   4b. If a respective allow privilege is available, then allow.\n#   4c. If not then deny\n# 5. If there are any denials w.r.t. modified stages, simply deny the user from saving.\n# Rule 4 and 5 are contradicting, one of them is to be enabled. Comment line 92-100 to disable rule 4.\n\ndeny[msg]{\n  #not user_is_admin\n  \n  some i\n  role_def = permissions.role_grants[i]\n  role_def_flag = i in input.pipeline.user.groups\n  role_def_flag == true\n  \n  denial_set = user_is_denied\n  denial_size = count(denial_set) \n  to_number(denial_size) > 0\n\n# Comment rest of the statements in this rule if rule 4 is to be enabled\n  acceptance_set = user_is_allowed\n\n  some j\n  accepted_stages = [acceptance_set[j].name | acceptance_set[j].grant == \"allow\"]\n  \n  some k\n  denied_stages = [denial_set[k].name | denial_set[k].grant == \"deny\"; not denial_set[k].name in accepted_stages]\n  denial_size_after_acceptance = count(denied_stages)\n  denial_size_after_acceptance > 0\n  \n  denial_stage_msg = concat(\",\" , denied_stages)\n  msg = sprintf(\"Denied for stages: %v\", [denial_stage_msg])\n}\n\n\n# Check if user is admin\n#user_is_admin {\n # \"admin\" in input.pipeline.user.groups\n#}\n\n# Obtain list of denied and allowed stages for the groups assigned to user\nmake_grant_decision{  \n  some grant_idx\n  user_is_denied[grant_idx]\n\n  some grant_idx2\n  user_is_allowed[grant_idx2]\n}\n\nuser_is_denied[grant_idx] {\n  some stage in modified_stages\n  some role in input.pipeline.user.groups\n  some grant_idx in permissions.role_grants[role]\n  \n  grant_idx.name == stage.name\n  grant_idx.type == stage.type\n  grant_idx.grant == \"deny\" \n}\n\nuser_is_allowed[grant_idx2] {\n  some stage in modified_stages\n  some role in input.pipeline.user.groups\n  some grant_idx2 in permissions.role_grants[role]\n  \n  grant_idx2.name == stage.name\n  grant_idx2.type == stage.type\n  grant_idx2.grant == \"allow\" \n}"}'
            curl --header 'Content-Type: application/json' --header 'x-spinnaker-user: admin' --request POST http://oes-sapor:8085/oes/v2/policy/save --data '{"name":"BlackOutWindow","type":"Runtime","accountType":"OPA","accountName":"OPA","description":"Policy to Prevent deployment during a specified date/time range.","status":"INACTIVE","rego":"# Sample Runtime policy\n  # This policy blocks deployments in the blackout window period\n  \n  package opsmx.blackoutwindow\n  \n  deny[\"No deploys between 25th - 31st Dec 2020\"] {\n    [year, month, day] := time.date([time.now_ns(), \"America/Los_Angeles\"])\n    year == 2020\n    month == 12\n    day >= 25\n    day <= 31\n  }"}'

            STORAGE_TYPE=gitea
            GITEA_USERNAME=opsmx
            GITEA_PASSWORD=opsmxadmin123
            USERNAME=admin
            PASSWORD=saporadmin
            response=$(curl -s http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker)
            name=$(echo $response | jq '.[].name')
            if [ -z "$name" ];
            then
              if [[ "$STORAGE_TYPE"  ==  "gitea" ]];
              then

              curl -X POST -H "Content-Type: application/json"  -k -d '{"name":"'"$GITEA_USERNAME"'"}' -u $GITEA_USERNAME:$GITEA_PASSWORD http://isd-gitea-http.opsmx-isd:3000/api/v1/users/$GITEA_USERNAME/tokens >token.json
              TOKEN=$(cat token.json | jq '.sha1' -r)

              response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v6/datasource --data '{"datasourceType": "GITHUB", "name": "gitops", "spinEnabled": "false", "configurationFields": {"token": "'$TOKEN'", "username": "", "hostUrl": "http://isd-gitea-http:3000", "url": "http://isd-gitea-http:3000/api/v1/users/opsmx" } }')
              
              id=$(echo $response | jq '.id')
              curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":true,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITHUB","config":{"bucketName":"","region":"","endPoint":"http://isd-gitea-http:3000/'$GITEA_USERNAME'/gitea-standard-repo.git","sourcePath":""}},"pipelinePromotionConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITHUB","config":{"bucketName":"","region":"","endPoint":"http://isd-gitea-http:3000/'$GITEA_USERNAME'/gitea-standard-repo.git","sourcePath":""}},"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'

              sleep 5
              kubectl delete po isd-spinnaker-halyard-0 -n opsmx-isd
              #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":false,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITHUB","config":{"bucketName":"","region":"","endPoint":"http://isd-gitea-http:3000/'$GITEA_USERNAME'/gitea-standard-repo.git","sourcePath":""}},"pipelinePromotionConfiguration":null,"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'
                 break
              fi
            fi

            STORAGE_TYPE=git
            BASEURL_HOST=github.com
            USERNAME=admin
            PASSWORD=saporadmin
            TOKEN=$(echo -n "$USERNAME":"$PASSWORD" | base64)
            response=$(curl -s http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker)
            name=$(echo $response | jq '.[].name')
            if [ -z "$name" ];
            then
              if [[ "$STORAGE_TYPE"  ==  "git" && "$BASEURL_HOST" == "github.com" ]];
              then
              response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v6/datasource --data '{"datasourceType": "GITHUB", "name": "gitops", "spinEnabled": "false", "configurationFields": {"token": "git/stash_token", "username": "git/stash_username", "hostUrl": "https://github.com/", "url": "https://api.github.com" } }')
              id=$(echo $response | jq '.id')
              curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":false,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITHUB","config":{"bucketName":"","region":"","endPoint":"https://github.com/OpsMx/standard-gitops-repo.git","sourcePath":""}},"pipelinePromotionConfiguration":null,"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'
              #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://oes-gate.example.ops.com", "authenticationType": "LDAP", "token": "'"${TOKEN}"'", "externalAccountFlag": "true","pipelinePromotionFlag": "false","syncAccountFlag": "false", "externalAccountConfiguration": {"accountId": "'"${id}"'","accountName": "gitops", "provider": "GITHUB", "config": {"bucketName": "", "region": "","endPoint": "https://github.com/OpsMx/standard-gitops-repo.git", "sourcePath": "" }}}'
                  break
              fi
              if [[ "$STORAGE_TYPE"  ==  "git" && "$BASEURL_HOST" == "gitlab.com" ]];
              then
              response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v6/datasource --data '{"datasourceType": "GITLAB", "name": "gitops", "spinEnabled": "false", "configurationFields": {"token": "git/stash_token", "hostUrl": "https://gitlab.com/" } }')
              id=$(echo $response | jq '.id')
              curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":false,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITLAB","config":{"bucketName":"","region":"","endPoint":"https://gitlab.com/OpsMx/standard-gitops-repo.git","sourcePath":""}},"pipelinePromotionConfiguration":null,"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'
                  break
              fi
              if [[ "$STORAGE_TYPE"  ==  "stash" ]];
              then
                if [[ "" ]]
                then
                  response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v2/datasources --data '{"datasourceType": "BITBUCKET", "name": "gitops-bitbucket", "spinEnabled": "false", "configurationFields": {"authType":"bearer","username": "git/stash_username","token": "git/stash_token","read":"","write":"",  "hostUrl": "https://github.com/OpsMx//standard-gitops-repo.git", "url": "https://api.bitbucket.org/2.0/" } }')
                  id=$(echo $response | jq '.id')
                   curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://sapor-gate:8084", "authenticationType": "LDAP", "token": "'"${TOKEN}"'", "externalAccountFlag": "true", "pipelinePromotionFlag": "false","syncAccountFlag": "false", externalAccountConfiguration": {"accountId": "'"${id}"'","accountName": "gitops-bitbucket", "provider": "BITBUCKET", "config": {"bucketName": "", "region": "","endPoint": "https://github.com/OpsMx//standard-gitops-repo.git", "sourcePath": " " }}}'

                  break
                else
                  response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v2/datasources --data '{"datasourceType": "BITBUCKET", "name": "gitops-bitbucket", "spinEnabled": "false", "configurationFields": {"authType":"bearer","username": "git/stash_username","token": "git/stash_token","read":"","write":"", "hostUrl": "https://github.com/OpsMx//standard-gitops-repo.git", "url": "https://api.bitbucket.org/2.0/" } }')
                  id=$(echo $response | jq '.id')
                  curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://sapor-gate:8084", "authenticationType": "LDAP", "token": "'"${TOKEN}"'", "externalAccountFlag": "true", "pipelinePromotionFlag":"false","syncAccountFlag":"false", externalAccountConfiguration": {"accountId": "'"${id}"'","accountName": "gitops-bitbucket", "provider": "BITBUCKET", "config": {"bucketName": "", "region": "","endPoint": "https://github.com/OpsMx//standard-gitops-repo.git", "sourcePath": "" }}}'
                  break
                fi
              fi
              if [[ "$STORAGE_TYPE"  ==  "s3" ]];
              then
                 curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v2/datasources --data '{"datasourceType":"AMAZONS3","name":"gitops-s3","configurationFields":{"access_id":"AWS_ACCESS_KEY_ID","secret_key":"AWS_SECRET_ACCESS_KEY"},"spinnakerNames":[""],"spinEnabled": "false"} }'
                 curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://sapor-gate:8084", "authenticationType": "LDAP", "token": "'"${TOKEN}"'" , "externalAccountFlag": "true", "pipelinePromotionFlag":"false", "syncAccountFlag":"false", externalAccountConfiguration": {"accountName": "gitops-s3","config":{"bucketName":"bucket name.e.g-testbucket","region":"regionofbucket","endPoint":""},"provider": "AMAZONS3"}}'
              fi
            else
              echo "Spinnaker is already Integrated"
              break
            fi
        

    else
        if [ $wait_period -gt 2000 ];
        then
            echo \"Script is timed out as the Spinnaker is not ready yet.......\"
            break
        else
            echo \"Waiting for Spinnaker services to be ready\"
            sleep 1m
        fi
    fi
    done
---
# Source: oes/templates/configmaps/oes-dashboard-configmap.yaml
apiVersion: v1
data:
  dashboard-local.yml: |
    opsmx:
      dashboard:
        installation:
          mode: OES-AP
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    platformservice.url: http://oes-platform:8095
    autopilot.url: http://oes-autopilot:8090
    oes.sapor.url: http://oes-sapor:8085
    visibilityservice.url: http://oes-visibility:8096
    auditclientservice:
      url: "http://oes-audit-client:8098"
    gateservice:
      url: "http://oes-gate:8084"
    app:
      sync:
        enabled: true
    spinnakerLink: /deck/
    
kind: ConfigMap
metadata:
  name: oes-dashboard-config
  labels:
    app: oes
    component: dashboard
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
---
# Source: oes/templates/configmaps/oes-ui-configmap.yaml
apiVersion: v1
data:
  app-config.json: |
    {
        "endPointUrl": "/gate/",
        "setApplicationInterval": 300000,
        "triggerPipeline": false
    }
  help-text.json: "{\n   \"POLICY_LISTING\":{\n      \"HEADER\":\"Policies not found!\",\n
    \     \"BODY\":\"<div >The Policy Management feature allows you to create policies
    to set stringent guidelines for safe and fine grained controls in a CI/CD pipeline.
    This feature gives you to set guard rails by declaring specific policy rules or
    guidelines. For e.g., <strong>Automated Testing should be completed before deployment</strong>
    \ is a rule which must be met when creating a CI/CD pipeline.</div> <br>  <div  >
    \ Static Policy lets users validate the conditions while creating the pipelines,
    whereas Runtime Policy enables users for automated decision making during pipeline
    execution.</div><br> <div > A policy defines a set of conditions that needs to be
    checked. As an example, a policy could be created to define a blackout window period
    (or a moratorium period) for performing production deployments. A moratorium period
    defines the time period within which no production deployments should be performed.
    Any deployment to the production environment during this period will automatically
    be rejected/stopped, if that deployment is triggered during the moratorium period.</div><br><div
    \ > Autopilot uses Open Policy Engine(OPA) for policy definition & execution. OPA
    is a open source, general-purpose policy engine that unifies policy enforcement
    across the stack. It uses a high-level declarative language called Rego that lets
    you specify policy as code and simple APIs to offload policy decision-making from
    your software.</div><br><div  > Click on <strong>New Policy</strong> button to create
    a new policy.</div>\"\n   },\n   \"AGENT_LISTING\":{\n      \"HEADER\":\"No Agents
    found!\",\n      \"BODY\":\"<div><p>The Agent allows Spinnaker installations to
    reach through firewalls in a secure manner,allowing access to private Kubernetes
    clusters as well as reach internal services such as Jenkins and Artifactory. The
    agent is typically used with OpsMx's SaaS Spinnaker offering, where OpsMx hosts
    the Spinnaker installation, but services used by Spinnaker are within a secure area
    owned by the customer.One of the core advantages of using an agent is that the credentials
    do not need to be provided to anyone i.e.credentials remain with - in the cluster
    where deployment is done. </p><p> The Agent is a two part system: a <b> Controller
    </b> runs near Spinnaker, and the <b>Agent</b> runs in the target secure cluster.The
    Agent is configured to communicate with specific services(Kubernetes, Jenkins etc)
    within a customer 's security domain, while the Controller is in Spinnaker's domain.
    </p> <p> The Agent is deployed with a manifest provided by OpsMx.This manifest has
    per - installation credentials to authenticate to the controller,controller address
    etc.Services are configured in the Agent by the customer.URL endpoints.Spinnaker
    account names and credentials are specified to the agent configuration using a service
    configuration.The credentials never leave the agent. </p><p> <b> New Agent </b>
    button is enabled when Spinnaker is configured in <b>Setup->Spinnaker</b>. Click
    on <b> New Agent </b> to create the Agent for your environment.</p></div>\"\n   },\n
    \  \"AGENT_CREATION\":{\n      \"HEADER\":\"Agent\",\n      \"BODY\":\"<p>Adding
    an agent involves the following steps:</p><ul class='helpTextUI'><li>Enter the details
    (Agent Name, Cluster Name and Description) and click save</li> <li>Click <b>Download
    Manifest</b> which appears after save</li> <li>In the remote Kubernetes cluster,
    create service configmap in the default namespace. <span>Examples are available
    <a href='https://github.com/OpsMx/standard-gitops-repo/tree/master/SAMPLES/agent-config'
    target='_blank'>here</a></span> </li> <li>Apply the downloaded manifest in the default
    namespace using <code>kubectl apply -f &lt;downloaded file&gt; </code> <span>Note
    that the agent should be able to reach the LB configured with agent-grpc service</span>
    </li> <li>Check the Setup->Agent screen for the agent connection status</li>  </ul>\",\n
    \     \"AGENT_NAME\":{\n         \"TOOLTIP\":\"Name of the agent with which it will
    referred to\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Agent
    Name cannot be empty\",\n            \"cannotContainSpace\":\"Agent Name cannot
    contain space\",\n            \"noSpecialCharacters\":\"Allowed special character
    is '-'\",\n            \"startingFromNumber\":\"Agent Name should not start with
    number\",\n            \"agentNameExist\":\"Agent Name already exists\"\n         }\n
    \     },\n      \"BODY\":\"<p>The Agent allows Spinnaker installations to reach
    through firewalls in a secure manner,allowing access to private Kubernetes clusters
    as well as reach internal services such as Jenkins and Artifactory.</p> <p>Adding
    an agent involves the following steps:</p><ul class='helpTextUI'><li>Enter the details
    (Agent Name, Cluster Name and Description) and click save</li> <li>Click <b>Download
    Manifest</b> which appears after save</li> <li>In the remote Kubernetes cluster,
    create service configmap in the default namespace. <span>Examples are available
    <a href='https://github.com/OpsMx/standard-gitops-repo/tree/master/SAMPLES/agent-config'
    target='_blank'>here</a></span> </li> <li>Apply the downloaded manifest in the default
    namespace using <code>kubectl apply -f &lt;downloaded file&gt; </code> <span>Note
    that the agent should be able to reach the LB configured with agent-grpc service</span>
    </li> <li>Check the Setup->Agent screen for the agent connection status</li>  </ul>\",\n
    \     \"CLUSTER_NAME\":{\n         \"TOOLTIP\":\"Name of the remote cluster on which
    agent will be installed on\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Cluster
    Name cannot be empty\",\n            \"cannotContainSpace\":\"Cluster Name cannot
    contain space\",\n            \"noSpecialCharacters\":\"Allowed special character
    is '-'\",\n            \"startingFromNumber\":\"Cluster Name should not start with
    number\"\n         }\n      },\n      \"DESCRIPTION\":{\n         \"TOOLTIP\":\"Short
    description about the agent\",\n         \"VALIDATION_MESSAGE\":{\n            \n
    \        }\n      },\n      \"CONNECT_TO_SPINNAKER\":{\n         \"TOOLTIP\":\"The
    spinnaker instance you want to associate this account to\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Please select Spinnaker\"\n         }\n      }\n   },\n
    \  \"CLOUDPROVIDER_LISTING\":{\n      \"HEADER\":\"No Cloud Providers found!\",\n
    \     \"BODY\":\"<div><p>Providers are integrations to Cloud platforms you deploy
    your applications to.</p> <p>In this section, youll register credentials for your
    Cloud platforms. Those credentials are known as Accounts. Autopilot allows you to
    \ create & manage Accounts for different Spinnaker Cloud Providers such as AWS,
    GCP, Kubernetes, etc.</p><p>When Spinnaker is configured for <b>Direct Sync</b>,
    <b>New Accounts</b> button will not be visible.</p><p><b>New Accounts</b> button
    will be enabled when Spinnaker is configured to use External Accounts in <b>Setup->Spinnaker</b>.
    Click on <b>New Accounts</b> button to create an account for your cloud provider.
    \ You can create multiple accounts for the same provider.</p><p>Click on <b>Sync
    Spinnaker Accounts</b> button to sync Cloud Provider accounts with Spinnaker. </p></div>\"\n
    \  },\n   \"CLOUDPROVIDER_CREATION\":{\n      \"HEADER\":\"Cloud Provider\",\n      \"BODY\":\"<p>In
    this page, you can  create & manage Accounts for different Spinnaker Cloud Providers.</p>\",\n
    \     \"AGENT_NAME\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Agent name cannot be empty\",\n            \"cannotContainSpace\":\"Agent
    name cannot contain space\",\n            \"noSpecialCharacters\":\"Allowed special
    character are ',-'\"\n         }\n      },\n      \"CLOUD_PROVIDER\":{\n         \"TOOLTIP\":\"The
    cloud provider type for which you want to add the account\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Please select Cloud Provider\"\n         }\n      },\n
    \     \"SPINNAKER\":{\n         \"TOOLTIP\":\"The Spinnaker instance with which
    this account would be tied to\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Please
    select Spinnaker\"\n         }\n      },\n      \"ENVIRONMENT\":{\n         \"TOOLTIP\":\"The
    environment name for the account. Many accounts can share the same environment (e.g.
    dev, test, prod)\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Please
    select Environment\"\n         }\n      },\n      \"CUSTOM_ENVIRONMENT\":{\n         \"TOOLTIP\":\"\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"noSpecialCharacters\":\"Environment
    Name cannot contain special characters\",\n            \"cannotContainSpace\":\"Environment
    Name cannot contain space\",\n            \"required\":\"Environment Name cannot
    be empty\",\n            \"startingFromNumber\":\"Environment Name cannot start
    with number\",\n            \"maxlength\":\"Environment name should not have more
    than 63 characters!\",\n            \"exists\":\"Environment name already exists\"\n
    \        }\n      },\n      \"ACCOUNT_NAME\":{\n         \"TOOLTIP\":\"Name of the
    account to operate on\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Account
    name cannot be empty\",\n            \"cannotContainSpace\":\"Account name cannot
    contain space\",\n            \"noSpecialCharacters\":\"Allowed special character
    is '-'\"\n         }\n      },\n      \"NAMESPACE\":{\n         \"TOOLTIP\":\"A
    list of namespaces this Spinnaker account can deploy to and will cache (namespaces
    should be 'coma' separated ex: default,dev\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Namespace cannot be empty\",\n            \"cannotContainSpace\":\"Namespace
    cannot contain space\",\n            \"noSpecialCharacters\":\"Special characters
    not allowed except ',-'\"\n         }\n      },\n      \"UPLOAD_KUBECONFIG_FILE\":{\n
    \        \"TOOLTIP\":\"The path to your kubeconfig file. By default, it will be
    under the Spinnaker users home directory in the typical .kube/config location.\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"required\":\"File cannot be empty\"\n
    \        }\n      },\n      \"READ\":{\n         \"TOOLTIP\":\"A user must have
    at least one of these roles in order to view this accounts cloud resources.\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"cannotContainSpace\":\"Read Permissions
    cannot contain space\"\n         }\n      },\n      \"WRITE\":{\n         \"TOOLTIP\":\"A
    user must have at least one of these roles in order to make changes to this accounts
    cloud resources\",\n         \"VALIDATION_MESSAGE\":{\n            \"cannotContainSpace\":\"Write
    Permissions cannot contain space\"\n         }\n      },\n      \"EXECUTE\":{\n
    \        \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":{\n            \"cannotContainSpace\":\"Execute
    Permissions cannot contain space\"\n         }\n      },\n      \"ACCOUNT_ID\":{\n
    \        \"TOOLTIP\":\"Your AWS account ID to manage. Refer http://docs.aws.amazon.com/IAM/latest/UserGuide/console_account-alias.html
    for more information\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Account
    Id cannot be empty\",\n            \"cannotContainSpace\":\"Account Id cannot contain
    space\"\n         }\n      },\n      \"ROLE\":{\n         \"TOOLTIP\":\"If set,
    Halyard will configure a credentials provider that uses AWS Security Token Service
    to assume the specified role\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Role
    cannot be empty\",\n            \"cannotContainSpace\":\"Role cannot contain space\"\n
    \        }\n      },\n      \"REGIONS\":{\n         \"TOOLTIP\":\"The AWS regions
    this Spinnaker account will manage\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Region
    cannot be empty\",\n            \"cannotContainSpace\":\"Region cannot contain space\"\n
    \        }\n      },\n      \"PRIMARY_ACCOUNT\":{\n         \"TOOLTIP\":\"Whether
    this account is the primary account? If yes then provide the access & secret key
    details.\",\n         \"VALIDATION_MESSAGE\":{\n            \n         }\n      },\n
    \     \"ACCESS_KEY\":{\n         \"TOOLTIP\":\"The default access key used to communicate
    with AWS\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Access
    key cannot be empty\"\n         }\n      },\n      \"ACCESS_KEY_BAKERY\":{\n         \"TOOLTIP\":\"The
    default access key used for AWS bakery configuration\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Access Key (Bakery) cannot be empty\"\n         }\n      },\n
    \     \"SECRET_KEY\":{\n         \"TOOLTIP\":\"The secret key used to communicate
    with AWS\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Secret
    key cannot be empty\"\n         }\n      },\n      \"SECRET_KEY_BAKERY\":{\n         \"TOOLTIP\":\"The
    default secret key used for AWS baskery configuration\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Secret Key (Bakery) cannot be empty\"\n         }\n      },\n
    \     \"APP_KEY\":{\n         \"TOOLTIP\":\"The appKey (password) of your service
    principal\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"App
    key cannot be empty\",\n            \"cannotContainSpace\":\"App key cannot contain
    space\"\n         }\n      },\n      \"CLIENT_ID\":{\n         \"TOOLTIP\":\"The
    clientId (also called appId) of your service principal\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Client Id cannot be empty\",\n            \"cannotContainSpace\":\"Client
    Id cannot contain space\"\n         }\n      },\n      \"DEFAULT_KEYVALUT\":{\n
    \        \"TOOLTIP\":\"The name of a KeyVault that contains the user name, password,
    and ssh public key used to create VMs\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Default
    Keyvault cannot be empty\",\n            \"cannotContainSpace\":\"Default Keyvault
    cannot contain space\"\n         }\n      },\n      \"SUBSCRIPTION_ID\":{\n         \"TOOLTIP\":\"The
    subscriptionId that your service principal is assigned to\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Subscription Id cannot be empty\",\n            \"cannotContainSpace\":\"Subscription
    Id cannot contain space\"\n         }\n      },\n      \"TENANT_ID\":{\n         \"TOOLTIP\":\"The
    tenantId that your service principal is assigned to\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Tenant Id cannot be empty\",\n            \"cannotContainSpace\":\"Tenant
    Id cannot contain space\"\n         }\n      },\n      \"GCP_FILE\":{\n         \"TOOLTIP\":\"The
    path to a JSON service account that Spinnaker will use as credentials. This is only
    needed if Spinnaker is not deployed on a Google Compute Engine VM, or needs permissions
    not afforded to the VM it is running on. Refer https://cloud.google.com/compute/docs/access/service-accounts
    for more information\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"File
    cannot be empty\"\n         }\n      },\n      \"AWS_ACCOUNT_NAME\":{\n         \"TOOLTIP\":\"\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"required\":\"Please Select AWS
    Account\"\n         }\n      }\n   },\n   \"SPINNAKER_LISTING\":{\n      \"HEADER\":\"No
    Spinnaker Configured!\",\n      \"BODY\":\"<div><p>The Spinnaker Setup tab allows
    you to setup a Spinnaker instance with which you can connect Autopilot and sync
    all the applications from Spinnaker. </p><p>GitOps style Spinnaker is suported where
    in all configuration is maintained in a repository such as git.  These optional
    sections help configure gitOps style Spinnaker:</p> <p><b>Source Control for Accounts:</b>
    \ In this section, you can specify the repository for External configuration in
    Spinnaker</p> <p><b>Source Control for Pipeline:</b>In this section, you can specify
    the repository for pipeline gitOps in Spinnaker that allows you to save and restore
    pipelines from a git repository.</p> <p>Click on the <b>Add Spinnaker</b> button
    to add Spinnaker instance</p></div>\"\n   },\n   \"SPINNAKER_SETUP\":{\n      \"HEADER\":\"Spinnaker\",\n
    \     \"BODY\":\"<p>In this page you can add / update your Spinnaker instance.</p>
    <p><strong>Fields:</strong></p> <ul class='helpTextUI'> <li><strong>Spinnaker Name</strong>:
    User defined name for Spinnaker instance.<br> <span> Example: opsmx-spinnaker</span></li>
    <li><strong>Spinnaker Gate URL</strong>: Gate URL of the Spinnaker instance.<br>
    <span>Example: https://spinnaker-gate.xyz.com or http://oes-gate:8084</span></li>
    <li><strong>Authentication Type:</strong>: Can be LDAP or X509</li> <li><strong>Token:
    </strong>This is used when Authentication Type is LDAP; username & password to LDAP
    server separated by ':' in base64 format; Output of 'echo -ne 'username:password'
    | base64 -w0'</li>  <li><strong>Password: </strong>This is used when Authentication
    Type is LDAP; Password for P12 File</li> <li><strong>P12 File:</strong> This is
    used when Authentication Type is X509; P12 File needed for X509/AD Authentication</li>
    <li><strong>Source Control for Accounts: </strong>In this section, you can specify
    the repository for External configuration in Spinnaker</li> <li><strong>Source Control
    for Pipeline: </strong>In this section, you can specify the repository for pipeline
    gitOps in Spinnaker that allows you to save and restore pipelines from a git repository</li>
    </ul>\",\n      \"SPINNAKER_NAME\":{\n         \"TOOLTIP\":\"Name of the Spinnaker
    instance\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Spinnaker
    Name cannot be empty\",\n            \"cannotContainSpace\":\"Spinnaker Name cannot
    contain space\",\n            \"noSpecialCharacters\":\"Allowed special character
    is '-'\",\n            \"startingFromNumber\":\"Spinnaker Name should not start
    with number\"\n         }\n      },\n      \"SPINNAKER_GATE_URL\":{\n         \"TOOLTIP\":\"Gate
    Url of the Spinnaker instance\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Spinnaker
    Gate URL cannot be empty\",\n            \"cannotContainSpace\":\"Spinnaker Gate
    URL cannot contain space\",\n            \"invalidUrl\":\"Spinnaker Gate URL is
    invalid\"\n         }\n      },\n      \"AUTHENTICATION_TYPE\":{\n         \"TOOLTIP\":\"Select
    the type of authentication for the spinnaker being added\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Please select Authentication Type\"\n         }\n      },\n
    \     \"LDAP_USERNAME\":{\n         \"TOOLTIP\":\"User Name\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"User Name cannot be empty\",\n            \"minlength\":\"User
    Name should be more than 4 characters\"\n         }\n      },\n      \"LDAP_PASSWORD\":{\n
    \        \"TOOLTIP\":\"Password\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Password
    cannot be empty\",\n            \"minlength\":\"Password should be more than 8 characters\"\n
    \        }\n      },\n      \"TOKEN\":{\n         \"TOOLTIP\":\"Token for Spinnaker
    authentication\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Token
    cannot be empty\",\n            \"minlength\":\"Token should be more than 8 characters\"\n
    \        }\n      },\n      \"PASSWORD\":{\n         \"TOOLTIP\":\"Password\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"required\":\"Password cannot be
    empty\",\n            \"minlength\":\"Password should be more than 8 characters\"\n
    \        }\n      },\n      \"P12_FILE\":{\n         \"TOOLTIP\":\"P12 File\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"required\":\"P12 File cannot be
    empty\"\n         }\n      },\n      \"SYNC_ACCOUNTS\":{\n         \"TOOLTIP\":\"Select
    Mode of synchronisation of Cloud Providers between Autopilot & Spinnaker\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Please select Sync Accounts type\"\n         }\n      },\n
    \     \"ACCOUNTS_PROVIDER\":{\n         \"TOOLTIP\":\"Source Control for Halyard
    Configuration and / or External Account Configuration\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Please select provider\"\n         }\n      },\n      \"ACCOUNTS_ACCOUNT_NAME\":{\n
    \        \"TOOLTIP\":\"Account name of the Source Control\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Please select Account Name\"\n         }\n      },\n
    \     \"ACCOUNTS_REPOSITORY\":{\n         \"TOOLTIP\":\"Repository name with full
    path in the selected Source Control Eg., https://github.com/OpsMx/Opsmx-Saas.git\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"required\":\"Repository cannot
    be empty\",\n            \"cannotContainSpace\":\"Repository cannot contain space\",\n
    \           \"invalidUrl\":\"Repository is invalid\"\n         }\n      },\n      \"ACCOUNTS_SOURCE_PATH\":{\n
    \        \"TOOLTIP\":\"Existing path in the repository\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \n         }\n      },\n      \"ACCOUNTS_REGION\":{\n         \"TOOLTIP\":\"The
    AWS regions this Spinnaker account will manage\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Region cannot be empty\",\n            \"cannotContainSpace\":\"Region
    cannot contain space\",\n            \"startingFromNumber\":\"Region should not
    start with number\"\n         }\n      },\n      \"ACCOUNTS_BUCKET_NAME\":{\n         \"TOOLTIP\":\"Bucket
    Name\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Bucket Name
    cannot be empty\",\n            \"cannotContainSpace\":\"Bucket Name cannot contain
    space\",\n            \"startingFromNumber\":\"Bucket Name should not start with
    number\"\n         }\n      },\n      \"PIPELINE_PROVIDER\":{\n         \"TOOLTIP\":\"Use
    this Spinnaker for pipeline promotion.\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Please
    select provider\"\n         }\n      },\n      \"PIPELINE_ACCOUNT_NAME\":{\n         \"TOOLTIP\":\"\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"required\":\"Please select Account
    Name\"\n         }\n      },\n      \"PIPELINE_REPOSITORY\":{\n         \"TOOLTIP\":\"\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"required\":\"Repository cannot
    be empty\",\n            \"cannotContainSpace\":\"Repository cannot contain space\",\n
    \           \"invalidUrl\":\"Repository is invalid\"\n         }\n      },\n      \"PIPELINE_SOURCE_PATH\":{\n
    \        \"TOOLTIP\":\"Existing path in the repository\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \n         }\n      },\n      \"PIPELINE_REGION\":{\n         \"TOOLTIP\":\"\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"required\":\"Region cannot be empty\",\n
    \           \"cannotContainSpace\":\"Region cannot contain space\",\n            \"startingFromNumber\":\"Region
    should not start with number\"\n         }\n      },\n      \"PIPELINE_BUCKET_NAME\":{\n
    \        \"TOOLTIP\":\"Bucket Name\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Bucket
    Name cannot be empty\",\n            \"cannotContainSpace\":\"Bucket Name cannot
    contain space\",\n            \"startingFromNumber\":\"Bucket Name should not start
    with number\"\n         }\n      }\n   },\n   \"INTEGRATOR_LISTING\":{\n      \"HEADER\":\"No
    Integrator found!\",\n      \"BODY\":\"<div><p>Autopilot offers integration with
    many CI/CD Tools. Integrations are grouped under the following categories - Artifact,
    CI, Governance, Monitoring Tools, Notifications, Policy and SAST/DAST.</p> <p> Integrations
    are used to </p> <ul> <li> pull logs & metrics for Continuous Verification </li>
    <li> pull meta data from CI/CD Tools for Informed Approvals </li> <li> enforce organizational
    policies at the time of creating or executing a  pipeline. </li> <li> configure
    integrations in Spinnaker for Artifacts, Notifications. etc </li> </ul> <p>Click
    on the <b>New Integration</b> button to add accounts for your CI/CD tools</p> </div>\",\n
    \     \"SYNC_SPINNAKER_ACCOUNTS\":{\n         \"TOOLTIP\":\"Push Integration changes
    to Spinnaker\",\n         \"VALIDATION_MESSAGE\":\"\"\n      }\n   },\n   \"PIPELINE_EXECUTION_AUDIT_LISTING\":{\n
    \     \"HEADER\":\"Pipeline executions not found!\",\n      \"BODY\":\"<div>This
    page shows pipeline executions coming from a CD Tool such as Spinnaker in a list
    view. It also contains the summary view showing the total number of Pipeline Runs,
    Successful Runs, Failed Runs, Cancelled Runs.</div><br>    <div >Only important
    fields including Application, Service, Pipeline, Status, Start Time and End Time
    are shown by default. Additional fields can be enabled using the Hamburger menu
    towars the right corner.</div><br> <div>Ensure that the Spinnaker is already connected
    under <strong><a routerLink='/setup/spinnaker'>Setup -> Spinnaker</a></strong>.
    Pipeline executions will start appearing in this page after establishing connection
    to Spinnaker. </div>\",\n      \"TOOLTIP\":{\n         \"EXECUTION_DATA\":\"Pipeline
    is in Running State\",\n         \"CONNECTOR_DATA\":\"Pipeline is in Running State\",\n
    \        \"STAGE_DURATION\":\"Pipeline is in Running State\"\n      },\n      \"VALIDATION_MESSAGE\":{\n
    \        \"STAGE_DURATION\":\"No Data available to view Stage Duration\"\n      }\n
    \  },\n   \"PIPELINE_AUDIT_LISTING\":{\n      \"HEADER\":\"Pipeline updates not
    found!\",\n      \"BODY\":\"<div>This page shows pipeline updates coming from a
    CD Tool such as Spinnaker in a list view. </div> <div >  Ensure that the Spinnaker
    is already connected under  <strong><a routerLink='/setup/spinnaker'>Setup -> Spinnaker</a></strong>.
    Pipeline updates will start appearing in this page after establishing connection
    to Spinnaker.</div>\"\n   },\n   \"POLICY_AUDIT_LISTING\":{\n      \"HEADER\":\"Policy
    updates / executions not found!\",\n      \"BODY\":\"<div>This page shows policy
    updates and policy executions, along with allowed/denied information, in a list
    view. Possible uses, apart from audit and compliance, includes helping users understand
    the policies that they might be inadvertently trying to break.</div><br> <div>For
    policy updates, ensure that a policy is created/updated under <strong><a routerLink='/policymanagement'>Compliance
    -> Policy Management</a></strong>. For policy execution events, please add a policy
    in a pipeline and execute it.</div>\"\n   },\n   \"POLICY_CREATION\":{\n      \"BODY\":\"<p>In
    this page, you can  define & manage policies.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li> <strong>Name:</strong> User defined name for the policy</li><li><strong>Policy
    Type:</strong> Static or Runtime Policy</li><li> <strong>Policy Engine:</strong>
    Policy Engine to be used; currently, only OPA is supported</li> <li><strong>Policy
    Engine Account:</strong> Policy Engine Account for the Credentials </li>        <li><strong>Policy
    File:</strong> File containing the Policy You can upload the file by clicking on
    <strong>Choose File</strong> button. This is optional. If not present, you can enter
    the policy directly in the <strong>Policy Details</strong> field</li><li> <strong>Policy
    Details:</strong> Policy definition</li>                                 <li><strong>Policy
    Permissions:</strong> Enable/disable access to the policy in Autopilot to specific
    usergroup</li></ul>\",\n      \"HEADER\":\"Policy\",\n      \"NAME\":{\n         \"TOOLTIP\":\"Policy
    Name\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Name cannot
    be empty\",\n            \"cannotContainSpace\":\"Name cannot contain space\",\n
    \           \"exists\":\"Name already exists\"\n         }\n      },\n      \"POLICY_DETAILS\":{\n
    \        \"TOOLTIP\":\"Policy Details\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Policy
    Details cannot be empty\"\n         }\n      },\n      \"POLICY_ENGINE\":{\n         \"TOOLTIP\":\"Supported
    Policy Account Types\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Please
    select Policy Account Type\"\n         }\n      },\n      \"POLICY_ENGINE_ACCOUNT\":{\n
    \        \"TOOLTIP\":\"Policy Account Names\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Please select Policy Engine Account\"\n         }\n      },\n
    \     \"POLICY_TYPE\":{\n         \"TOOLTIP\":\"A static policy lets users validate
    conditions before the start of execution, whereas a Runtime policy enables users
    for automated decision making during execution.\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Please select Policy Engine Type\"\n         }\n      },\n
    \     \"POLICY_DESCRIPTION\":{\n         \"TOOLTIP\":\"Policy Description\"\n      },\n
    \     \"POLICY_FILE\":{\n         \"TOOLTIP\":\"Policy File\"\n      }\n   },\n
    \  \"VERIFICATION\":{\n      \"HEADER\":\"Verfication Gate executions not found!\",\n
    \     \"BODY\":\"<div><p>The Continuous Verification performs automated log and
    metrics analysis for new   releases with built-in unsupervised and supervised machine
    learning algorithms for risk analysis and canary deployments.</p> <p>Continuous
    Verification is a release verification process that provides Dev and Ops engineers
    an intelligent automated real-time actionable risk assessment of a new release deployed.
    The Continuous Verification verifies the latest version of the service comparing
    to the baseline or prior release after production rollout.         The baseline
    can be a deployment done prior or the current deployment during rollout using canary
    or blue/green or rolling update strategies.</p> <p>It leverages unsupervised and
    supervised machine learning techniques to analyze 100s of metrics and logs data
    to perform in-depth analysis of architectural regressions, performance, scalability
    and security violations of new releases in a scalable way for enterprises.</p> <p>Autopilot
    provides a Verification Gate to analyse logs from your Target Application and this
    can be inserted as a Stage in your CI/CD Pipeline.Note that one must configure the
    metric and log datasources, such as Prometheus and Elastic before using this functionality.</p>
    <p>This page shows Verification Gate executions in a list view.  </p> <p>Insert
    Verification Gate to a pipeline in your application using <a [routerLink]='['/setup/applications']'><strong>Setup
    -> Applications</strong></a>. When the pipeline is run, the Gate executions will
    start appearing in this page.</p></div>\",\n      \"LOG_ANALYSIS\":{\n         \"BODY\":\"\",\n
    \        \"SENSITIVITY\":{\n            \"TOOLTIP\":\"Impact of Unexpected Issues
    on the log scoring\",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        },\n         \"PERCEIVED_RISK\":{\n            \"TOOLTIP\":\"The overall
    risk associated with the changes in this verification run\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         }\n      },\n      \"ANALYSIS_SUMMARY\":{\n
    \        \"LOG_TEMPLATE\":{\n            \"TOOLTIP\":\"Log Template\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"METRIC_TEMPLATE\":{\n            \"TOOLTIP\":\"Metric
    Template\",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        },\n         \"LOG_BASELINE_START_TIME\":{\n            \"TOOLTIP\":\"Baseline
    Start Time\",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        },\n         \"LOG_BASELINE_END_TIME\":{\n            \"TOOLTIP\":\"Baseline
    End Time\",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        },\n         \"LOG_NEW_RELEASE_START_TIME\":{\n            \"TOOLTIP\":\"New
    Release Start Time\",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        },\n         \"LOG_NEW_RELEASE_END_TIME\":{\n            \"TOOLTIP\":\"New
    Release End Time\",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        },\n         \"ANALYSIS_TYPE\":{\n            \"TOOLTIP\":\"Analysis Type\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"LOG_STATUS\":{\n            \"TOOLTIP\":\"Log Status\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"LOG_SCORE\":{\n            \"TOOLTIP\":\"Log
    Score\",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        },\n         \"METRIC_STATUS\":{\n            \"TOOLTIP\":\"Metric Status\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"METRIC_SCORE\":{\n            \"TOOLTIP\":\"Metric Score\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"BASELINE_SIZE\":{\n            \"TOOLTIP\":\"Baseline
    Size\",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        },\n         \"NEW_RELEASE_SIZE\":{\n            \"TOOLTIP\":\"New Release
    Size\",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        },\n         \"BASELINE_LINES\":{\n            \"TOOLTIP\":\"Baseline Lines\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"NEW_RELEASE_LINES\":{\n            \"TOOLTIP\":\"New Release Lines\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"ANALYSIS_DURATION\":{\n            \"TOOLTIP\":\"Analysis Duration\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"LIFETIME_HOURS\":{\n            \"TOOLTIP\":\"Lifetime Hours\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"RECLASSIFICATION_DURATION\":{\n
    \           \"TOOLTIP\":\"Reclassification Duration\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"INTERVAL_MINUTES\":{\n            \"TOOLTIP\":\"Interval
    Minutes\",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        },\n         \"REGULAR_EXPRESSION\":{\n            \"TOOLTIP\":\"Regular
    Expression\",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        },\n         \"RESPONSE_KEY\":{\n            \"TOOLTIP\":\"Response Key\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"SCORING_ALGORITHM\":{\n            \"TOOLTIP\":\"Scoring Algorithm\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"BASELINE_LOGS\":{\n            \"TOOLTIP\":\"Baseline Logs\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"NEW_RELEASE_LOGS\":{\n            \"TOOLTIP\":\"New
    Release Logs\",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        }\n      },\n      \"METRIC_ANALYSIS\":{\n         \"BODY\":\"\"\n      },\n
    \     \"CORRELATION\":{\n         \"BODY\":\"\"\n      }\n   },\n   \"MANUAL_TRIGGER\":{\n
    \     \"BODY\":\"<p>Continuous Verification is a REST service that can be deployed
    on premise or use managed cloud service for analysis. Continuous Verification interfaces
    with monitoring systems for logs and metrics and uses the metadata provided in start
    analysis phase to retrieve the logs and metrics for deployment verification. Continuous
    Verification does not interface with the services deployed directly for its analysis.
    \           Deployment Pipeline can be based on Spinnaker or Jenkins for Enterprise
    Continuous Delivery. Verification can also be triggered manually by providing the
    required parameters in this dialog box.</p>\",\n      \"APPLICATION\":{\n         \"TOOLTIP\":\"Name
    of the application\",\n         \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"BASELINE_START_TIME\":{\n
    \        \"TOOLTIP\":\"Time to enable warming up of the container\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"NEW_RELEASE_START_TIME\":{\n         \"TOOLTIP\":\"Intervals in
    which metric-data is fetched and analysed\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"SUCCESSFUL_SCORE\":{\n         \"TOOLTIP\":\"The score under which
    the Analysis should fail\",\n         \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"UNHEALTHY_SCORE\":{\n
    \        \"TOOLTIP\":\"The score above which the Analysis should be a pass\",\n
    \        \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"ANALYSIS_LIFETIME\":{\n
    \        \"TOOLTIP\":\"The time in hours for which the Canary Analysis should be
    run\",\n         \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"RUN_INFO\":{\n         \"TOOLTIP\":{\n
    \           \"Build Info\":\"http://jenkins.opsmx.net:8181/jenkins/job/Dev-visibilityservice-build-branch/770/\",\n
    \           \"Code Repository\":\"https://github.com/OpsMx/visibility-service\",\n
    \           \"Version\":\"v1.09\"\n         },\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"SERVICE\":{\n         \"TOOLTIP\":\"Service\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"TEMPLATE_NAME\":{\n         \"TOOLTIP\":\"Template Name\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"GATE\":{\n         \"TOOLTIP\":\"Gate\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"FILTER_KEY\":{\n         \"TOOLTIP\":\"Filter Key\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"BASELINE\":{\n         \"TOOLTIP\":\"Baseline\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"NEW_RELEASE\":{\n         \"TOOLTIP\":\"New Release\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     }\n   },\n   \"TEST_VERIFICATON\":{\n      \"HEADER\":\"Test Verfication Gate
    executions not found!\",\n      \"BODY\":\"<div> <p>The Continuous Verification
    performs automated log and metric analysis for new releases with built-in unsupervised
    and supervised machine learning algorithms for risk analysis. Autopilot provides
    a Test Verification Gate to analyse logs from your Test Harness and this can be
    inserted as a Stage in your CI/CD Pipeline. </p>     <p>This page shows Test Verification
    Gate executions in a list view. </p> <p>Insert Test Verification Gate to a pipeline
    in your application using <a [routerLink]='['/setup/applications']'><strong>Setup
    -> Applications</strong></a>.When the pipeline is run, the Gate executions will
    start appearing in this page.</p> </div>\"\n   },\n   \"TEST_CASE\":{\n      \"HEADER\":\"Test
    Cases not found!\",\n      \"BODY\":\"<div> <p>The Continuous Verification performs
    automated log and metric analysis for new releases with built-in unsupervised and
    supervised machine learning algorithms for risk analysis. Autopilot provides a Test
    Verification Gate to analyse logs from your Test Harness and this can be inserted
    as a Stage in your CI/CD Pipeline. </p>     <p>This page shows Test Cases in a list
    view. </p> <p>Insert Test Verification Gate to a pipeline in your application using
    <a [routerLink]='['/setup/applications']'><strong>Setup -> Applications</strong></a>.When
    the pipeline is run, the Gate executions will start appearing in this page.</p>
    </div>\"\n   },\n   \"VISIBILITY_LISTING\":{\n      \"HEADER\":\" <div><span style='font-size:
    16px; font-weight: bold;'>Approval Gate executions not found!</span></div>\",\n
    \     \"BODY\":\"<div><p>Autopilot provides <strong>approval</strong> mechanism
    for deployments. To make an informed decision regarding pipeline execution, an approver
    may need to check the data from multiple data sources, such as CI Systems, Repositories,
    SAST/DAST Tools etc. Autopilot provides Approval Gate feature which fetches relevant
    information from multiple CI/CD Tools, presents the data in one place, to enable
    the user to make an quick and informed decision on pipeline execution. This Gate
    can be inserted as a Stage in your CI/CD Pipeline. </p> <p>Note that appropriate
    data sources must be configured in the <strong>Integration</strong> view before
    Approval stage can be used.</p> <p>This page shows Approval Gate executions in a
    list view.</p> <p> Insert Approval Gate to a pipeline in your application using
    <strong><a routerLink='/setup/v2/applications'>Setup -> Applications</a></strong>.
    When the pipeline is run, the Gate executions will start appearing in this page.
    </p> </div>\"\n   },\n   \"VISIBILITY_DETAILS\":{\n      \"APPLICATION_NAME\":{\n
    \        \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"SERVICE_NAME\":{\n
    \        \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"APPROVAL_BTN_TITLE\":{\n
    \        \"TOOLTIP\":\"Insufficient Permission to execute\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"GATE_NAME\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"STATUS\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"COMMENT\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"TRIGGER_URL\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"APPROVAL_GROUP\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"CONNECTORS\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"ACTIVATED_TIME\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"REVIEWED_AT\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"REVIEWER\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"COMMENTS\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     }\n   },\n   \"FORM_GRID\":{\n      \"ADD_NEW_ROW\":{\n         \"TOOLTIP\":\"Add
    New Row\",\n         \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"DELETE_ROW\":{\n
    \        \"TOOLTIP\":\"Delete row\",\n         \"VALIDATION_MESSAGE\":\"\"\n      }\n
    \  },\n   \"APPLICATION_DASHBOARD\":{\n      \"VERIFICATION_FAILURES\":{\n         \"TOOLTIP\":\"Total
    number of Verification Failures including Test Verification Failures\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     }\n   },\n   \"APPLICATION_LISTING\":{\n      \"HEADER\":\"No Applications
    found!\",\n      \"BODY\":\"<p> You will be able to view the applications you have
    created or imported from a CD Tool such as Spinnaker in this page. There could be
    just one or multiple services in an application. Each service can have multiple
    pipelines and each pipeline can have multiple stages needed in order to successfully
    deploy the application. </p> <p>You can create native Autopilot applications or
    import the applications created in Spinnaker.</p> <p><strong>Spinnaker Application</strong>:
    To import applications from Spinnaker, click on the <strong>Sync Spinnaker Applications</strong>
    button; before doing this, ensure that the Spinnaker is already connected under
    <strong><a  routerLink='/setup/spinnaker'>Setup -> Spinnaker</a></strong></p> <p><strong>Autopilot
    Application</strong>: To create a native Autopilot Application, click on the <strong>New
    Application</strong> button</p>\",\n      \"PLACEHOLDER\":\"You don't have access
    to this Page. Please contact your Administrator\",\n      \"SYNC_SPINNAKER\":{\n
    \        \"TOOLTIP\":\"To be able to work on applications created in Spinnaker,
    you need to import them here\",\n         \"VALIDATION_MESSAGE\":\"\"\n      }\n
    \  },\n   \"START_DEPLOYMENT\":{\n      \"APPLICATION_NAME\":{\n         \"TOOLTIP\":\"\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"required\":\"Application Name is
    required\",\n            \"empty\":\"Please create Spinnaker Application to continue\"\n
    \        }\n      },\n      \"SERVICE_NAME\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Service Name is required\",\n            \"empty\":\"Pipelines
    are not present for this Application\"\n         }\n      },\n      \"START_DEPLOYMENT_BTN\":{\n
    \        \"TOOLTIP\":\"Please create Spinnaker Application to 'Start New Deployment'\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"required\":\"Service Name is required\"\n
    \        }\n      }\n   },\n   \"APPLICATION_DETAILS\":{\n      \"HEADER\":\"Application
    Details\",\n      \"BODY\":\"<ul class='helpTextUI'><li><strong>Application Name</strong>:
    User defined name of the application</li> <li><strong>Description</strong>: Application
    description</li> <li><strong>Email ID</strong>: Your email id</li></ul>\",\n      \"APPLICATION_NAME\":{\n
    \        \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":{\n            \"exists\":\"Application
    already exists\",\n            \"noSpecialCharacters\":\"Application Name cannot
    contain special characters\",\n            \"cannotContainSpace\":\"Application
    Name cannot contain space\",\n            \"required\":\"Application Name cannot
    be empty\",\n            \"startingFromNumber\":\"Application Name cannot start
    with numbers\",\n            \"maxlength\":\"Application name should not have more
    than 63 characters!\"\n         }\n      },\n      \"APPLICATION_DESCRIPTION\":{\n
    \        \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"EMAIL_ID\":{\n
    \        \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":{\n            \"email\":\"Email
    Id is invalid\",\n            \"required\":\"Email Id cannot be empty\"\n         }\n
    \     }\n   },\n   \"SERVICE_DETAILS\":{\n      \"HEADER\":\"Services\",\n      \"BODY\":\"<p>An
    Application can contain multiple services. A service can contain multiple pipelines.
    When a Service is created, a Pipeline with the same name is created automatically.
    You can add more pipelines by clicking on '+' symbol in <strong>Service Pipeline</strong></p>\",\n
    \     \"SERVICE_NAME\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"exists\":\"Service already exists\",\n            \"noSpecialCharacters\":\"Service
    Name cannot contain special characters\",\n            \"cannotContainSpace\":\"Service
    Name cannot contain space\",\n            \"required\":\"Service Name cannot be
    empty\",\n            \"startingFromNumber\":\"Service Name cannot start with number\",\n
    \           \"maxlength\":\"Service name should not have more than 63 characters!\"\n
    \        }\n      },\n      \"SERVICE_PIPELINE\":{\n         \"TOOLTIP\":\"\",\n
    \        \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"ADD_NEW_SERVICE\":{\n         \"TOOLTIP\":\"Add
    a new Service\",\n         \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"SHOW_OR_HIDE_SERVICE\":{\n
    \        \"TOOLTIP\":\"Show / Hide this Service in the Application Dashboard\",\n
    \        \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"DELETE_PIPELINE_ICON\":{\n
    \        \"TOOLTIP\":\"Delete Pipeline from Service\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"DELETE_PERMISSION\":{\n         \"TOOLTIP\":\"Insufficient Permission
    to Delete this Service\",\n         \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"DELETE_SERVICE\":{\n
    \        \"TOOLTIP\":\"Service can be deleted on deleting pipelines\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     }\n   },\n   \"GROUP_PERMISSION\":{\n      \"APP_PERMISSIONS\":{\n         \"TOOLTIP\":\"Authorization
    definition for this Application\",\n         \"VALIDATION_MESSAGE\":{\n            \"groupValid\":\"Groups
    cannot be empty\",\n            \"permissionsValid\":\"Atleast 1 permission should
    be assigned to the groups\",\n            \"allPermissionForOneGroup\":\"Atleast
    1 group should have all permissions\"\n         }\n      },\n      \"INTEGRATORS_PERMISSIONS\":{\n
    \        \"TOOLTIP\":\"Authorization definition for this Integration\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"CLOUD_PROVIDER_PERMISSIONS\":{\n         \"TOOLTIP\":\"Authorization
    definition for this Cloud Provider\",\n         \"VALIDATION_MESSAGE\":\"\"\n      },\n
    \     \"AGENT_PERMISSIONS\":{\n         \"TOOLTIP\":\"Authorization definition for
    this Agent\",\n         \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"POLICY_PERMISSIONS\":{\n
    \        \"TOOLTIP\":\"Authorization definition for this Policy\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"ADD_GROUP\":{\n         \"TOOLTIP\":\"Add New Group\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"DELETE\":{\n         \"TOOLTIP\":\"Delete\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     }\n   },\n   \"GATE_DETAILS\":{\n      \"HEADER\":\"Gate Configuration\",\n
    \     \"BODY\":\"<p>Select Gates from <strong>Existing Gates</strong> dropdown to
    load Gate Configuration and to add new Gate Configuration click the <strong>Add
    New Gate</strong> button</p> <p>Autopilot has the following Gate Types</p> <ul class='helpTextUI'>
    <li><strong>Approval</strong>: Fetches relevant information from multiple CI/CD
    Tools, presents the data in one place, to enable the user to make quick and informed
    decision on pipeline execution</li> <li><strong>Verification</strong>: Analyze logs
    & metrics from your target application to evaluate the risk in software delivery</li>
    <li><strong>Test Verification</strong>: Analyze logs from your Test Harness to evaluate
    the risk in software delivery</li>  <li><strong>Policy</strong>: Defines a set of
    conditions that need to be verified while creating or executing a CI/CD pipeline</li>
    </ul>\",\n      \"PIPELINE\":{\n         \"TOOLTIP\":\"Shows the structure of how
    the Gates are stacked in the Pipeline\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"TYPE\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"EXISITING_GATE\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"ENVIRONMENT\":{\n         \"TOOLTIP\":\"Specify Environment for
    this Gate\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Environment
    Name is Invalid\"\n         }\n      },\n      \"CUSTOM_ENVIRONMENT_NAME\":{\n         \"TOOLTIP\":\"\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"noSpecialCharacters\":\"Environment
    Name cannot contain special characters\",\n            \"cannotContainSpace\":\"Environment
    Name cannot contain space\",\n            \"required\":\"Environment Name cannot
    be empty\",\n            \"startingFromNumber\":\"Environment Name cannot start
    with number\",\n            \"maxlength\":\"Environment name should not have more
    than 63 characters!\"\n         }\n      },\n      \"GATE_NAME\":{\n         \"TOOLTIP\":\"\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"exists\":\"Gate already exists\",\n
    \           \"noSpecialCharacters\":\"Gate Name cannot contain special characters\",\n
    \           \"cannotContainSpace\":\"Gate Name cannot contain space\",\n            \"required\":\"Gate
    Name cannot be empty\",\n            \"startingFromNumber\":\"Gate Name cannot start
    with number\",\n            \"maxlength\":\"Gate name should not have more than
    63 characters!\"\n         }\n      },\n      \"DEPENDS_ON\":{\n         \"TOOLTIP\":\"This
    field determines the placement of the current Gate in the Pipeline. This field is
    not required if there are no Stages in the Pipeline\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Depends On cannot be empty\"\n         }\n      },\n
    \     \"CONNECTOR\":{\n         \"TOOLTIP\":\"Tool to gather information for informed
    Approvals\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Please
    select Connector\"\n         }\n      },\n      \"ACCOUNT\":{\n         \"TOOLTIP\":\"Account
    name of the connector\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Please
    select Account\"\n         }\n      },\n      \"TEMPLATE\":{\n         \"TOOLTIP\":\"Define
    the specific fields of interest from connector\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Please select Template\"\n         }\n      },\n      \"ADD_NEW_TEMPLATE\":{\n
    \        \"TOOLTIP\":\"Add New Connector\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"EDIT_TEMPLATE\":{\n         \"TOOLTIP\":\"Edit Template\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"VIEW_TEMPLATE\":{\n         \"TOOLTIP\":\"View Template\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"DELETE_TEMPLATE\":{\n         \"TOOLTIP\":\"Delete Template\",\n
    \        \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"TEMPLATE_TOOL_TYPE\":{\n
    \        \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"TEMPLATE_NAME\":{\n
    \        \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":{\n            \"noSpecialCharacters\":\"Template
    Name cannot contain special characters\",\n            \"required\":\"Template Name
    cannot be empty\",\n            \"startingFromNumber\":\"Template Name cannot start
    with number\",\n            \"maxlength\":\"Template Name should not have more than
    63 characters!\"\n         }\n      },\n      \"TEMPLATE_DESCRIPTION\":{\n         \"TOOLTIP\":\"\",\n
    \        \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"AUTOMATED_APPROVAL\":{\n
    \        \"TOOLTIP\":\"Use predefined conditions to Approve or Reject a request.
    You can configure conditions using Policies.\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Please select Approval Condition\"\n         }\n      },\n
    \     \"APPROVAL_GROUPS\":{\n         \"TOOLTIP\":\"Selected groups will be able
    to review this Approval Gate\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Please
    select Approval Groups to continue\"\n         }\n      },\n      \"APPROVAL_GROUP_MSG\":{\n
    \        \"TOOLTIP\":\"Selected groups should have atleast view access to the application\",\n
    \        \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"GATE_SECURITY_SOURCE_URL\":{\n
    \        \"TOOLTIP\":\"Source Url\",\n         \"VALIDATION_MESSAGE\":\"\"\n      },\n
    \     \"GATE_SECURITY_SOURCE_URL_COPY\":{\n         \"TOOLTIP\":\"Copy Source Url\",\n
    \        \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"PAYLOAD_CONSTRAINTS\":{\n
    \        \"TOOLTIP\":\"Payload Constraints for Gate Security\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"PAYLOAD_CONSTRAINTS_KEY\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"cannotContainSpace\":\"Key cannot contain space\",\n            \"required\":\"Invalid
    Key\"\n         }\n      },\n      \"LOG_TEMPLATE\":{\n         \"TOOLTIP\":\"A
    collection of all the information needed to run the log analysis\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"CREATE_GATE_CONFIG_TEMPLATE\":{\n         \"TOOLTIP\":\"Create
    New Template\",\n         \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"EDIT_GATE_CONFIG_TEMPLATE\":{\n
    \        \"TOOLTIP\":\"Edit Template\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"VIEW_GATE_CONFIG_TEMPLATE\":{\n         \"TOOLTIP\":\"View Template\",\n
    \        \"VALIDATION_MESSAGE\":\"\"\n      },\n      \"DELETE_GATE_CONFIG_TEMPLATE\":{\n
    \        \"TOOLTIP\":\"Delete Template\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"METRIC_TEMPLATE\":{\n         \"TOOLTIP\":\"Information needed
    to run the metric analysis\",\n         \"VALIDATION_MESSAGE\":\"\"\n      },\n
    \     \"POLICY\":{\n         \"TOOLTIP\":\"\",\n         \"VALIDATION_MESSAGE\":\"\"\n
    \     },\n      \"DELETE_PERMISSION\":{\n         \"TOOLTIP\":\"Insufficient Permission
    to Delete this Gate\",\n         \"VALIDATION_MESSAGE\":\"\"\n      }\n   },\n   \"LOGGED_INUSER_DETAILS\":{\n
    \     \"HEADER\":\"No Users found\",\n      \"BODY\":\"\"\n   },\n   \"INTEGRATION\":{\n
    \     \"AMAZONS3\":{\n         \"HEADER\":\"Amazon S3\",\n         \"BODY\":\"<span><p>Amazon
    S3 integration can be used to configure Spinnaker for Amazon S3.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Account Name</strong>: User defined name for the
    Amazon S3 Account <span class='noBr'>(Example: opsmx-s3)</span></li><li><strong>Access
    Key Id</strong>: AWS Access Key Id</li><li><strong>Secret Access Key</strong>: AWS
    Secret Access Key</li><li><strong>Connect to Spinnaker</strong>: Toggle to configure
    Spinnaker for Amazon S3</li><li><strong>Permissions</strong>: Enable/disable access
    to the Amazon S3 account in Autopilot to specific usergroups</li></ul></span>\",\n
    \        \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User defined name for the
    Amazon S3 account\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"ACCESS_ID\":{\n            \"TOOLTIP\":\"AWS
    Access Key Id\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Access
    Key Id cannot be empty\"\n            }\n         },\n         \"SECRET_KEY\":{\n
    \           \"TOOLTIP\":\"AWS Secret Access Key\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Secret Access Key cannot be empty\"\n            }\n
    \        },\n         \"SPINNAKERTOGGLE\":{\n            \"TOOLTIP\":\"\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         }\n      },\n      \"ARTIFACTORY\":{\n
    \        \"HEADER\":\"Artifactory\",\n         \"BODY\":\"<span><p>Artifactory integration
    can be used as a datasource for Approval Gate as well as to configure Spinnaker
    for Artifactory.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User defined name for the Artifactory Account <span class='noBr'>(Example:
    opsmx-artifactory)</span></li><li><strong>Endpoint</strong>: Artifactory URL <span
    class='noBr'>(Example: https://xyz.myjfrog.com)</span></li><li><strong>Token</strong>:
    Artifactory personal access token. You can find <a href='https://www.jfrog.com/confluence/display/JFROG/Access+Tokens'
    target='_blank'>here</a> how to generate personal access tokens. <span class='autolinebreak'>(Example:
    ZlQDAwMFwvdXNlcnNcL21hZGh1a2FyIiwic2NwIjoiYXBwbGllZC1wZXJtaXNzaW9uc1wvYWRtaW4gYXBpOioiLCJhdWQiOlsiamZydEAqIiwiamZhY0AqIiwiamZldnmbWRAKiJdLCJpc3MiOiJqZmZlQDAAzNzY3MiwiaWF0IjoxNjI5ODY0ODcyLCJqdGkiOiI1ZWFiNjlhYi1hZDY0LTRjOGItOTMyZC0wMDAxMWZiZWU5YWIifQ.tzBgL3fQgZ1dwlLLS2UAT7G)</span></li><li><strong>Connect
    to Spinnaker</strong>: Toggle to configure Spinnaker for Artifactory</li><li><strong>Permissions</strong>:
    Enable/disable access to the Artifactory account in Autopilot to specific usergroups</li></ul></span>\",\n
    \        \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User defined name for the
    Artifactory account\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"ENDPOINT\":{\n            \"TOOLTIP\":\"Artifactory
    URL\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Endpoint
    cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n
    \        },\n         \"TOKEN\":{\n            \"TOOLTIP\":\"Artifactory Personal
    Access Token\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token
    cannot be empty\"\n            }\n         },\n         \"SPINNAKERTOGGLE\":{\n
    \           \"TOOLTIP\":\"\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         }\n      },\n      \"BITBUCKET\":{\n         \"HEADER\":\"Bitbucket
    Cloud\",\n         \"BODY\":\"<span><p>BitBucket Cloud integration can be used as
    a datasource for Approval Gate as well as to configure Spinnaker for BitBucket Cloud.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Name</strong>: User defined name for the Bitbucket
    Cloud Account <span class='noBr'>(Example: opsmx-bitbucket)</span></li><li><strong>Host
    URL</strong>: BitBucket Cloud URL <span class='noBr'>(Example: https://bitbucket.org)</span></li><li><strong>API
    URL</strong>: This is needed by Autopilot to access Bitbucket Cloud resources such
    as accounts & repositories through API calls <span class='noBr'>(Example: https://api.bitbucket.org/2.0/repositories)</span></li><li><strong>Authentication
    Type</strong>: can be Token or User Name/Password</li><li><strong>User Name</strong>:
    Bitbucket Cloud User Name</li><li><strong>Token</strong>: BitBucket personal access
    token <span class='noBr'>(Example: xCPkVZfxaE9iULmfYYkK)</span></li> <li><strong>Password</strong>:
    Bitbucket Cloud Password</li><li><strong>Connect to Spinnaker</strong>: Toggle to
    configure Spinnaker for Bitbucket Cloud</li><li><strong>Permissions</strong>: Enable/disable
    access to the Bitbucket Account in Autopilot to specific usergroups</li></ul></span>\",\n
    \        \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User defined name for the
    BitBucket Cloud account\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"HOSTURL\":{\n            \"TOOLTIP\":\"BitBucket
    Cloud URL\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Host
    URL cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n
    \        },\n         \"APIURL\":{\n            \"TOOLTIP\":\"BitBucket Cloud Api
    URL. This is needed by Autopilot to access Bitbucket Cloud resources such as accounts
    & repositories through API calls\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"API
    URL cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n
    \        },\n         \"AUTHENTICATIONTYPE\":{\n            \"TOOLTIP\":\"can be
    Token or User Name/Password\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         },\n         \"TOKEN\":{\n            \"TOOLTIP\":\"BitBucket
    Cloud personal access token\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token
    cannot be empty\"\n            }\n         },\n         \"USERNAME\":{\n            \"TOOLTIP\":\"BitBucket
    Cloud User Name\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"User
    Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":\"User
    Name cannot contain space\",\n               \"required\":\"User Name cannot be
    empty\",\n               \"startingFromNumber\":\"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"PASSWORD\":{\n            \"TOOLTIP\":\"BitBucket
    Cloud Password\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Password
    cannot be empty\"\n            }\n         },\n         \"SPINNAKERTOGGLE\":{\n
    \           \"TOOLTIP\":\"\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         }\n      },\n      \"BITBUCKET_SERVER\":{\n         \"HEADER\":\"Bitbucket
    Server\",\n         \"BODY\":\"<span><p>BitBucket Server integration can be used
    as a datasource for Approval Gate as well as to configure Spinnaker for BitBucket
    Server.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User defined name for the Bitbucket Server Account <span class='noBr'>(Example:
    opsmx-bitbucket)</span></li><li><strong>Host URL</strong>: BitBucket Server URL
    <span class='noBr'>(Example: https://xyz.mybitbucket.com)</span></li><li><strong>Authentication
    Type</strong>: can be Token or User Name/Password</li><li><strong>User Name</strong>:
    Bitbucket Server User Name</li><li><strong>Token</strong>: BitBucket Server personal
    access token. You can find <a href='https://confluence.atlassian.com/bitbucketserver/personal-access-tokens-939515499.html'
    target='_blank'>here</a> how to generate personal access tokens. <span class='noBr'>(Example:
    DjpMgHmwqUnIvvmljFgqGQ)</span></li><li><strong>Password</strong>: Bitbucket Server
    Password</li><li><strong>Connect to Spinnaker</strong>: Toggle to configure Spinnaker
    for Bitbucket Server</li><li><strong>Permissions</strong>: Enable/disable access
    to the Bitbucket Server account in Autopilot to specific usergroups</li></ul></span>\",\n
    \        \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User defined name for the
    Bitbucket Server account\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"HOSTURL\":{\n            \"TOOLTIP\":\"BitBucket
    Server URL\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Host
    URL cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n
    \        },\n         \"AUTHENTICATIONTYPE\":{\n            \"TOOLTIP\":\"can be
    Token or User Name/Password\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         },\n         \"TOKEN\":{\n            \"TOOLTIP\":\"Bitbucket
    Server personal access token\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token
    cannot be empty\"\n            }\n         },\n         \"USERNAME\":{\n            \"TOOLTIP\":\"Bitbucket
    Server User Name\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"User
    Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":\"User
    Name cannot contain space\",\n               \"required\":\"User Name cannot be
    empty\",\n               \"startingFromNumber\":\"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"PASSWORD\":{\n            \"TOOLTIP\":\"Bitbucket
    Server Password\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Password
    cannot be empty\"\n            }\n         },\n         \"SPINNAKERTOGGLE\":{\n
    \           \"TOOLTIP\":\"\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         }\n      },\n      \"DOCKERHUB\":{\n         \"HEADER\":\"Docker
    Registry\",\n         \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the Docker Registry account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"TOKEN\":{\n
    \           \"TOOLTIP\":\"Docker Registry Personal Access Token\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Token cannot be empty\"\n            }\n         },\n
    \        \"USERNAME\":{\n            \"TOOLTIP\":\"Docker Registry User Name\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"User
    Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":\"User
    Name cannot contain space\",\n               \"required\":\"User Name cannot be
    empty\",\n               \"startingFromNumber\":\"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"HOSTURL\":{\n            \"TOOLTIP\":\"Docker
    Registry Host URL\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Host
    URL cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n
    \        }\n      },\n      \"OCR\":{\n         \"HEADER\":\"Other Container Registry\",\n
    \        \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the Other Container Registry account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"TOKEN\":{\n
    \           \"TOOLTIP\":\"Container Registry Personal Access Token\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Token cannot be empty\"\n            }\n         },\n
    \        \"USERNAME\":{\n            \"TOOLTIP\":\"Container Registry User Name\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"User
    Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":\"User
    Name cannot contain space\",\n               \"required\":\"User Name cannot be
    empty\",\n               \"startingFromNumber\":\"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"HOSTURL\":{\n            \"TOOLTIP\":\"Container
    Registry Host URL\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Host
    URL cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n
    \        }\n      },\n      \"GITHUB\":{\n         \"HEADER\":\"GitHub\",\n         \"BODY\":\"<span><p>GIT
    HUB integration can be used as a datasource for Approval Gate as well as to configure
    Spinnaker for GitHub.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User defined name for the GitHub Account<span class='noBr'>(Example:
    opsmx-github)</span></li><li><strong>Token</strong>: GitHub personal access token.
    You can find <a href='https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token'
    target='_blank'>here</a> how to generate personal access tokens. <span class='noBr'>(Example:
    ghp_ln1eJK4yuomnY6JREp72IDJC4Hq6Sm)</span></li><li><strong>User Name</strong>: GitHub
    User Name</li><li><strong>Connect to Spinnaker</strong>: Toggle to configure Spinnaker
    for GitHub</li><li><strong>Permissions</strong>: Enable/disable access to the GIT
    HUB account in Autopilot to specific usergroups</li></ul></span>\",\n         \"ACCOUNTNAME\":{\n
    \           \"TOOLTIP\":\"User defined name for the GitHub account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"HOSTURL\":{\n
    \           \"TOOLTIP\":\"GitHub Host URL\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Host URL cannot be empty\",\n               \"invalidUrl\":\"URL
    is invalid\"\n            }\n         },\n         \"URL\":{\n            \"TOOLTIP\":\"GitHub
    Api URL to access resources such as accounts & repositories through API calls.\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \"required\":\"API URL cannot
    be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n         },\n
    \        \"TOKEN\":{\n            \"TOOLTIP\":\"GitHub Personal Access Token. You
    can generate token (settings -> Developer Settings -> Personal access tokens ->
    generate new Token)\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token
    cannot be empty\"\n            }\n         },\n         \"USERNAME\":{\n            \"TOOLTIP\":\"GitHub
    User Name\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"User
    Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":\"User
    Name cannot contain space\",\n               \"required\":\"User Name cannot be
    empty\",\n               \"startingFromNumber\":\"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"SPINNAKERTOGGLE\":{\n            \"TOOLTIP\":\"\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         }\n
    \     },\n      \"GITLAB\":{\n         \"HEADER\":\"GitLab\",\n         \"BODY\":\"\",\n
    \        \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User defined name for the
    GitLab account\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"HOSTURL\":{\n            \"TOOLTIP\":\"GitLab
    Host URL\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Host
    URL cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n
    \        },\n         \"APIBASEURL\":{\n            \"TOOLTIP\":\"\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"API URL cannot be empty\",\n               \"invalidUrl\":\"URL
    is invalid\"\n            }\n         },\n         \"TOKEN\":{\n            \"TOOLTIP\":\"\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token cannot
    be empty\"\n            }\n         },\n         \"SPINNAKERTOGGLE\":{\n            \"TOOLTIP\":\"Switch
    On this toggle to configure the resource in a gitops enabled Spinnaker instance\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         }\n
    \     },\n      \"GITREPO\":{\n         \"HEADER\":\"Git Repo\",\n         \"BODY\":\"\",\n
    \        \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"The name of the account to
    operate on\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"DEPLOYMENT\":{\n            \"TOOLTIP\":\"This
    Halyard deployment will be used for Account creation / update\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"URL cannot be empty\",\n               \"invalidUrl\":\"URL
    is invalid\"\n            }\n         },\n         \"AUTHENTICATIONTYPE\":{\n            \"TOOLTIP\":\"Select
    how the external resource confirms the user credentials\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"URL\":{\n            \"TOOLTIP\":\"\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \"required\":\"API URL cannot
    be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n         },\n
    \        \"TOKEN\":{\n            \"TOOLTIP\":\"Git token\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Token cannot be empty\"\n            }\n         },\n
    \        \"PASSWORD\":{\n            \"TOOLTIP\":\"Git password\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Password cannot be empty\"\n            }\n         },\n
    \        \"USERNAME\":{\n            \"TOOLTIP\":\"Git username\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"User Name cannot contain special characters
    other than - and _\",\n               \"cannotContainSpace\":\"User Name cannot
    contain space\",\n               \"required\":\"User Name cannot be empty\",\n               \"startingFromNumber\":\"User
    Name cannot start with numbers\"\n            }\n         },\n         \"SPINNAKERTOGGLE\":{\n
    \           \"TOOLTIP\":\"Switch On this toggle to configure the resource in a gitops
    enabled Spinnaker instance\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         }\n      },\n      \"HELM\":{\n         \"HEADER\":\"Helm\",\n
    \        \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"The
    name of the account to operate on\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"REPOSITORY\":{\n            \"TOOLTIP\":\"URL
    of the Helm Chart Repository\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"URL
    cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n
    \        },\n         \"DEPLOYMENT\":{\n            \"TOOLTIP\":\"This Halyard deployment
    will be used for Account creation / update\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"AUTHENTICATIONTYPE\":{\n
    \           \"TOOLTIP\":\"Select how the external resource confirms the user credentials\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"TOKEN\":{\n            \"TOOLTIP\":\"\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Token cannot be empty\"\n            }\n         },\n
    \        \"USERNAME\":{\n            \"TOOLTIP\":\"User Name\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"User Name cannot contain special characters
    other than - and _\",\n               \"cannotContainSpace\":\"User Name cannot
    contain space\",\n               \"required\":\"User Name cannot be empty\",\n               \"startingFromNumber\":\"User
    Name cannot start with numbers\"\n            }\n         },\n         \"PASSWORD\":{\n
    \           \"TOOLTIP\":\"Password\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         },\n         \"PASSWORDCOMMAND\":{\n            \"TOOLTIP\":\"Command
    to retrieve docker token/password, commands must be available in environment\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"FILE\":{\n            \"TOOLTIP\":\"The path to a file containing your
    docker password in plaintext (not a docker/config.json file)\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"SPINNAKERTOGGLE\":{\n            \"TOOLTIP\":\"Switch
    On this toggle to configure the resource in a gitops enabled Spinnaker instance\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         }\n
    \     },\n      \"HTTP\":{\n         \"HEADER\":\"Http\",\n         \"BODY\":\"\",\n
    \        \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"The name of the account to
    operate on\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"AUTHENTICATIONTYPE\":{\n            \"TOOLTIP\":\"Select
    how the external resource confirms the user credentials\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"TOKEN\":{\n            \"TOOLTIP\":\"\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token cannot
    be empty\"\n            }\n         },\n         \"USERNAME\":{\n            \"TOOLTIP\":\"User
    Name\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"User
    Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":\"User
    Name cannot contain space\",\n               \"required\":\"User Name cannot be
    empty\",\n               \"startingFromNumber\":\"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"PASSWORD\":{\n            \"TOOLTIP\":\"Password\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"PASSWORDCOMMAND\":{\n            \"TOOLTIP\":\"Command to retrieve docker
    token/password, commands must be available in environment\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"FILE\":{\n            \"TOOLTIP\":\"The
    path to a file containing your docker password in plaintext (not a docker/config.json
    file)\",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        },\n         \"SPINNAKERTOGGLE\":{\n            \"TOOLTIP\":\"Switch On
    this toggle to configure the resource in a gitops enabled Spinnaker instance\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         }\n
    \     },\n      \"GCS\":{\n         \"HEADER\":\"GCS\",\n         \"BODY\":\"\",\n
    \        \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"The name of the account to
    operate on\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"AUTHENTICATIONTYPE\":{\n            \"TOOLTIP\":\"Select
    how the external resource confirms the user credentials\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"FILE\":{\n            \"TOOLTIP\":\"JSON
    service account that Spinnaker will use as credentials\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"SPINNAKERTOGGLE\":{\n            \"TOOLTIP\":\"Switch
    On this toggle to configure the resource in a gitops enabled Spinnaker instance\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         }\n
    \     },\n      \"ECR\":{\n         \"HEADER\":\"ECR\",\n         \"BODY\":\"\",\n
    \        \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"The name of the account to
    operate on\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"REPOSITORIES\":{\n            \"TOOLTIP\":\"An
    optional list of repositories to cache images from\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"cannotContainSpace\":\"Repository cannot contain space\",\n               \"startingFromNumber\":\"Repository
    cannot start with numbers\"\n            }\n         },\n         \"REGISTRYURL\":{\n
    \           \"TOOLTIP\":\"The registry address you want to pull and deploy images
    from. For example: gcr.io\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         },\n         \"GROUPMEMBERSHIP\":{\n            \"TOOLTIP\":\"A
    user must be a member of at least one specified group in order to make changes to
    this accounts cloud resources\",\n            \"VALIDATION_MESSAGE\":{\n               \"cannotContainSpace\":\"Repository
    cannot contain space\"\n            }\n         },\n         \"REGION\":{\n            \"TOOLTIP\":\"AWS
    region\"\n         },\n         \"EMAIL\":{\n            \"TOOLTIP\":\"Your docker
    registry email\",\n            \"VALIDATION_MESSAGE\":{\n               \"email\":\"Email
    Id is invalid\",\n               \"required\":\"Email Id cannot be empty\"\n            }\n
    \        },\n         \"AUTHENTICATIONTYPE\":{\n            \"TOOLTIP\":\"Select
    how the external resource confirms the user credentials\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"TOKEN\":{\n            \"TOOLTIP\":\"\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token cannot
    be empty\"\n            }\n         },\n         \"USERNAME\":{\n            \"TOOLTIP\":\"GCR
    User Name\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"User
    Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":\"User
    Name cannot contain space\",\n               \"required\":\"User Name cannot be
    empty\",\n               \"startingFromNumber\":\"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"PASSWORD\":{\n            \"TOOLTIP\":\"Your
    docker registry password\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         },\n         \"PASSWORDCOMMAND\":{\n            \"TOOLTIP\":\"Command
    to retrieve docker token/password, commands must be available in environment\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"FILE\":{\n            \"TOOLTIP\":\"The path to a file containing your
    docker password in plaintext (not a docker/config.json file)\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"SPINNAKERTOGGLE\":{\n            \"TOOLTIP\":\"Switch
    On this toggle to configure the resource in a gitops enabled Spinnaker instance\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         }\n
    \     },\n      \"PUBSUB\":{\n         \"HEADER\":\"PUBSUB\",\n         \"BODY\":\"\",\n
    \        \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"The name of the account to
    operate on\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"PROJECTNAME\":{\n            \"TOOLTIP\":\"The
    name of the GCP project your subscription lives in\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"cannotContainSpace\":\"Project Name cannot contain space\",\n               \"required\":\"Project
    Name cannot be empty\"\n            }\n         },\n         \"SUBSCRIPTIONNAME\":{\n
    \           \"TOOLTIP\":\"The name of the subscription to listen to. This identifier
    does not include the name of the project, and must already be configured for Spinnaker
    to work.\",\n            \"VALIDATION_MESSAGE\":{\n               \"cannotContainSpace\":\"Subscription
    Name cannot contain space\",\n               \"required\":\"Subscription Name cannot
    be empty\"\n            }\n         },\n         \"MESSAGEFORMAT\":{\n            \"TOOLTIP\":\"Supporting
    Message Formats: GCB,GCS,GCR,CUSTOM\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         },\n         \"TEMPLATEFILE\":{\n            \"TOOLTIP\":\"Applicable
    only for CUSTOM message format\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         },\n         \"AUTHENTICATIONTYPE\":{\n            \"TOOLTIP\":\"Select
    how the external resource confirms the user credentials\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"FILE\":{\n            \"TOOLTIP\":\"JSON
    service account that Spinnaker will use as credentials\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"SPINNAKERTOGGLE\":{\n            \"TOOLTIP\":\"Switch
    On this toggle to configure the resource in a gitops enabled Spinnaker instance\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         }\n
    \     },\n      \"GCB\":{\n         \"HEADER\":\"GCB\",\n         \"BODY\":\"\",\n
    \        \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"The name of the account to
    operate on\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"PROJECTNAME\":{\n            \"TOOLTIP\":\"The
    name of the GCP project in which to trigger and monitor builds\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"cannotContainSpace\":\"Project Name cannot contain space\",\n               \"required\":\"Project
    Name cannot be empty\"\n            }\n         },\n         \"SUBSCRIPTIONNAME\":{\n
    \           \"TOOLTIP\":\"The name of the PubSub subscription on which to listen
    for build changes\",\n            \"VALIDATION_MESSAGE\":{\n               \"cannotContainSpace\":\"Subscription
    Name cannot contain space\",\n               \"required\":\"Subscription Name cannot
    be empty\"\n            }\n         },\n         \"AUTHENTICATIONTYPE\":{\n            \"TOOLTIP\":\"Select
    how the external resource confirms the user credentials\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"FILE\":{\n            \"TOOLTIP\":\"JSON
    service account that Spinnaker will use as credentials\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"USERNAME\":{\n            \"TOOLTIP\":\"GCB
    User Name\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"User
    Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":\"User
    Name cannot contain space\",\n               \"required\":\"User Name cannot be
    empty\",\n               \"startingFromNumber\":\"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"PASSWORD\":{\n            \"TOOLTIP\":\"Password\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"SPINNAKERTOGGLE\":{\n            \"TOOLTIP\":\"Switch On this toggle
    to configure the resource in a gitops enabled Spinnaker instance\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         }\n      },\n      \"GCR\":{\n         \"HEADER\":\"GCR\",\n
    \        \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"The
    name of the account to operate on\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"AUTHENTICATIONTYPE\":{\n            \"TOOLTIP\":\"Select
    how the external resource confirms the user credentials\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"REPOSITORIES\":{\n            \"TOOLTIP\":\"An
    optional list of repositories to cache images from\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"cannotContainSpace\":\"Repository cannot contain space\",\n               \"startingFromNumber\":\"Repository
    cannot start with numbers\"\n            }\n         },\n         \"REGISTRYURL\":{\n
    \           \"TOOLTIP\":\"The registry address you want to pull and deploy images
    from. For example: gcr.io\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         },\n         \"REQUIREDGROUPMEMBERSHIP\":{\n            \"TOOLTIP\":\"A
    user must be a member of at least one specified group in order to make changes to
    this accounts cloud resources\",\n            \"VALIDATION_MESSAGE\":{\n               \"cannotContainSpace\":\"Repository
    cannot contain space\"\n            }\n         },\n         \"EMAIL\":{\n            \"TOOLTIP\":\"Your
    docker registry email\",\n            \"VALIDATION_MESSAGE\":{\n               \"email\":\"Email
    Id is invalid\",\n               \"required\":\"Email Id cannot be empty\"\n            }\n
    \        },\n         \"URL\":{\n            \"TOOLTIP\":\"\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"API URL cannot be empty\",\n               \"invalidUrl\":\"URL
    is invalid\"\n            }\n         },\n         \"TOKEN\":{\n            \"TOOLTIP\":\"\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token cannot
    be empty\"\n            }\n         },\n         \"USERNAME\":{\n            \"TOOLTIP\":\"GCR
    User Name\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"User
    Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":\"User
    Name cannot contain space\",\n               \"required\":\"User Name cannot be
    empty\",\n               \"startingFromNumber\":\"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"PASSWORD\":{\n            \"TOOLTIP\":\"Your
    docker registry password\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         },\n         \"PASSWORDCOMMAND\":{\n            \"TOOLTIP\":\"Command
    to retrieve docker token/password, commands must be available in environment\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"FILE\":{\n            \"TOOLTIP\":\"The path to a file containing your
    docker password in plaintext (not a docker/config.json file)\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"SPINNAKERTOGGLE\":{\n            \"TOOLTIP\":\"Switch
    On this toggle to configure the resource in a gitops enabled Spinnaker instance\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         }\n
    \     },\n      \"BAMBOO\":{\n         \"HEADER\":\"Bamboo CI\",\n         \"BODY\":\"
    <span><p>Bamboo CI integration can be used as a datasource for Approval Gate.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'> <li><strong>Name</strong>: User defined name for the Bamboo
    CI Account <span class='noBr'>(Example: opsmx-bamboo)</span></li><li><strong>Endpoint</strong>:
    Bamboo CI URL <span class='noBr'>(Example: https://xyz.mybamboo.com)</span></li><li><strong>Token</strong>:
    Bamboo CI personal access token. You can find <a href='https://confluence.atlassian.com/bamboo/personal-access-tokens-976779873.html'
    target='_blank'>here</a> how to generate personal access tokens. <span>(Example:
    YmFrwqw0w9r90skfsOk9wcdd014p98kklw==)</span></li><li><strong>User Name</strong>:
    Bamboo CI User Name</li><li><strong>Password</strong>: Bamboo CI Password</li><li><strong>Permissions</strong>:
    Enable/disable access to the Bamboo CI account in Autopilot to specific usergroups</li></ul></span>\",\n
    \        \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User defined name for the
    Bamboo CI account\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"ENDPOINT\":{\n            \"TOOLTIP\":\"Bamboo
    CI URL\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Bamboo
    End Point cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n
    \           }\n         },\n         \"AUTHENTICATIONTYPE\":{\n            \"TOOLTIP\":\"can
    be Token or User Name/Password\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         },\n         \"TOKEN\":{\n            \"TOOLTIP\":\"Bamboo
    CI personal access token\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token
    cannot be empty\"\n            }\n         },\n         \"USERNAME\":{\n            \"TOOLTIP\":\"Bamboo
    CI User Name\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"User
    Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":\"User
    Name cannot contain space\",\n               \"required\":\"User Name cannot be
    empty\",\n               \"startingFromNumber\":\"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"PASSWORD\":{\n            \"TOOLTIP\":\"Bamboo
    CI Password\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Password
    cannot be empty\"\n            }\n         }\n      },\n      \"JENKINS\":{\n         \"HEADER\":\"Jenkins\",\n
    \        \"BODY\":\"<span><p>Jenkins integration can be used as a datasource for
    Approval Gate as well as to configure Spinnaker for Jenkins.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Account Name</strong>: User defined name for the
    Jenkins Account <span class='noBr'>(Example: opsmx-jenkins)</span></li><li><strong>Host
    URL</strong>: Jenkins URL <span class='noBr'>(Example: https://xyz.my-jenkins.com/jenkins)</span></li><li><strong>Authentication
    Type</strong>: can be Token or User Name/Password    </li><li><strong>Token</strong>:
    Jenkins personal access token. You can find <a href='https://www.jenkins.io/doc/book/using/using-credentials/'
    target='_blank'>here</a> how to generate personal access tokens. <span>(Example:
    77d67609a841b1811a114b7fbfa109b3c2)</span></li><li><strong>User Name</strong>: Jenkins
    User Name</li><li><strong>Password</strong>: Jenkins Password</li><li><strong>Connect
    to Spinnaker</strong>: Toggle to configure Spinnaker for Jenkins</li><li><strong>Permissions</strong>:
    Enable/disable access to the Jenkins account in Autopilot to specific usergroups</li></ul></span>\",\n
    \        \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User defined name for the
    Jenkins account\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"HOSTURL\":{\n            \"TOOLTIP\":\"Jenkins
    URL\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Host
    URL cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n
    \        },\n         \"AUTHENTICATIONTYPE\":{\n            \"TOOLTIP\":\"can be
    Token or User Name/Password\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         },\n         \"TOKEN\":{\n            \"TOOLTIP\":\"Jenkins
    personal access token\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token
    cannot be empty\"\n            }\n         },\n         \"USERNAME\":{\n            \"TOOLTIP\":\"Jenkins
    User Name\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"User
    Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":\"User
    Name cannot contain space\",\n               \"required\":\"User Name cannot be
    empty\",\n               \"startingFromNumber\":\"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"PASSWORD\":{\n            \"TOOLTIP\":\"Jenkins
    Password\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Password
    cannot be empty\"\n            }\n         },\n         \"SPINNAKERTOGGLE\":{\n
    \           \"TOOLTIP\":\"\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         }\n      },\n      \"JIRA\":{\n         \"HEADER\":\"Jira\",\n
    \        \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the Jira account\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"EMAIL\":{\n            \"TOOLTIP\":\"Jira
    Email Id\",\n            \"VALIDATION_MESSAGE\":{\n               \"email\":\"Email
    Id is invalid\",\n               \"required\":\"Email Id cannot be empty\"\n            }\n
    \        },\n         \"TOKEN\":{\n            \"TOOLTIP\":\"Jira Personal Access
    Token\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token
    cannot be empty\"\n            }\n         },\n         \"HOSTURL\":{\n            \"TOOLTIP\":\"Jira
    Host URL\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Host
    URL cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n
    \        },\n         \"SPINNAKERTOGGLE\":{\n            \"TOOLTIP\":\"\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         }\n      },\n      \"SERVICENOW\":{\n         \"HEADER\":\"Service
    Now\",\n         \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the Service Now account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"USERNAME\":{\n
    \           \"TOOLTIP\":\"Service Now User Name\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"User Name cannot contain special characters
    other than - and _\",\n               \"cannotContainSpace\":\"User Name cannot
    contain space\",\n               \"required\":\"User Name cannot be empty\",\n               \"startingFromNumber\":\"User
    Name cannot start with numbers\"\n            }\n         },\n         \"PASSWORD\":{\n
    \           \"TOOLTIP\":\"Service Now Password\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Password cannot be empty\"\n            }\n         },\n
    \        \"HOSTURL\":{\n            \"TOOLTIP\":\"Service Now Host URL\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Host URL cannot be empty\",\n               \"invalidUrl\":\"URL
    is invalid\"\n            }\n         }\n      },\n      \"APPDYNAMICS\":{\n         \"HEADER\":\"APPDYNAMICS\",\n
    \        \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the APPDYNAMICS account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"CONTROLLERHOST\":{\n
    \           \"TOOLTIP\":\"APPDYNAMICS Controller Host\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Controller Host  cannot be empty\",\n               \"invalidUrl\":\"URL
    is invalid\"\n            }\n         },\n         \"TEMPORARYACCESSTOKEN\":{\n
    \           \"TOOLTIP\":\"APPDYNAMICS Personal Temporary Access Token\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Temporary Access Token cannot be empty\"\n            }\n
    \        }\n      },\n      \"CLOUDWATCH\":{\n         \"HEADER\":\"AWS-CLOUDWATCH\",\n
    \        \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the AWS-CLOUDWATCH account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"ACCESS_ID\":{\n
    \           \"TOOLTIP\":\"AWS-CLOUDWATCH Access Key Id\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Access Key Id cannot be empty\"\n            }\n         },\n
    \        \"SECRET_KEY\":{\n            \"TOOLTIP\":\"AWS-CLOUDWATCH Secret Access
    Key\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Secret
    Access Key cannot be empty\"\n            }\n         }\n      },\n      \"DATADOG\":{\n
    \        \"HEADER\":\"DATADOG\",\n         \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n
    \           \"TOOLTIP\":\"User defined name for the DATADOG account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"API_KEY\":{\n
    \           \"TOOLTIP\":\"DATADOG Api Key\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Application Key cannot be empty\"\n            }\n
    \        },\n         \"APPLICATION_KEY\":{\n            \"TOOLTIP\":\"DATADOG Application
    Key\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Application
    Key cannot be empty\"\n            }\n         }\n      },\n      \"DYNATRACE\":{\n
    \        \"HEADER\":\"Dynatrace\",\n         \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n
    \           \"TOOLTIP\":\"User defined name for the Dynatrace account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"END_POINT\":{\n
    \           \"TOOLTIP\":\"Dynatrace URL\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Url cannot be empty\",\n               \"invalidUrl\":\"URL
    is invalid\"\n            }\n         },\n         \"API_TOKEN\":{\n            \"TOOLTIP\":\"Dynatrace
    Personal Access Token\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Api
    Token cannot be empty\"\n            }\n         }\n      },\n      \"ELASTICSEARCH\":{\n
    \        \"HEADER\":\"Elasticsearch\",\n         \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n
    \           \"TOOLTIP\":\"User defined name for the Elasticsearch account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"ENDPOINT\":{\n
    \           \"TOOLTIP\":\"ElasticSearch End Point\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Elastic End Point cannot be empty\",\n               \"invalidUrl\":\"URL
    is invalid\"\n            }\n         },\n         \"USERNAME\":{\n            \"TOOLTIP\":\"ElasticSearch
    User Name\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"User
    Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":\"User
    Name cannot contain space\",\n               \"startingFromNumber\":\"User Name
    cannot start with numbers\"\n            }\n         },\n         \"PASSWORD\":{\n
    \           \"TOOLTIP\":\"ElasticSearch Password\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Password cannot be empty\"\n            }\n         },\n
    \        \"KIBANAENDPOINT\":{\n            \"TOOLTIP\":\"ElasticSearch Kibana End
    Point\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Kibana
    End Point cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n
    \           }\n         },\n         \"KIBANAUSERNAME\":{\n            \"TOOLTIP\":\"ElasticSearch
    Kibana User Name\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Kibana
    User Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":\"Kibana
    User Name cannot contain space\",\n               \"required\":\"Kibana User Name
    cannot be empty\",\n               \"startingFromNumber\":\"Kibana User Name cannot
    start with numbers\"\n            }\n         },\n         \"KIBANAPASSWORD\":{\n
    \           \"TOOLTIP\":\"ElasticSearch Kibana Password\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Kibana Password cannot be empty\"\n            }\n
    \        }\n      },\n      \"GRAPHITE\":{\n         \"HEADER\":\"Graphite\",\n
    \        \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the Graphite account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"URL\":{\n
    \           \"TOOLTIP\":\"Graphite End Point\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"End Point cannot be empty\",\n               \"invalidUrl\":\"URL
    is invalid\"\n            }\n         }\n      },\n      \"GRAYLOG\":{\n         \"HEADER\":\"GRAYLOG\",\n
    \        \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the GRAYLOG account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"ENDPOINT\":{\n
    \           \"TOOLTIP\":\"GrayLog End Point\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"End Point cannot be empty\",\n               \"invalidUrl\":\"URL
    is invalid\"\n            }\n         },\n         \"TOKEN\":{\n            \"TOOLTIP\":\"GrayLog
    Personal Access Token\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token
    cannot be empty\"\n            }\n         }\n      },\n      \"NEWRELIC\":{\n         \"HEADER\":\"New
    Relic\",\n         \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the New Relic account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"APIKEY\":{\n
    \           \"TOOLTIP\":\"NewRelic Api Key\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Token cannot be empty\"\n            }\n         },\n
    \        \"APPLICATIONKEY\":{\n            \"TOOLTIP\":\"NewRelic Application Key\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token cannot
    be empty\"\n            }\n         },\n         \"ACCOUNTID\":{\n            \"TOOLTIP\":\"NewRelic
    Account Id\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token
    cannot be empty\"\n            }\n         },\n         \"QUERYKEY\":{\n            \"TOOLTIP\":\"NewRelic
    Query Key\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token
    cannot be empty\"\n            }\n         }\n      },\n      \"PROMETHEUS\":{\n
    \        \"HEADER\":\"Prometheus\",\n         \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n
    \           \"TOOLTIP\":\"User defined name for the Prometheus account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"ENDPOINT\":{\n
    \           \"TOOLTIP\":\"Prometheus End Point\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"End Point cannot be empty\",\n               \"invalidUrl\":\"URL
    is invalid\"\n            }\n         },\n         \"USERNAME\":{\n            \"TOOLTIP\":\"Prometheus
    User Name\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"User
    Name cannot contain special characters other than - and _\",\n               \"cannotContainSpace\":\"User
    Name cannot contain space\",\n               \"required\":\"User Name cannot be
    empty\",\n               \"startingFromNumber\":\"User Name cannot start with numbers\"\n
    \           }\n         },\n         \"PASSWORD\":{\n            \"TOOLTIP\":\"Prometheus
    Password\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Password
    cannot be empty\"\n            }\n         }\n      },\n      \"SPLUNK\":{\n         \"HEADER\":\"Splunk\",\n
    \        \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the Splunk account\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"END_POINT\":{\n            \"TOOLTIP\":\"Splunk
    Splunk URL\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Splunk
    Url  cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n
    \        },\n         \"PASSWORD\":{\n            \"TOOLTIP\":\"Splunk Password\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \"required\":\"Password cannot
    be empty\"\n            }\n         },\n         \"USER_NAME\":{\n            \"TOOLTIP\":\"Splunk
    User Name\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"DASHBOARD_ENDPOINT\":{\n            \"TOOLTIP\":\"Splunk
    DashBoard URL\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Splunk
    DashBoard Url cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n
    \           }\n         }\n      },\n      \"STACKDRIVER\":{\n         \"HEADER\":\"Stackdriver\",\n
    \        \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the Stackdriver account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"KEY_FILE\":{\n
    \           \"TOOLTIP\":\"Stackdriver Encrypted Key file\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Encrypted Key File cannot be empty\"\n            }\n
    \        }\n      },\n      \"SUMOLOGIC\":{\n         \"HEADER\":\"Sumo Logic\",\n
    \        \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the Sumologic account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"ACCESSID\":{\n
    \           \"TOOLTIP\":\"sumologic Access Id. You can generate Access Id (Administration
    > Security > Access Keys)\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Access
    Id cannot be empty\"\n            }\n         },\n         \"ACCESSKEY\":{\n            \"TOOLTIP\":\"sumologic
    Access Key. You can generate Access Id (Administration > Security > Access Keys)\",\n
    \           \"VALIDATION_MEeSSAGE\":{\n               \"required\":\"Access Key
    cannot be empty\"\n            }\n         },\n         \"ZONE\":{\n            \"TOOLTIP\":\"sumologic
    Zone\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Zone
    cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Zone
    cannot contain space\",\n               \"required\":\"Zone cannot be empty\",\n
    \              \"startingFromNumber\":\"Zone cannot start with numbers\"\n            }\n
    \        }\n      },\n      \"VMWARETANZU\":{\n         \"HEADER\":\"VMWare Tanzu
    Observability\",\n         \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the VMWare Tanzu Observability account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"END_POINT\":{\n
    \           \"TOOLTIP\":\"VMWare Tanzu Observability URL\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Url cannot be empty\",\n               \"invalidUrl\":\"URL
    is invalid\"\n            }\n         },\n         \"EMAIL\":{\n            \"TOOLTIP\":\"VMWare
    Tanzu Observability Email Id\",\n            \"VALIDATION_MESSAGE\":{\n               \"email\":\"Email
    Id is invalid\",\n               \"required\":\"Email Id cannot be empty\"\n            }\n
    \        },\n         \"API_TOKEN\":{\n            \"TOOLTIP\":\"VMWare Tanzu Observability
    Personal Access Token\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Api
    Token cannot be empty\"\n            }\n         }\n      },\n      \"MSTEAMS\":{\n
    \        \"HEADER\":\"Microsoft Teams\",\n         \"BODY\":\"\"\n      },\n      \"SLACK\":{\n
    \        \"HEADER\":\"Slack\",\n         \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n
    \           \"TOOLTIP\":\"User defined name for the Slack account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"BOTNAME\":{\n
    \           \"TOOLTIP\":\"Slack Bot Name\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Bot Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Bot Name cannot contain
    space\",\n               \"required\":\"Bot Name cannot be empty\",\n               \"startingFromNumber\":\"Bot
    Name cannot start with numbers\"\n            }\n         },\n         \"TOKEN\":{\n
    \           \"TOOLTIP\":\"Slack Personal Access Token\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Token cannot be empty\"\n            }\n         },\n
    \        \"SPINNAKERTOGGLE\":{\n            \"TOOLTIP\":\"\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         }\n      },\n      \"OPA\":{\n         \"HEADER\":\"OPA\",\n
    \        \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the OPA account\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"ENDPOINT\":{\n            \"TOOLTIP\":\"OPA
    End Point\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"End
    Point cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n
    \        }\n      },\n      \"AQUAWAVE\":{\n         \"HEADER\":\"Aqua Wave\",\n
    \        \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the Aqua Wave account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"USERNAME\":{\n
    \           \"TOOLTIP\":\"Aqua Wave User Name\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"User Name cannot contain special characters
    other than - and _\",\n               \"cannotContainSpace\":\"User Name cannot
    contain space\",\n               \"required\":\"User Name cannot be empty\",\n               \"startingFromNumber\":\"User
    Name cannot start with numbers\"\n            }\n         },\n         \"TOKEN\":{\n
    \           \"TOOLTIP\":\"Aqua Wave Personal Access Token\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Token cannot be empty\"\n            }\n         }\n
    \     },\n      \"APPSCAN\":{\n         \"HEADER\":\"HCL AppScan\",\n         \"BODY\":\"\",\n
    \        \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User defined name for the
    HCL AppScan account\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"TOKEN\":{\n            \"TOOLTIP\":\"Appscan
    Personal Access Token\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token
    cannot be empty\"\n            }\n         }\n      },\n      \"JFROG\":{\n         \"HEADER\":\"JFrog
    XRay Scanning\",\n         \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User
    defined name for the JFrog XRay Scanning account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"ENDPOINT\":{\n
    \           \"TOOLTIP\":\"JFrog URL\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Endpoint
    cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n
    \        },\n         \"TOKEN\":{\n            \"TOOLTIP\":\"JFrog Personal Access
    Token\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token
    cannot be empty\"\n            }\n         }\n      },\n      \"PRISMACLOUD\":{\n
    \        \"HEADER\":\"Prisma Cloud\",\n         \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n
    \           \"TOOLTIP\":\"User defined name for the Prisma Cloud account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"HOSTURL\":{\n
    \           \"TOOLTIP\":\"Prisma Cloud Host URL\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Host URL cannot be empty\",\n               \"invalidUrl\":\"URL
    is invalid\"\n            }\n         },\n         \"APPLICATIONURL\":{\n            \"TOOLTIP\":\"Prisma
    Cloud Application URL\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Application
    URL cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n
    \        },\n         \"ACCESSKEYID\":{\n            \"TOOLTIP\":\"Prisma Cloud
    Access Key Id\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Access
    Key Id cannot be empty\"\n            }\n         },\n         \"SECRETKEY\":{\n
    \           \"TOOLTIP\":\"Prisma Cloud Secret Key\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Secret Key cannot be empty\"\n            }\n         }\n
    \     },\n      \"SONARQUBE\":{\n         \"HEADER\":\"SonarQube\",\n         \"BODY\":\"\",\n
    \        \"ACCOUNTNAME\":{\n            \"TOOLTIP\":\"User defined name for the
    SonarQube account\",\n            \"VALIDATION_MESSAGE\":{\n               \"noSpecialCharacters\":\"Account
    Name cannot contain special characters other than -\",\n               \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n               \"required\":\"Account Name cannot
    be empty\",\n               \"startingFromNumber\":\"Account Name cannot start with
    numbers\"\n            }\n         },\n         \"HOSTURL\":{\n            \"TOOLTIP\":\"Sonarqube
    Host URL\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Host
    URL cannot be empty\",\n               \"invalidUrl\":\"URL is invalid\"\n            }\n
    \        },\n         \"TOKEN\":{\n            \"TOOLTIP\":\"Sonarqube Personal
    Access Token\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Token
    cannot be empty\"\n            }\n         }\n      },\n      \"AUTOPILOT\":{\n
    \        \"HEADER\":\"Autopilot\",\n         \"BODY\":\"\",\n         \"ACCOUNTNAME\":{\n
    \           \"TOOLTIP\":\"User defined name for the Autopilot account\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"Account Name cannot contain special characters
    other than -\",\n               \"cannotContainSpace\":\"Account Name cannot contain
    space\",\n               \"required\":\"Account Name cannot be empty\",\n               \"startingFromNumber\":\"Account
    Name cannot start with numbers\"\n            }\n         },\n         \"USERNAME\":{\n
    \           \"TOOLTIP\":\" Autopilot User Name\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"noSpecialCharacters\":\"User Name cannot contain special characters
    other than - and _\",\n               \"cannotContainSpace\":\"User Name cannot
    contain space\",\n               \"required\":\"User Name cannot be empty\",\n               \"startingFromNumber\":\"User
    Name cannot start with numbers\"\n            }\n         }\n      }\n   },\n   \"UNCHANGED_FORM\":\"Form
    is unchanged. Please make modifications in the form to enable the button.\",\n   \"INVALID_FORM\":\"Few
    fields are mandatory or invalid. Please fill the form to enable the button.\",\n
    \  \"NO_WRITE_ACCESS\":\"You have only read permission. Please check with your administrator
    for updating permissions.\",\n   \"METRIC_TEMPLATE\":{\n      \"APM_INFRA\":{\n
    \        \"TEMPLATE_NAME\":{\n            \"TOOLTIP\":\"The unique name of the template
    for identification\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Template
    Name cannot be empty\",\n               \"noSpecialCharacters\":\"Template Name
    cannot contain special characters\",\n               \"cannotContainSpace\":\"Template
    Name cannot contain space\",\n               \"startingFromNumber\":\"Template Name
    cannot start with number\",\n               \"maxlength\":\"Template name should
    not have more than 63 characters!\",\n               \"exists\":\"Template already
    exists\"\n            }\n         },\n         \"APM_MONITORING_PROVIDER\":{\n            \"TOOLTIP\":\"Select
    an APM datasource provider of choice\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"APM_ACCOUNT\":{\n            \"TOOLTIP\":\"Select
    the account of interest in the configured APM datasource \",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"APM_APPLICATION\":{\n            \"TOOLTIP\":\"Select
    the application of interest that you want to monitor\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"APM_API_SELECTION\":{\n
    \           \"TOOLTIP\":\"Select the relevant API metrics to monitor \",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"INFRA_MONITORING_PROVIDER\":{\n
    \           \"TOOLTIP\":\"Select an INFRA metrics datasource provider of choice\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"INFRA_ACCOUNT\":{\n            \"TOOLTIP\":\"Select the account of interest
    in the configured INFRA metrics datasource \",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"INFRA_METRIC_GROUPS\":{\n
    \           \"TOOLTIP\":\"Metrics groups organized as groups for quick overview
    on each infrastructure component\",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         },\n         \"FILTER_KEY\":{\n            \"TOOLTIP\":\"A
    metric scope placeholder to filter the scope of the metric\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Filter Key cannot be empty\",\n               \"cannotContainSpace\":\"Filter
    Key cannot contain space\"\n            }\n         },\n         \"BASELINE\":{\n
    \           \"TOOLTIP\":\"A unique metric scope to identify the baseline metric\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \"required\":\"Baseline cannot
    be empty\",\n               \"cannotContainSpace\":\"Baseline cannot contain space\"\n
    \           }\n         },\n         \"NEW_RELEASE\":{\n            \"TOOLTIP\":\"A
    unique metric scope to identify the canary metric\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"New Release cannot be empty\",\n               \"cannotContainSpace\":\"New
    Release cannot contain space\"\n            }\n         },\n         \"NORMALIZATION\":{\n
    \           \"TOOLTIP\":\"The selected Load metric will be dividing all the metrics
    to make the metrics more comparable to each other\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"THRESHOLD\":{\n            \"TOOLTIP\":\"Select
    'Hard' mode for a stringent analysis and 'Easy' mode for a more lenient analysis\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"SPECIFY_CRITICAL_WATCHLIST\":{\n            \"TOOLTIP\":\"Metrics marked
    as critical, will affect the overall canary analysis score if they fail Metrics
    marked as in watchlist will be shown first in the metric analysis report\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         }\n      },\n      \"CUSTOM\":{\n         \"TEMPLATE_NAME\":{\n
    \           \"TOOLTIP\":\"The unique name of the template for identification\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \"required\":\"Template Name
    cannot be empty\",\n               \"noSpecialCharacters\":\"Template Name cannot
    contain special characters\",\n               \"cannotContainSpace\":\"Template
    Name cannot contain space\",\n               \"startingFromNumber\":\"Template Name
    cannot start with number\",\n               \"maxlength\":\"Template name should
    not have more than 63 characters!\",\n               \"exists\":\"Template already
    exists\"\n            }\n         },\n         \"DATA_SOURCE\":{\n            \"TOOLTIP\":\"Select
    a datasource provider of choice\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Data
    source cannot be empty\"\n            }\n         },\n         \"ACCOUNT\":{\n            \"TOOLTIP\":\"Select
    the account of interest in the configured datasource \",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Account cannot be empty\"\n            }\n         },\n
    \        \"FILTER_KEY\":{\n            \"TOOLTIP\":\"Metric Scope Placeholder will
    be replaced by Baseline & New Release values in the Metric Query; For example, Scope
    Placeholder pod_name will be replaced by Baseline & New Release values in the
    metric query avg(container_memory_usage_bytes{pod=~'pod_name',container!=''}) for
    getting baseline & New Release metrics data respectively from the monitoring provider\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \"required\":\"Filter Key cannot
    be empty\",\n               \"cannotContainSpace\":\"Filter Key cannot contain space\"\n
    \           }\n         },\n         \"BASELINE\":{\n            \"TOOLTIP\":\"Unique
    metric scope to identify the baseline metric data\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Baseline cannot be empty\",\n               \"cannotContainSpace\":\"Baseline
    cannot contain space\"\n            }\n         },\n         \"NEW_RELEASE\":{\n
    \           \"TOOLTIP\":\"Unique metric scope to identify the canary metric data\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \"required\":\"New Release
    cannot be empty\",\n               \"cannotContainSpace\":\"New Release cannot contain
    space\"\n            }\n         },\n         \"ADD_NEW_QUERY\":{\n            \"TOOLTIP\":\"Add
    New Query\",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        },\n         \"QUERY_SELECTION\":{\n            \"TOOLTIP\":\"Select the
    relevant metrics to monitor \",\n            \"VALIDATION_MESSAGE\":{\n               \n
    \           }\n         },\n         \"QUERY_NAME\":{\n            \"TOOLTIP\":\"A
    meaningful name given to a query or a group of similar queries \",\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Query Name cannot be empty\"\n            }\n         },\n
    \        \"QUERY_STRING\":{\n            \"TOOLTIP\":\"Query to fetch the metric
    from the data source provider\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Query
    String cannot be empty\"\n            }\n         },\n         \"RISK_DIRECTION\":{\n
    \           \"TOOLTIP\":\"Direction in which the metric difference is allowed to
    expand\",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        },\n         \"THRESHOLD\":{\n            \"TOOLTIP\":\"Percentage difference
    beyond which the Metric is treated as FAIL\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"CRITICAL\":{\n            \"TOOLTIP\":\"Critical\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"WATCHLIST\":{\n            \"TOOLTIP\":\"Metrics marked as in watchlist
    will be shown first in the metric analysis report\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"WEIGHT\":{\n            \"TOOLTIP\":\"Numerical
    importance given to a metric; it can range from 0 as lowest to 1 as the highest\",\n
    \           \"VALIDATION_MESSAGE\":{\n               \n            }\n         },\n
    \        \"CRITICALITY\":{\n            \"TOOLTIP\":\"Normal is selected to remove
    the metric from the metric group for score calculation if it has no data, Critical
    is selected to fail the entire analysis if this metric fails or has no data, Must
    Have Data is used to fail a metric if data is missing\",\n            \"VALIDATION_MESSAGE\":{\n
    \              \n            }\n         },\n         \"NAN_STRATEGY\":{\n            \"TOOLTIP\":\"Handles
    NaN values which can occur if there is no data in a particular interval for metric
    data. \",\n            \"VALIDATION_MESSAGE\":{\n               \n            }\n
    \        }\n      }\n   },\n   \"USAGE_INSIGHTS\":{\n      \"APPLICATIONS\":{\n
    \        \"TOOLTIP\":\"Application\"\n      },\n      \"PIPELINES\":{\n         \"TOOLTIP\":\"Pipelines\"\n
    \     },\n      \"PIPELINES_WITH_INTELLIGENT_GATES\":{\n         \"TOOLTIP\":\"Pipelines
    with Intelligent Gates\"\n      },\n      \"INTELLIGENT_GATES_BREAKDOWN\":{\n         \"TOOLTIP\":\"Intelligent
    Gates Breakdown\"\n      },\n      \"GATES_USED\":{\n         \"TOOLTIP\":\"Gates
    Used\"\n      },\n      \"USERS\":{\n         \"TOOLTIP\":\"Users\"\n      }\n   },\n
    \  \"DELIVERY_INSIGHTS\":{\n      \"PIPELINES\":{\n         \"TOOLTIP\":\"Pipelines\"\n
    \     },\n      \"MOST_ACTIVE_PIPELINES\":{\n         \"TOOLTIP\":\"Most Active
    Pipelines\"\n      },\n      \"MOST_SUCCESSFUL_PIPELINES\":{\n         \"TOOLTIP\":\"Most
    Successful Pipelines\"\n      },\n      \"MOST_FAILED_PIPELINES\":{\n         \"TOOLTIP\":\"Most
    Failed Pipelines\"\n      },\n      \"FASTEST_PIPELINES\":{\n         \"TOOLTIP\":\"Fastest
    Pipelines \"\n      },\n      \"SLOWEST_PIPELINES\":{\n         \"TOOLTIP\":\"Slowest
    Pipelines \"\n      },\n      \"MANUAL_JUDGMENT\":{\n         \"TOOLTIP\":\"Manual
    Judgment\"\n      }\n   },\n   \"ACCESS_MANAGEMENT\":{\n      \"ADMINISTRATOR\":{\n
    \        \"INFO\":\"Super Administrator Groups will not appear in the dropdown since
    their Access Permissions cannot be modified.<br> Administrators will have full Access
    to all Resources.\",\n         \"TOOLTIP\":\"Groups with Administration Permissions\"\n
    \     },\n      \"USER_ROLE_LISTING\":{\n         \"HEADER\":\"ROLE MANAGEMENT\",\n
    \        \"BODY\":\"Users should be assigned user roles only if they need global
    access to one or more resources.\"\n      },\n      \"USER_ROLE_CREATION\":{\n         \"ROLENAME\":{\n
    \           \"TOOLTIP\":\"\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Role
    Name cannot be empty\"\n            }\n         },\n         \"USER_GROUPS\":{\n
    \           \"TOOLTIP\":\"\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Groups
    cannot be empty\"\n            }\n         },\n         \"PERMISSIONS\":{\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Atleast one feature has to be enabled with permissions\"\n
    \           }\n         }\n      },\n      \"FEATURE_VISIBILTY_LISTING\":{\n         \"HEADER\":\"FEATURE
    FLAG MANAGEMENT\",\n         \"BODY\":\"Feature Visibility is used for scenarios
    where one or more user groups need exclusive access to a specific feature. For example,
    the 'Compliance Team' should only access the Policy Management feature. Administrators
    can enable the feature flag for the compliance team user group. The feature visibility
    function will ensure that the policy management feature is not visible for all other
    user groups.\"\n      },\n      \"FEATURE_VISIBILTY_CREATION\":{\n         \"ROLENAME\":{\n
    \           \"TOOLTIP\":\"\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Role
    Name cannot be empty\"\n            }\n         },\n         \"USER_GROUPS\":{\n
    \           \"TOOLTIP\":\"\",\n            \"VALIDATION_MESSAGE\":{\n               \"required\":\"Groups
    cannot be empty\"\n            }\n         },\n         \"PERMISSIONS\":{\n            \"VALIDATION_MESSAGE\":{\n
    \              \"required\":\"Atleast one feature has to be enabled\"\n            }\n
    \        }\n      }\n   },\n   \"LOG_TEMPLATE\":{\n      \"STRING_PATTERN\":{\n
    \        \"TOOLTIP\":\"String Pattern\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"String
    Pattern cannot be empty\"\n         }\n      },\n      \"LOG_TOPICS\":{\n         \"TOOLTIP\":\"Strings
    that appear in logs with their characterization\"\n      },\n      \"LOG_TAGS\":{\n
    \        \"TOOLTIP\":\"Create custom tags based on business logic.\"\n      },\n
    \     \"CHARACTERIZATION_TOPIC\":{\n         \"TOOLTIP\":\"Characterization Topic\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"required\":\"Characterization Topic
    cannot be empty\"\n         }\n      },\n      \"TYPE\":{\n         \"TOOLTIP\":\"Type\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \n         }\n      },\n      \"ENABLE_CLUSTER_TAG\":{\n
    \        \"TOOLTIP\":\"Create custom tags based on business logic.\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \n         }\n      },\n      \"CLUSTER_TAG_STRING\":{\n         \"TOOLTIP\":\"The
    string pattern that appears in logs\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Cluster
    Tag String cannot be empty\"\n         }\n      },\n      \"CLUSTER_TAG\":{\n         \"TOOLTIP\":\"Cluster
    Tag\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Cluster Tag
    cannot be empty\"\n         }\n      },\n      \"LOG_TEMPLATE_NAME\":{\n         \"TOOLTIP\":\"Log
    Template Name\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Template
    Name cannot be empty\"\n         }\n      },\n      \"PROVIDER\":{\n         \"TOOLTIP\":\"Data
    source for Risk Analysis\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Provider
    cannot be empty\"\n         }\n      },\n      \"LOG_ACCOUNT\":{\n         \"TOOLTIP\":\"Account
    of the Log provider; Refer Integrations tab under Setup\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Log Account cannot be empty\"\n         }\n      },\n
    \     \"QUERY_FILTER_KEY\":{\n         \"TOOLTIP\":\"Unique Key which identify logs
    to be processed in the Index\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Query
    Filter Key cannot be empty\"\n         }\n      },\n      \"BASELINE\":{\n         \"TOOLTIP\":\"Unique
    value which identify baseline logs in the Index\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Baseline cannot be empty\"\n         }\n      },\n      \"NEW_RELEASE\":{\n
    \        \"TOOLTIP\":\"Unique value which identify New Release logs in the Index\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"required\":\"New Release cannot
    be empty\"\n         }\n      },\n      \"RESPONSE_KEYWORDS\":{\n         \"TOOLTIP\":\"Field
    name in the Index containing logs to be processed\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Response Keywords cannot be empty\"\n         }\n      },\n
    \     \"TIMESTAMP_KEY\":{\n         \"TOOLTIP\":\"Unique Key which identify the
    timestamp for log; this field is optional; by default, it is @timestamp for elasticsearch
    and timestamp for graylog\",\n         \"VALIDATION_MESSAGE\":{\n            \n
    \        }\n      },\n      \"AUTOBASELINE\":{\n         \"TOOLTIP\":\"ML based
    learning of the baseline from historic analysis\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \n         }\n      },\n      \"CONTEXTUAL_CLUSTER\":{\n         \"TOOLTIP\":\"Enable/disable
    cluster of unexpected events in similar context\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \n         }\n      },\n      \"CONTEXTUAL_WINDOW_SIZE\":{\n         \"TOOLTIP\":\"Number
    of Log events to be seen in a Context. Allowed size in between 25 and 50\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"max\":\"Allowed size is in between 25 to 50\",\n            \"min\":\"Allowed
    size is in between 25 to 50\"\n         }\n      },\n      \"INFO_CLUSTER_SCORING\":{\n
    \        \"TOOLTIP\":\"Enabling this option will include INFO clusters in scoring\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \n         }\n      },\n      \"SENSITIVITY\":{\n
    \        \"TOOLTIP\":\"Impact of Unexpected Issues on the log scoring\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Sensitivity cannot be empty\"\n         }\n      },\n
    \     \"SCORING_ALGORITHM\":{\n         \"TOOLTIP\":\"Scoring Algorithm for Risk
    Analysis\",\n         \"VALIDATION_MESSAGE\":{\n            \n         }\n      },\n
    \     \"LOG_GROUP\":{\n         \"TOOLTIP\":\"Group of log streams that share the
    same retention, monitoring, and access control settings\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Log Group cannot be empty\"\n         }\n      },\n      \"LOG_STREAM\":{\n
    \        \"TOOLTIP\":\"Sequence of log events that share the same source\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Log Stream cannot be empty\"\n         }\n      },\n
    \     \"REGION\":{\n         \"TOOLTIP\":\"Geographic area where AWS data center\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"required\":\"Region cannot be empty\"\n
    \        }\n      },\n      \"INDEX_PATTERN\":{\n         \"TOOLTIP\":\"Index containing
    logs for processing\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Intex
    Pattern cannot be empty\"\n         }\n      },\n      \"CUSTOM_REGEX\":{\n         \"TOOLTIP\":\"Custom
    Regular Expression to filter the logs\",\n         \"VALIDATION_MESSAGE\":{\n            \n
    \        }\n      },\n      \"REGULAR_EXPRESSION\":{\n         \"TOOLTIP\":\"Sequence
    of characters that specifies a search pattern\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \n         }\n      },\n      \"RESPONSE_KEY\":{\n         \"TOOLTIP\":\"Field
    name in the Index where regex to be searched\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \n         }\n      },\n      \"STREAM_ID\":{\n         \"TOOLTIP\":\"The
    streams are a mechanism to route messages into categories in realtime while they
    are processed\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Stream
    ID cannot be empty\"\n         }\n      },\n      \"NAMESPACE\":{\n         \"TOOLTIP\":\"Namespace\",\n
    \        \"VALIDATION_MESSAGE\":{\n            \"required\":\"Namespace cannot be
    empty\"\n         }\n      },\n      \"TEST_CASE_KEY\":{\n         \"TOOLTIP\":\"Field
    in the log index which holds the test case names\",\n         \"VALIDATION_MESSAGE\":{\n
    \           \"required\":\"Test Case Key cannot be empty\"\n         }\n      },\n
    \     \"TEST_SUITE_KEY\":{\n         \"TOOLTIP\":\"Field in the log index which
    \ holds the test suite names\",\n         \"VALIDATION_MESSAGE\":{\n            \"required\":\"Test
    Suite Key cannot be empty\"\n         }\n      }\n   }\n}\n"
kind: ConfigMap
metadata:
  name: oes-ui-config
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
---
# Source: oes/templates/configmaps/oes-ui-nginxconf.yaml
apiVersion: v1
data:
  nginx.conf: |
    # For more information on configuration, see:
    #   * Official English Documentation: http://nginx.org/en/docs/
    #   * Official Russian Documentation: http://nginx.org/ru/docs/
  
    user nginx;
    worker_processes auto;
    error_log /var/log/nginx/error.log debug;
    pid /tmp/nginx.pid;
  
    # Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.
    include /usr/share/nginx/modules/*.conf;
  
    events {
        worker_connections 1024;
    }
  
    http {
        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                          '$status $body_bytes_sent "$http_referer" '
                          '"$http_user_agent" "$http_x_forwarded_for"';
  
        access_log  /var/log/nginx/access.log  main;
  
        sendfile            on;
        tcp_nopush          on;
        tcp_nodelay         on;
        keepalive_timeout   65;
        types_hash_max_size 2048;
  
        include             /etc/nginx/mime.types;
        default_type        application/octet-stream;
  
        # Load modular configuration files from the /etc/nginx/conf.d directory.
        # See http://nginx.org/en/docs/ngx_core_module.html#include
        # for more information.
        include /etc/nginx/conf.d/*.conf;
  
        server {
            listen       8080 default_server;
            #listen       [::]:8080 default_server;
            server_name  _;
            root /var/www/html;
  
            # Load configuration files for the default server block.
            include /etc/nginx/default.d/*.conf;
  
            location ^~ /deck {
              proxy_pass http://spin-deck:9000/ ;
            }
  
            location ^~ /plugin-manifest.json {
              proxy_pass http://spin-deck:9000 ;
            }
  
            location ^~ /gate/ {
              proxy_pass http://oes-gate:8084/ ;
            }
  
            location ^~ /application {
              proxy_pass http://oes-ui:8080 ;
            }
  
            location ^~ /ui {
              try_files $uri $uri/ /ui/index.html;
            }
  
            # Go to Gate if you don't know what to do
            location / {
              proxy_pass http://oes-gate:8084/ ;
            }
  
  
        }
    }

kind: ConfigMap
metadata:
  name: oes-ui-nginxconf
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
---
# Source: oes/templates/configmaps/opa-persist.yaml
apiVersion: v1
data:
  opa-persist.sh: |
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    SAPOR=$(grep oes-sapor /tmp/inst.status | awk '{print $2}')
    PLATFORM=$(grep oes-platform /tmp/inst.status | awk '{print $2}')

    wait_period=$(($wait_period+10))

    if [ "$SAPOR" == "true" ] && [ "$PLATFORM" == "true" ];
    then
      echo \"Spinnaker and OES services are Up and Ready..\"
      set -x
      sleep 5
      BASEURL=$GATEURL
      USERPASS="-u ${GATEUSER}:${GATEPASS}"
      curl $USERPASS $BASEURL/oes/v1/policies/list > listofpolicies.json
      #Get the policy NAMES
      [ -s "listofpolicies.json" ] && (cat listofpolicies.json | jq .[] | jq -r .policyName > policies) || sleep infinity
      #for each NAME
      while read -e name; do
        #Get content
        curl $USERPASS $BASEURL/oes/v1/policy/$name > tmp.json

        #Get Policy ID
        ID=`cat tmp.json|jq .response | jq '.policyId'`
        #Delete Policy ID
        cat tmp.json|jq .response | jq 'del(.policyId)'  > update.json

        #update
        curl $USERPASS -X PUT -H "Content-Type: application/json" -d @update.json $BASEURL/oes/v1/policy/$ID
      done <  policies
      sleep infinity
      #endFOR
    else
      if [ $wait_period -gt 2000 ];
      then
          echo \"Script is timed out as the OES is not ready yet.......\"
          break
      else
          echo \"Waiting for OES services to be ready\"
          sleep 1m
      fi
    fi
    done
kind: ConfigMap
metadata:
  name: opa-persist
---
# Source: oes/templates/configmaps/standard-error-codes.yaml
apiVersion: v1
data:
  standard-error-codes.csv: |-
    standardErrorCodesMapping.ISD-IsEmpty-400-01 = ISD-IsEmpty-400-01 : {0} - {1} is empty. Please provide the {1}.
    standardErrorCodesMapping.ISD-IsNull-400-02 = ISD-IsNull-400-02 : {0} - {1} is null. Please provide the {1}.
    standardErrorCodesMapping.ISD-MustBeAlphanumericName-400-03 = ISD-MustBeAlphanumericName-400-03 : {0} - {1} should be alphanumeric without any special characters !
    standardErrorCodesMapping.ISD-ExceedsMaxStringLength-400-04 = ISD-ExceedsMaxStringLength-400-04 : {0} - {1} should not have more than {2} characters.
    standardErrorCodesMapping.ISD-NotConfigured-400-05 = ISD-NotConfigured-400-05 : {0} - {1} is not configured. Please configure the {1} !
    standardErrorCodesMapping.ISD-PolicyNotProvided-400-06 = ISD-PolicyNotProvided-400-06 : {0} - Policies are mandatory for automated approval gate.
    standardErrorCodesMapping.ISD-EmptyKeyOrValueInJson-400-07 = ISD-EmptyKeyOrValueInJson-400-07 : {0} - {1} is missing in json !
    standardErrorCodesMapping.ISD-UnableToParseJSON-400-08 = ISD-UnableToParseJSON-400-08 : {0} - Unable to parse Json. Please provide a valid json with required data !
    standardErrorCodesMapping.ISD-MustBeANumber-400-09 = ISD-MustBeANumber-400-09 : {0} - {1} must be a number : {2}
    standardErrorCodesMapping.ISD-Unauthorized-401-01 = ISD-Unauthorized-401-01 : {0} - {1} not authorized. {2}.
    standardErrorCodesMapping.ISD-Unauthorized-401-02 = ISD-Unauthorized-401-02 : {0} - User group not found for user : {1}.
    standardErrorCodesMapping.ISD-NotAdmin-401-03 = ISD-NotAdmin-401-03 : {0} - {1} is not an admin !
    standardErrorCodesMapping.ISD-Forbidden-403-01 = ISD-Forbidden-403-01 : {0} - {1} doesn't have {2} permission on this feature: {3}
    standardErrorCodesMapping.ISD-Forbidden-403-02 = ISD-Forbidden-403-02 : {0} - {1} is invalid.
    standardErrorCodesMapping.ISD-Forbidden-403-03 = ISD-Forbidden-403-03 : {0} - {1} : {2}.
    standardErrorCodesMapping.ISD-Forbidden-403-04 = ISD-Forbidden-403-04 : {0} - {1} namespace is not accessible for given kubeconfig account {2}.
    standardErrorCodesMapping.ISD-IsNotFound-404-01 = ISD-IsNotFound-404-01 : {0} - {1} not found : {2}
    standardErrorCodesMapping.ISD-NoData-404-02 = ISD-NoData-404-02 : {0} - No data found for {1}
    standardErrorCodesMapping.ISD-DoesNotExist-404-03 = ISD-DoesNotExist-404-03 : {0} - {1} does not exist {2}.
    standardErrorCodesMapping.ISD-IsNotFound-404-04 = ISD-IsNotFound-404-04 : {0} - {1} not found {2}.
    standardErrorCodesMapping.ISD-AlreadyExists-409-01 = ISD-AlreadyExists-409-01 : {0} - {1} already exists: {2}
    standardErrorCodesMapping.ISD-FailedToDelete-412-01 = ISD-FailedToDelete-412-01 : {0} - Unable to delete {1} as {1} is already in use !
    standardErrorCodesMapping.ISD-FailedToDeletePolicy-412-02 = ISD-FailedToDeletePolicy-412-02 : {0} - Unable to delete policy as it is already in use for {1} gate !
    standardErrorCodesMapping.ISD-FailedToUpdate-412-03 = ISD-FailedToUpdate-412-03 : {0} - Unable to update {1} as {1} is already in use !
    standardErrorCodesMapping.ISD-InvalidURL-422-01 = ISD-InvalidURL-422-01 : {0} - The requested {1} URL is invalid !
    standardErrorCodesMapping.ISD-ConnectionOrAuthenticationFailed-422-02 = ISD-ConnectionOrAuthenticationFailed-422-02 : {0} - {1} connection or authentication failed : HTTP status {2}
    standardErrorCodesMapping.ISD-InvalidCredentials-422-03 = ISD-InvalidCredentials-422-03 : {0} - {1} credentials are invalid !
    standardErrorCodesMapping.ISD-InvalidEndpoint-422-04 = ISD-InvalidEndpoint-422-04 : {0} - {1} endpoint is invalid !
    standardErrorCodesMapping.ISD-InvalidEndpointOrCredentials-422-05 = ISD-InvalidEndpointOrCredentials-422-05 : {0} - {1} endpoint or credentials are invalid !
    standardErrorCodesMapping.ISD-UsernameOrPasswordIsBlank-422-06 = ISD-UsernameOrPasswordIsBlank-422-06 : {0} - {1} is blank but {2} is supplied. Both must be present or blank.
    standardErrorCodesMapping.ISD-UnknownDatasource-422-07 = ISD-UnknownDatasource-422-07 : {0} - Unknown datasource or datasource is currently not supported : {1}
    standardErrorCodesMapping.ISD-InvalidProvider-422-08 = ISD-InvalidProvider-422-08 : {0} - {1} provider is invalid !
    standardErrorCodesMapping.ISD-InvalidPath-422-09 = ISD-InvalidPath-422-09 : {0} - {1} path is invalid !
    standardErrorCodesMapping.ISD-UnableToGenerate-422-10 = ISD-UnableToGenerate-422-10 : {0} - Unable to generate {1} !
    standardErrorCodesMapping.ISD-FailedToCreate-422-11 = ISD-FailedToCreate-422-11 : {0} - Failed to create {1}.
    standardErrorCodesMapping.ISD-EndpointIsBlank-422-12 = ISD-EndpointIsBlank-422-12 : {0} - {1} endpoint is blank. {2} must be blank.
    standardErrorCodesMapping.ISD-ConnectionOrAuthenticationFailed-422-13 = ISD-ConnectionOrAuthenticationFailed-422-13 : {0} - {1} connection or authentication failed.
    standardErrorCodesMapping.ISD-FailedToUpdate-422-14 = ISD-FailedToUpdate-422-14 : {0} - Failed to Update {1}.
    standardErrorCodesMapping.ISD-FailedToDelete-422-15 = ISD-FailedToDelete-422-15 : {0} - Failed to Delete {1}.
    standardErrorCodesMapping.ISD-DoesNotMatch-422-16 = ISD-DoesNotMatch-422-16 : {0} - {1} does not match {2}.
    standardErrorCodesMapping.ISD-DoesNotExist-422-17 =  ISD-DoesNotExist-422-17 : {0} - {1} does not exist {2}.
    standardErrorCodesMapping.ISD-DoesNotSupport-422-18 = ISD-DoesNotSupport-422-18 : {0} - {1} does not support {2}.
    standardErrorCodesMapping.ISD-UnableToVerify-422-19 = ISD-UnableToVerify-422-19 : {0} - Unable to verify {1}.
    standardErrorCodesMapping.ISD-FailedToInitialize-422-20 = ISD-FailedToInitialize-422-20 : {0} - Failed to initialize {1}.
    standardErrorCodesMapping.ISD-DoesNotHave-422-21 = ISD-DoesNotHave-422-21 : {0} - {1} does not have {2}.
    standardErrorCodesMapping.ISD-UnableToAddStage-424-01 = ISD-UnableToAddStage-424-01 : {0} - Unable to add stage in {1} !
    standardErrorCodesMapping.ISD-UnableToDelete-424-02 = ISD-UnableToDelete-424-02 : {0} - Unable to delete {1} while analysis is under process !
    standardErrorCodesMapping.ISD-UnableToDelete-424-03 = ISD-UnableToDelete-424-03 : {0} - Unable to delete {1} as already in use {2}
    standardErrorCodesMapping.ISD-UnableToDelete-424-04 = ISD-UnableToDelete-424-04 : {0} - Unable to delete {1} as it is involved in multi-service analysis !
    standardErrorCodesMapping.ISD-ShouldBeNumber-500-01 = ISD-ShouldBeNumber-500-01 : {0} - {1} should be an number !
    standardErrorCodesMapping.ISD-ShouldBePositiveNumber-500-02 = ISD-ShouldBePositiveNumber-500-02 : {0} - {1} should be an positive number !
    standardErrorCodesMapping.ISD-UnableToFetch-500-03 = ISD-UnableToFetch-500-03 : {0} - Unable to fetch {1} from database. Please try after some time !
    standardErrorCodesMapping.ISD-UnableToCreate-500-04 = ISD-UnableToCreate-500-04 : {0} - Unable to create {1} !
    standardErrorCodesMapping.ISD-UnableToDelete-500-05 = ISD-UnableToDelete-500-05 : {0} - Unable to delete {1} !
    standardErrorCodesMapping.ISD-UnableToUpdate-500-06 = ISD-UnableToUpdate-500-06 : {0} - Unable to update {1} !
    standardErrorCodesMapping.ISD-UnableToValidate-500-07 = ISD-UnableToValidate-500-07 : {0} - Unable to validate {1} !
    standardErrorCodesMapping.ISD-ServiceUnavailable-503-01 = ISD-ServiceUnavailable-503-01 : {0} - {1} : {2}
    standardErrorCodesMapping.ISD-ServiceUnavailable-503-02 = ISD-ServiceUnavailable-503-02 : {0} - {1}
kind: ConfigMap
metadata:
  labels:
    app: oes
  name: standard-error-codes-config
---
# Source: oes/templates/forwarder/oes-forwarder-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: opsmx-controller-controller1
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
data:
  configFile: |
    serviceHostname: opsmx-controller-controller1
    agentHostname: controller.exampleopsmx.net
    remoteCommandHostname: controller.exampleopsmx.net
    controlHostname: opsmx-controller-controller1
    #agentAdvertisePort: "443"
    serviceAuth:
      currentKeyName: "public.pem"
      headerMutationKeyName: "public.pem"
---
# Source: oes/templates/pipeline-promotion/pipe-promot-config-cm.yaml
apiVersion: v1
data:
  repo.properties: |
    #properties file for pipeline promotion scripts

    # Common Stuff
    repo_type=git
    repo_name=repo_name
    root_folder=pipeline/
    #S3 Specific
    export AWS_ACCESS_KEY_ID=access_key
    export AWS_SECRET_ACCESS_KEY=secret_key

    #git mandatory patameters
    git_url=example.repo.com
    git_project=project_name
    git_user=username
    git_branch=samplerepo
    #git_password=
    #API
    git_api_url=https://api.github.com/repos  # bitbucket

    #Auto PR requirements
    merge_branch=false
    auto_merge=false
    git_approve_user=approver_user
    target_branch=master

    #optional
    #git_user_email=krish@company.com

    #delete pipeLine
    delete_on_sync_spin=
    delete_on_sync_repo=
    #git_approve_user_password=
    #git_secret_sshkey=
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: pipe-promot-config
---
# Source: oes/templates/pipeline-promotion/pipe-promot-scripts-cm.yaml
apiVersion: v1
data:
  bitbucket.sh: "#!/bin/bash\n\n#this script funtions only work for bitbucket central
    repository\n\n#this script funtions only work for git repo\n#env variables needed
    for this to work are as below\n#***git_url=\"example.bitbucket.com\" make sure
    you dont add http/https or / in the url\n#****git_repo=\"pipelinepromotion\" repo
    to be pushed/download pipeline json files from\n#***git_project=\"kes\" project
    key is needed to clone/push/pull merge code\n#***git_user=\"tes.user\" user is
    needed for cloning and pusing changes (stash does not support only access key)\n#***git_branch=\"testbranch\"
    the branch to which the code should be merged with\n#***merge_branch=false if
    true then provide all the below env variables\n#   git_secret_token=\"dafjaljoahfoasjoijso\"
    needed to create pull requests should be the git_users secret token\n#   git_pr_token=\"slkdfjaljoajfopaj\"
    this is approver token to approve pull requests / you can also provide approver
    password here.\n#   git_approve_user=\"test.approver\"  username of the pull request
    approver\n#   git_password=\"adjoowddaw\" make sure your password does not include
    special characters like # @*/. special characters cause git clone command to fail
    with https\n#\n#  repo_type=\"stash\" for selfhosted bitbucket server please use
    stash as repo type\n#***root_folder=\"path/to/pipeline-promotion/folder\" folder
    to be selected in the repo to which the pipeline jobs to be pushed\n#***command=upload
    for running specific job -\n#                                         upload -
    to upload spinnaker pipeline json files to repo\n#                                         download
    - to download pipeline json file from repo and apply on spinnaker\n#***spinnaker_applications=\"testapp,sampleapp\"
    application needed to collect the pipeline information\n#spinnaker_pipelines=\"\"
    provide pipelines to be collected, if nothing given, all the pipelines of the
    application are collected\n#git_secret_sshkey=\"sshkey\" ssh key if you want to
    clone repo with ssh protocol\n\n# note *** env variables are mandatory to work
    with the script\n\nsource scripts/git.sh\ngit_bitbucket_api=$git_api_url\npr_id=0\napprove_pr_bitbucket(){\n
    \ approve_req=$(curl -X POST -u $git_approve_user:$git_pr_token \\\n  $git_bitbucket_api${git_project}/${git_repo}/pullrequests/${pr_id}/approve
    -o -I -L -s -w \"%{http_code}\")\n  echo $approve_req\n  if [[ $approve_req ==
    \"200\" ]];then\n    echo \"merge request approved successfully\"\n  else\n    echo
    \"FAIL: failed to approve the request \"\n    exit 1\n  fi\n}\n\nmerge_pr_bitbucket(){\n\n
    \ merge_req=$(curl  -X POST -u $git_user:$git_secret_token   \\\n  $git_bitbucket_api${git_project}/${git_repo}/pullrequests/${pr_id}/merge
    -o -I -L -s -w \"%{http_code}\")\n  echo $merge_req\n  if [[ $merge_req == 200
    \ ]]; then\n    echo \"merged pr successfully\"\n  elif [[ $merge_req == 202 ]];
    then\n    echo \"merging is in progress will be merged in less than a min\"\n
    \ else\n    echo \"FAILED: failed to merge $merge_pr\"\n    exit 1\nfi\n}\ncreate_pr_bitbucket(){\n\n\tlocal
    output=$(curl  -X POST -H \"Content-Type: application/json\" -u $git_user:$git_secret_token
    \  $git_bitbucket_api${git_project}/${git_repo}/pullrequests -d '{\n    \"title\":
    \"merging '$git_branch' to '$target_branch'\",\n    \"source\": {\n            \"branch\":
    {\n                \"name\": \"'$git_branch'\"\n            }\n        },\n        \"destination\":
    {\n            \"branch\": {\n                \"name\": \"'$target_branch'\"\n
    \           }\n        }\n}')\n  echo $output\n  echo $output > pr_response.json\n
    \ grep  \"There are no changes to be pulled\" pr_response.json\n  if [ \"$?\"
    = 0 ]\n  then\n    echo \"master branch is already up-to-date\"\n    exit 0\n
    \ else\n    pr_id=$(cat  pr_response.json| jq '(.id)' | sed 's/\\\"//g')\n    if
    [ $? = 0 ]; then\n      echo \"successfully created pull request \"\n      #rm
    -f pr_response.json\n    else\n      echo \"ERROR: failed to raise pull request
    $output\"\n      exit 1\n  fi\nfi\n}\n\nsync_spin_to_bitbucket(){\n  setup_git\n
    \ sync_spin_to_git\n  if [[ $merge_branch == \"true\" && $target_branch != \"\"
    && ($git_branch != $target_branch)  ]];then\n    if [[ $git_api_url_port != \"\"
    ]];then\n      git_bitbucket_api=$git_bitbucket_api:$git_api_url_port\n      create_pr_bitbucket\n
    \     if [[ $auto_merge == \"true\" ]]; then\n        approve_pr_bitbucket\n        sleep
    5\n        merge_pr_bitbucket\n      fi\n    else\n      create_pr_bitbucket\n
    \     if [[ $auto_merge == \"true\" ]]; then\n        approve_pr_bitbucket\n        sleep
    5\n        merge_pr_bitbucket\n      fi\n    fi\n  fi\n}\n"
  deployer.sh: "#!/bin/bash\necho \"In deployer.sh\"\nSBASE=scripts\nsource config/repo.properties\nBRANCH_NAME_UI=$(echo
    $branch_ui | sed 's/[][]//g')\necho $BRANCH_NAME_UI\nif [ -z \"$BRANCH_NAME_UI\"
    ]\n        then\n           echo \"Not Provided the Branch in the spinnaker UI....Continuing
    with the default branch specified in configmap\"\n           echo $git_branch\n
    else\n      echo \"Provided the User defined Branch in spinnaker UI\"\n      git_branch=$BRANCH_NAME_UI\n
    \     echo $git_branch\nfi\nROOT_FOLDER_UI=$(echo $rootfolder_ui | sed 's/[][]//g')\necho
    $ROOT_FOLDER_UI\nif [ -z \"$ROOT_FOLDER_UI\" ]\n        then\n           echo
    \"Not Provided the Save Path in the spinnaker UI....Continuing with the default
    path specified in configmap\"\n           echo $root_folder\n else\n      echo
    \"Provided the User defined Branch in spinnaker UI\"\n      root_folder=$ROOT_FOLDER_UI\n
    \     echo $root_folder\nfi\n\nsource $SBASE/spin.sh\nsource $SBASE/stash.sh\nsource
    $SBASE/s3.sh\nsource $SBASE/github.sh\nsource $SBASE/bitbucket.sh\necho \"Sourcing
    complete\"\nsync_repo_from_spinnaker(){\n\tif [[ $repo_type = \"s3\" ]];\n \tthen\n\t
    \  upload_spin_to_s3\n\telif [[ $repo_type = \"stash\" ]]; then\n\t\tsync_spin_to_stash\n
    \ elif [[ $repo_type == \"bitbucket\" ]]; then\n\t\tsync_spin_to_bitbucket\n\telif
    [[ $repo_type = \"git\" ]]; then\n\t\tsync_spin_to_github\n\telif [[ $repo_type
    = \"gitea\" ]]; then\n                sync_spin_to_github\n\telse\n\t\techo \"Not
    specified Repo type\"\n\t\texit 5\n\tfi\n}\nsync_spinnaker_from_repo(){\n\tif
    [[ $repo_type = \"s3\" ]];\n \tthen\n\t   sync_from_s3_spin\n\telif [[ $repo_type
    = \"stash\" || $repo_type = \"git\" || $repo_type = \"bitbucket\" ]]; then\n\t\tsync_git_to_spin\n\telif
    [[ $repo_type = \"gitea\" ]]; then\n\t\tsync_git_to_spin\n\tfi\n}\n\nif [[ \"$command\"
    == \"download\" ]]; then\n\tsync_spinnaker_from_repo\nelif [[ \"$command\" ==
    \"upload\" ]]; then\n        echo \"executing upload\"\n\t#statement\n\tsync_repo_from_spinnaker\nelse\n\techo
    \"ERROR: unknown command\"\n\nfi\necho \"Done executing\"\n"
  git.sh: "#!/bin/bash\nsource scripts/spin.sh\n\ngit_repo=$repo_name\ntempdir=\"/tmp/\"\npull_requred=false\nif
    [[ $git_branch == \"\" ]]\nthen\n  git_branch=\"master\"\nfi\nsetup_git() {\n
    \ echo \"Setting up the Git \"\n  local name=${git_user:-spinnaker}\n  local email=${git_user_email:-phani@opsmx.io}\n
    \ git config --global user.email \"$email\"\n  git config --global user.name \"$name\"\n}\nvalidate_clone()
    {\n\tif [ $? == 0 ]\n\tthen\n\t\techo \"Cloning done ${git_repo}\"\n\telse\n\t\techo
    \"Cloning failed with repo ${git_repo}, Please check credentials and repo access....\"\n\t\texit
    5\n\tfi\n}\ngit_clone_http() {\n  echo \"cloning $git_project/$git_repo over https\"\n
    \ if [[ $repo_type == \"git\" || $repo_type == \"bitbucket\" ]]; then\n    clone_result=$(git
    clone https://$git_user:${git_secret_token}@${git_url}/${git_project}/${git_repo}.git
    $tempdir/$git_repo 2> /dev/null)\n    validate_clone\n  elif [[ $repo_type ==
    \"gitea\" ]]; then\n    clone_result=$(git clone http://$git_user:${git_secret_token}@${git_url}/${git_project}/${git_repo}.git
    $tempdir/$git_repo 2> /dev/null)\n    validate_clone\n  elif [[ $repo_type ==
    \"stash\" ]]; then\n    #statements\n    if [[ $git_url_port != \"\" ]]; then\n
    \     clone_result=$(git  clone https://$git_user:${git_secret_token}@${git_url}:$git_url_port/scm/${git_project}/$git_repo.git
    $tempdir/$git_repo 2> /dev/null)\n      validate_clone\n    else\n      clone_result=$(git
    \ clone https://$git_user:${git_secret_token}@${git_url}/scm/${git_project}/$git_repo.git
    $tempdir/$git_repo 2> /dev/null)\n      validate_clone\n    fi\n  fi\n  #echo
    $clone_result\n}\nload_ssh(){\n\tmkdir /home/opsmx/.ssh\n\tcp /etc/git-secret/git_secret_sshkey
    ~/.ssh/id_rsa\n\tchmod 400 ~/.ssh/id_rsa\n\tssh-keyscan github.com >> ~/.ssh/known_hosts\n}\ngit_clone_ssh(){\n
    \ echo \"cloning $git_project/$git_repo over ssh\"\n  if [[ $repo_type == \"git\"
    || $repo_type == \"bitbucket\" ]]\n  then\n\t  load_ssh\n\t  clone_result=$(git
    clone git@${git_url}:${git_project}/$git_repo.git $tempdir/$git_repo 2> /dev/null)\n\t
    \ validate_clone\n  elif [[ $repo_type == \"stash\" && $git_url_port != \"\" ]];
    then\n    #statements\n    clone_result=$(git clone ssh://git@${git_url}:$git_url_port/${git_project}/$git_repo.git
    $tempdir/$git_repo 2> /dev/null)\n  else\n\n    clone_result=$(git clone ssh://git@${git_url}:${git_project}/$git_repo.git
    $tempdir/$git_repo $tempdir/$git_repo 2> /dev/null)\n  fi\n  #echo $clone_result\n}\n\ngit_add_file()
    {\n  local file=$1\n  git add $file\n}\n\ngit_add_all() {\n  git add $1\n}\ngit_tag_all()
    {\n  git tag -a Backup-$TAGSTAMP -m \"$msg\"\n  git push --tags\n}\n\ngit_delete_file()
    {\n  local file=$1\n  git rm $file\n}\n\ngit_checkout_branch(){\n  all_branches=$(git
    branch -r| grep -w  origin/$git_branch)\n  echo $all_lbranches\n  if [[ $all_branches
    != \"\" ]]\n  then\n    branch_checkout_result=$(git checkout $git_branch)\n    echo
    $branch_checkout_result\n    pull_requred=true\n  else\n    git checkout -b $git_branch\n
    \ fi\n\n}\ngit_add_all(){\n\n\tgit add $1\n\n}\ngit_commit_all() {\n  local branch=$git_branch\n
    \ local msg=\"checking application and pipeline raw data\"\n if [ \"$pull_requred\"
    = true ]; then\n   git pull origin $branch --no-edit\n   if [ \"$?\" != \"0\"
    ];then\n     echo \"[ERROR]: Failed to pull $branch upstream.\"\n     exit 1\n
    \ fi\nfi\n  opts=\"\"\n  if [ \"$git_commit_sign\" == \"true\" ]; then\n    opts=\"-s\"\n
    \ fi\n  #git commit $opts -a -m $msg\n  git commit -m \"$msg\"\n  git push --set-upstream
    origin $branch\n  if [ \"$?\" != \"0\" ];then\n    echo \"[ERROR]: Failed to push
    $branch upstream.\"\n    exit 1\n  fi\n}\n\nsync_spin_to_git() {\n\n  echo \"In
    upload function which copies spinnaker application and pipeline from spinnaker
    to repo\"\n\n  local user_root_folder=$root_folder\n\n  if [ \"$git_secret_sshkey\"
    != \"\" ]; then\n    git_clone_ssh\n  elif [ \"$git_secret_token\" != \"\" ];
    then\n    git_clone_http\n  else\n    echo \"git cloning requires either a git_aws_secret_key
    to be set or git_aws_secret_token\"\n   exit 5\n  fi\n\n  projectdir=$tempdir/$git_repo\n
    \ cd $projectdir\n  #We are done, get update git\n  git_checkout_branch\n  if
    [ -z $spinnaker_applications ]\n  then\n          spin application list > app.json\n
    \         spinnaker_app=$(cat app.json | jq -r '[.[].name]| @csv' | sed 's/\",\"/,/g;
    s/^\"\\|\"$//g')\n          rm -rf app.json\n          get_pipelines_data  $spinnaker_app\n
    \ else\n          get_pipelines_data  $spinnaker_applications\n    fi\n  git_add_all
    $root_folder\n  git_commit_all\n  return 0\n}\nsync_git_to_spin(){\n  setup_git\n
    \ if [ \"$git_secret_sshkey\" != \"\" ]; then\n    git_clone_ssh\n  elif [ \"$git_secret_token\"
    != \"\" ]; then\n    git_clone_http\n  else\n    echo \"git cloning requires either
    a git_aws_secret_key to be set or git_aws_secret_token\"\n   exit 5\n  fi\n  projectdir=$tempdir/$git_repo\n
    \ cd $projectdir\n  git_checkout_branch\n  syncup_spin\n}\n"
  github.sh: |
    #!/bin/bash

    #this script funtions only work for github central repository

    #this script funtions only work for git repo
    #env variables needed for this to work are as below
    #***git_url="example.bitbucket.com" make sure you dont add http/https or / in the url
    #****git_repo="pipelinepromotion" repo to be pushed/download pipeline json files from
    #***git_project="kes" project key is needed to clone/push/pull merge code
    #***git_user="tes.user" user is needed for cloning and pusing changes (stash does not support only access key)
    #***git_branch="testbranch" the branch to which the code should be merged with
    #***merge_branch=false if true then provide all the below env variables
    #   git_secret_token="dafjaljoahfoasjoijso" needed to create pull requests should be the git_users secret token
    #   git_pr_token="slkdfjaljoajfopaj" this is approver token to approve pull requests / you can also provide approver password here.
    #   git_approve_user="test.approver"  username of the pull request approver
    #   git_password="adjoowddaw" make sure your password does not include special characters like # @*/. special characters cause git clone command to fail with https
    #
    #  repo_type="stash" for selfhosted bitbucket server please use stash as repo type
    #***root_folder="path/to/pipeline-promotion/folder" folder to be selected in the repo to which the pipeline jobs to be pushed
    #***command=upload for running specific job -
    #                                         upload - to upload spinnaker pipeline json files to repo
    #                                         download - to download pipeline json file from repo and apply on spinnaker
    #***spinnaker_applications="testapp,sampleapp" application needed to collect the pipeline information
    #spinnaker_pipelines="" provide pipelines to be collected, if nothing given, all the pipelines of the application are collected
    #git_secret_sshkey="sshkey" ssh key if you want to clone repo with ssh protocol

    # note *** env variables are mandatory to work with the script

    source scripts/git.sh
    git_hub_api_url=$git_api_url
    approve_pr_github(){
      approve_req=$(curl -o -I -L -s -w "%{http_code}" -X POST -H "Accept: application/vnd.github.v3+json" -u $git_approve_user:$git_pr_token  $git_hub_api_url/$git_user/${git_repo}/pulls/${pr_id}/reviews \
      -d '{"body": "Spinnaker says LGTM","event": "APPROVE"}')
      echo $approve_req
      if [[ $approve_req == "200" ]];then
        echo "merge request approved successfully"
      else
        echo "FAIL: failed to approve the request $"
        exit 1
      fi
    }

    merge_pr_github(){

      merge_req=$(curl -o -I -L -s -w "%{http_code}" -X PUT -H "Accept: application/vnd.github.v3+json" -u $git_user:$git_secret_token $git_hub_api_url/$git_user/${git_repo}/pulls/${pr_id}/merge)
      echo $merge_req
      if [[ $merge_req == "200" ]]; then
        echo "merged pr successfully"
      else
        echo "FAILED: failed to merge $merge_pr"
        exit 1
    fi
    }

    create_pr_github(){

      local output=$(curl  -X POST -H "Accept: application/vnd.github.v3+json" -u $git_user:$git_secret_token $git_hub_api_url/${git_user}/${git_repo}/pulls \
      -d '{"title": "pull request to merge '$git_branch' to master","body": "pull request to merge latest pipleine jobs information to '$target_branch'", "head": "'${git_branch}'","base": "'$target_branch'"}')
      if [ "$?" != 0 ]
      then
        echo "master branch is already up-to-date"
        exit 0
      else
        echo $output
        echo $output > pr_response.json
        errors=$(cat  pr_response.json| jq '(.errors)' | sed 's/\"//g')
        if [[ $errors != null ]]; then
          echo "ERROR: failed to raise pull request $errors"
          exit 1
        fi
        pr_id=$(cat  pr_response.json| jq '(.number)' | sed 's/\"//g')
        if [[  $pr_id != ""  ]]; then
          echo "successfully created pull request "
        else
          echo "ERROR: failed to raise pull request $output"
          exit 1
      fi
    fi
    }

    sync_spin_to_github(){
      setup_git
      sync_spin_to_git
      if [[ $merge_branch == "true" && $target_branch != "" && ($git_branch != $target_branch)  ]];then
        if [[ $git_api_url_port != "" ]];then
          git_hub_api_url=$git_hub_api_url:$git_api_url_port

          create_pr_github
          if [[ $auto_merge == "true" ]]; then
            approve_pr_github
            merge_pr_github
          fi
        else
          create_pr_github
          if [[ $auto_merge == "true" ]]; then
            approve_pr_github
            merge_pr_github
          fi
        fi
      fi
    }
  s3.sh: |
    #!/bin/bash
    source scripts/spin.sh
    absolute_path="$(dirname $(readlink -f $0))"

    # s3_folder=folder/in/s3/bucket if not given script uploads to root folder or the s3 bucket
    # ***bucket_name=testenvpipelinebucket "bucktet name to upload pipeline configuration"
    # ***AWS_ACCESS_KEY_ID="SKJGIHOBGIHIHOOH" access key to access s3 bucket
    # ***AWS_SECRET_ACCESS_KEY="sdfjlasj2e334234sdljflsjflsd98y9sy/0UVv6eCg" secret to access s3 bucket
    # ***repo_type=s3 provide repo type as s3
    #***command=upload for running specific job -
    #                                         upload - to upload spinnaker pipeline json files to repo
    #                                         download - to download pipeline json file from repo and apply on spinnaker
    #***spinnaker_applications="testapp,sampleapp" application needed to collect the pipeline information
    #spinnaker_pipelines="" provide pipelines to be collected, if nothing given, all the pipelines of the application are collected


    # note *** env variables are mandatory to work with the script
    s3_folder=$root_folder
    tempdir="/tmp/"
    bucket_name=$repo_name
    create_bucket(){
      #to create a bucket in s3 bucket name needed
            aws s3 mb s3://$bucket_name
            if [ $? != 0 ]; then
                    echo "[ERROR]: Failed to create s3 bucket  might be aleady existing"
            fi
    }

    list_bucket(){
      # to llst bucket objects
         aws s3 ls s3://$bucket_name/
             if [ $? != 0 ]; then
              echo "[ERROR]: Failed to list s3 bucket "
          fi
    }

    list_application_folder(){
      # to list an object folder
            aws ls s3://$bucket_name/${s_folder}/$1 | awk '{print $4}'
    }

    upload_spin_to_s3(){
      # get the pipeline data from spinnaker and store in root_folder
      echo APP $spinnaker_applications
      if [ -z $spinnaker_applications ]
      then
              spin application list > app.json
              spinnaker_app=$(cat app.json | jq -r '[.[].name]| @csv' | sed 's/","/,/g; s/^"\|"$//g')
              rm -rf app.json
              get_pipelines_data $spinnaker_app

     else
              get_pipelines_data $spinnaker_applications
     fi

    #  get_pipelines_data
      #upload spinnaker pipelines data and upload to s3 folder
      aws s3 cp $tempdir/$bucket_name/$s3_folder s3://$bucket_name/$s3_folder --recursive
      if [ "$?" != 0 ]; then
              echo "[ERROR]: Failed to upload to bucket" $bucket_name
      else
              echo "uploaded to bucket successfully"
      fi
    }
    sync_from_s3_spin(){

      echo "downloading  spinnaker application pipelines configuration"

      aws s3 sync  s3://$bucket_name/$s3_folder $tempdir$s3_folder
      #apply configuration in spinnaker
      syncup_spin
    }

    delete_s3_object(){
      #delete an object in bucket
            aws rm s3://$bucket_name/${s3_folder}/${application_name}/  --recursive
            if [ $? != 0 ]; then
                    echo "[ERROR]: Failed to delete s3 application folder "
            else
                    echo "created bucket successfully"
            fi
    }
  spin.sh: "#!/bin/bash\n#source $(dirname $0)/git.sh\ntempdir=\"/tmp/\"\n\n#spinnaker_applications=\"sampleapp\"\nget_app_pipelines(){\n\tspin
    pipeline list --application $1  > tmp.json\n\tif [ \"$?\" != \"0\" ]; then\n\t\t\techo
    \"ERROR: spin pipeline list --application $1\"\n\t\t\treturn 1\n\tfi\n\tcat tmp.json
    | jq '.[] | (.name)' | sed 's/\\\"//g' > pipelines_in_application.list\n\tcat
    tmp.json | jq '.[] | (.id)' | sed 's/\\\"//g' > pipelines_guid.list\n\trm tmp.json\n}\n\n\nlive_backup_spin()
    {\n\n#This function will backup existing spinnaker data and store it in local
    for further comparison\n\n  if [[ $repo_type = \"s3\" ]]; then\n\t\tprojectdir=$tempdir/$root_folder\n\telse\n\t\tprojectdir=$tempdir/${git_repo}/$root_folder\n
    \ fi\n\tlive_projectdir_workdir=$projectdir/live_backup\n\n  if [ -d \"$live_projectdir_workdir\"
    ]\n  then\n    echo \"given live_spinnaker_project_work_dir is present\"\n  else\n
    \   echo \"given live_spinnaker_project_work_dir is not present therefore creating
    it\"\n    mkdir -p \"$projectdir/live_backup\"\n  fi\n\n  cd $live_projectdir_workdir\n\n
    \ spinnaker_app=$spinnaker_applications\n  IFS=',' read -r -a spinnaker_app_array
    <<< \"$spinnaker_app\"\n\n\n  spinnaker_pipe=$spinnaker_pipelines\n  IFS=',' read
    -r -a spinnaker_pipe_array <<< \"$spinnaker_pipe\"\n\n  for (( m=0; m<${#spinnaker_app_array[@]};
    m++ )); do\n     sourceApp=${spinnaker_app_array[$m]}\n     echo -e \"Processing
    application $sourceApp\\n\"\n     mkdir -p $sourceApp ; cd $sourceApp\n\t\t        #
    Get into the correct directory\n     spin -k pipeline list --application $sourceApp
    \ > tmp.json\n     if [ \"$?\" != \"0\" ]; then\n         echo \"ERROR: spin pipeline
    list --application $sourceApp\"\n         return 1\n     fi\n     cat tmp.json
    | jq '.[] | (.name)' | sed 's/\\\"//g' > live_pipelines_in_application.list\n
    \    cat tmp.json | jq '.[] | (.id)' | sed 's/\\\"//g' > live_pipelines_guid.list\n
    \    rm tmp.json\n\n     spin -k application get $sourceApp  > $sourceApp.json\n
    \    if [ \"$?\" != \"0\" ]; then\n         echo \"ERROR: spin application get
    $sourceApp\"\n         return 1\n     fi\n\n     if [[ ${#spinnaker_pipe_array[@]}
    > 0 ]]; then\n         for (( p=0; p<${#spinnaker_pipe_array[@]}; p++ )); do\n
    \           pipeLine=${spinnaker_pipe_array[$p]}\n            echo -e \"    Processing
    pipeline $pipeLine\\n\"\n            # Check if pipeline exists\n            existingPipe=`grep
    \\^${pipeLine}\\$ live_pipelines_in_application.list`\n            if [[ \"$existingPipe\"
    == \"${pipeLine}\" ]]; then\n               spin -k pipeline get --application
    $sourceApp  --name \"$pipeLine\" > \"$pipeLine.json\"\n               if [ \"$?\"
    != \"0\" ]; then\n                   echo \"ERROR: spin spin pipeline get --application
    $sourceApp  --name \\\"$pipeLine\\\"\"\n                   return 1\n               fi\n
    \           else\n               echo \"WARNING: pipeline=${pipeLine} not found
    in application=$sourceApp ... skipping\"\n            fi\n         done\n     else
    # No pipelines defined, get all the pipelines\n         while read -r line; do\n
    \           echo -e \"    Processing pipeline $line\\n\"\n            spin -k
    pipeline get --application $sourceApp --name \"$line\" > \"$line.json\"\n            if
    [ \"$?\" != \"0\" ]; then\n                echo \"ERROR: spin spin pipeline get
    --application $sourceApp  --name $line\"\n                return 1\n            fi\n
    \        done < live_pipelines_in_application.list\n     fi\n      cd ..\n  done\n
    \ return 0\n}\n\ndelete_odd_pipelines() {\n  #Delete the additional pielines that
    are in spinnaker and not in git\n   for (( m=0; m<${#spinnaker_app_array[@]};
    m++ )); do\n\t   sourceApp=${spinnaker_app_array[$m]}\n\t   if [ -f \"$projectdir/live_backup/$sourceApp/odd_pipeline.txt\"
    ]; then\n             if [ ! -s \"$projectdir/live_backup/$sourceApp/odd_pipeline.txt\"
    ]; then\n\t     echo \"no new pipelines to delete\"\n             else\n           echo
    \"============ Delete pipeline in $sourceApp Application =============\"\n\n\t
    \  while IFS= read -r pipelinename; do\n           echo \"Deleting the pipeline
    $pipelinename\"\n\t   spin -k pipeline delete --name $pipelinename --application
    $sourceApp\n           done < $projectdir/live_backup/$sourceApp/odd_pipeline.txt\n\n\t
    \  rm -rf $projectdir/live_backup/$sourceApp/odd_pipeline.txt\n\n   fi\n   fi\ndone\n\n}\n#Create
    default parameterconfig-files\ncreate_default_params() {\n    targetDir=${1:-default-config}\n
    \   echo \"Processing pipelines and creating output in $targetDir\"\n    mkdir
    -p $targetDir\n    for json in *.json ; do\n      [[ -f \"$json\" ]] || continue\n
    \     echo \"\tprocessing $json\"\n      cat \"$json\" | jq '.parameterConfig
    | reduce .[] as $p  ({};.Parameters += {($p.name): $p.default})'  >  $targetDir/tmp-param.json
    2>/dev/null\n      cat \"$json\" | jq '.triggers[0] '  >  $targetDir/tmp-trig.json
    2>/dev/null\n\n      if [[ `cat $targetDir/tmp-trig.json | wc -c` -gt 5 ]]\n      then\n
    \       cat $targetDir/tmp-param.json | jq '.triggerValues=$pp' --argfile pp $targetDir/tmp-trig.json
    > $targetDir/\"$json\" 2>/dev/null\n      else\n        cp  $targetDir/tmp-param.json
    $targetDir/\"$json\"\n      fi\n    done\n    rm -f $targetDir/tmp-param.json\n
    \   rm -f $targetDir/tmp-trig.json\n    #Remove all files with zero size\n    echo
    \"Removing files that do not have any parameters defined\"\n    find $targetDir
    -type f -size -4c -delete # No parameterConfig in the file\n    #find $targetDir
    -type f -size -4c -print -delete # No parameterConfig in the file\n}\n\nequate_pipelines_in_app()
    {\n\n #This function will comapre the applications and pipelines in git and spinnaker
    and gives the additional pipelines data\n\n  IFS=',' read -r -a spinnaker_app_array
    <<< \"$spinnaker_app\"\n\n  IFS=',' read -r -a spinnaker_pipe_array <<< \"$spinnaker_pipe\"\n\n
    \ for (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do\n     sourceApp=${spinnaker_app_array[$m]}\n\n
    \    touch $projectdir/live_backup/$sourceApp/odd_pipeline_id.txt\n\n\t\t echo
    $projectdir\n\t\t echo $git_project_work_dir\n\t\t echo $sourceApp\n     diff
    $projectdir/$git_project_work_dir/$sourceApp/pipelines_guid.list $projectdir/live_backup/$sourceApp/live_pipelines_guid.list
    | awk '{print $2}' | sed 1d > $projectdir/live_backup/$sourceApp/odd_pipeline_id.txt\n\n
    \    #list all existing spinnaker pipelines with app as reference\n     spin -k
    pipeline list --application $sourceApp > $projectdir/live_backup/$sourceApp/$sourceApp-pipeline_list.json\n
    \    touch $projectdir/live_backup/$sourceApp/odd_pipeline.txt\n\n     while IFS=
    read -r id; do\n     #Extract the pipeline names using guids as reference\n     cat
    $projectdir/live_backup/$sourceApp/$sourceApp-pipeline_list.json | jq '.[] | select
    (.id==\"'$id'\") | .name' -r >> $projectdir/live_backup/$sourceApp/odd_pipeline.txt\n
    \    done < $projectdir/live_backup/$sourceApp/odd_pipeline_id.txt\n  done\n}\n\nsyncup_spin()
    {\n  echo \"In Download function that updates the spinnaker instance with the
    contents in repo\"\n\n  #Backup of existing spinnaker pipelines with guids\n  live_backup_spin\n\n
    \ #Compare guids of existing pipelines and pipelines in git and provide names
    of additional pipelines\n  equate_pipelines_in_app\n\n  #Delete the extra pipelines(pipelines
    in spinnaker and not in git)\n\tif [[ $delete_on_sync_spin == \"true\" ]]; then\n\t\tdelete_odd_pipelines\n\tfi\n\n\tif
    [[ $repo_type = \"s3\" ]]; then\n\t\tprojectdir=$tempdir/$root_folder\n\t\techo
    \"project dir at synup spin $projectdir\"\n\telse\n\n\t\tprojectdir=$tempdir/${git_repo}/$root_folder\n\tfi\n
    \ if [ -d \"$projectdir\" ]\n  then\n    echo \"given git_project_work_dir is
    present\"\n  else\n    echo \"given git_project_work_dir is not present therefore
    creating it\"\n    mkdir -p \"$projectdir/$git_project_work_dir\"\n  fi\n\n  cd
    $projectdir\n  spinnaker_app=$spinnaker_applications\n  IFS=',' read -r -a spinnaker_app_array
    <<< \"$spinnaker_app\"\n\n  spinnaker_pipe=$spinnaker_pipelines\n  #IFS=',' read
    -r -a spinnaker_pipe_array <<< \"k8s-deploy\"\n  IFS=',' read -r -a spinnaker_pipe_array
    <<< \"$spinnaker_pipe\"\n\n  echo $projectdir\n  for (( m=0; m<${#spinnaker_app_array[@]};
    m++ )); do\n     sourceApp=${spinnaker_app_array[$m]}\n     echo -e \"Processing
    application $sourceApp\\n\"\n     cd $sourceApp              # Get into the correct
    directory\n     if [ \"$?\" != \"0\" ]; then\n         echo \"ERROR: Unable to
    change to application directory: $sourceApp\"\n         return 1\n     fi\n\n
    \    #Create the application by default, we can have flag to for this later\n
    \    spin -k application save -f $sourceApp.json\n     retVal=$?\n     if [[ \"$retVal\"
    != \"0\" && \"$ignore_errors\" == \"false\" ]]; then\n         echo \"ERROR: spin
    application save $sourceApp\"\n         return 1\n     elif [[ \"$retVal\" !=
    \"0\" && \"$ignore_errors\" == \"true\" ]]; then\n         echo \"ERROR: spin
    application save $sourceApp, continuing\"\n         cd ..\n         continue\n
    \    fi\n     #sleep 30 # Give a few seconds after application creation\n\n     if
    [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then\n         for (( p=0; p<${#spinnaker_pipe_array[@]};
    p++ )); do\n            pipeLine=${spinnaker_pipe_array[$p]}\n            echo
    -e \"    Processing pipeline $pipeLine\\n\"\n            # Check if pipeline file
    \ exists\n            if [ -f \"$pipeLine.json\" ]; then\n                #Update
    parameterConfig\n                if [[ \"$pipelineconfig\" == \"true\" ]]; then\n\n
    \                   mkdir -p temp\n                    update_params \"$pipeLine.json\"\n
    \                   rm -rf temp\n                fi\n               spin -k pipeline
    save --file \"$pipeLine.json\"\n               retVal=$?\n               if [[
    \"$retVal\" != \"0\" && \"$ignore_errors\" == \"false\" ]]; then\n                   echo
    \"ERROR: spin pipeline save --file $pipeLine.json\"\n                   return
    1\n               elif [[ \"$retVal\" != \"0\" && \"$ignore_errors\" == \"true\"
    ]]; then\n                   echo \"ERROR: spin pipeline save --file $pipeLine.json,
    continuing\"\n                   continue\n               fi\n            else\n
    \              echo \"WARNING: pipeline=${pipeLine} not found in application=$sourceApp
    ... skipping\"\n            fi\n         done\n     else # No pipelines defined,
    get all the pipelines\n         while read -r line; do\n            [[ -f \"$line.json\"
    ]] || continue\n            pipeLine=$line\n            echo -e \"    Processing
    pipeline $pipeLine\\n\"\n\n            #Update parameterConfig\n            if
    [[ \"$pipelineconfig\" == \"true\" ]]; then\n\t\t\t\t\t\t\techo \"in pipelineconfig
    else\"\n                mkdir -p temp\n                update_params \"$pipeLine.json\"\n
    \               #rm -rf temp\n            fi\n\n            echo `realpath $pipeLine.json`\n\t\t\t\t\t\tif
    test -f \"$pipeLine.json\"; then\n\t\t\t\t\t\t\tspin -k pipeline save --file \"$pipeLine.json\"\n\t\t\t\t\t\tfi\n\n
    \           retVal=$?\n            if [[ \"$retVal\" != \"0\" && \"$ignore_errors\"
    == \"false\"  ]]; then\n                echo \"ERROR: spin pipeline save --file
    $pipeLine.json\"\n                return 1\n            elif [[ \"$retVal\" !=
    \"0\" && \"$ignore_errors\" == \"true\" ]]; then\n                echo \"ERROR:
    spin pipeline save --file $pipeLine.json, continuing\"\n                continue\n
    \           fi\n           sleep 10 # Slow it down\n         done < pipelines_in_application.list\n
    \    fi\n     cd ..\n  done\n\n}\nget_pipelines_data(){\n\techo $1 \t\n\tlocal
    \ spinnaker_app=$1\n        IFS=',' read -r -a spinnaker_app_array <<< \"$spinnaker_app\"\n
    \       spinnaker_pipe=$spinnaker_pipelines\n        #IFS=',' read -r -a spinnaker_pipe_array
    <<< \"k8s-deploy\"\n        IFS=',' read -r -a spinnaker_pipe_array <<< \"$spinnaker_pipe\"\n\n\t\t\t\tif
    [[ $root_folder == \"\" ]]; then\n\t\t\t\t\troot_folder=\".\"\n\t\t\t\tfi\n        for
    (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do\n     sourceApp=${spinnaker_app_array[$m]}\n
    \    echo -e \"Processing application $sourceApp\\n\"\n\n\t\t echo \"get pipelines
    data $root_folder\"\n     mkdir -p $tempdir/$git_repo/${root_folder}/$sourceApp
    ; cd $tempdir/$git_repo/${root_folder}/$sourceApp              # Get into the
    correct directory\n\n     get_app_pipelines $sourceApp\n     spin application
    get $sourceApp  > $sourceApp.json\n     if [ \"$?\" != \"0\" ]; then\n         echo
    \"ERROR: spin application get $sourceApp\"\n         return 1\n     fi\n     if
    [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then\n         for (( p=0; p<${#spinnaker_pipe_array[@]};
    p++ )); do\n            pipeLine=${spinnaker_pipe_array[$p]}\n            echo
    -e \"    Processing pipeline $pipeLine\\n\"\n            # Check if pipeline exists\n
    \           existingPipe=`grep \\^${pipeLine}\\$ pipelines_in_application.list`\n
    \           if [[ \"$existingPipe\" == \"${pipeLine}\" ]]; then\n               spin
    pipeline get --application $sourceApp  --name \"$pipeLine\" > \"$pipeLine.json\"\n\n
    \              if [ \"$?\" != \"0\" ]; then\n                   echo \"ERROR:
    spin spin pipeline get --application $sourceApp  --name \\\"$pipeLine\\\"\"\n
    \                  return 1\n               fi\n            else\n               echo
    \"WARNING: pipeline=${pipeLine} not found in application=$sourceApp ... skipping\"\n
    \           fi\n         done\n     else # No pipelines defined, get all the pipelines\n
    \        while read -r line; do\n            echo -e \"    Processing pipeline
    $line\\n\"\n            spin pipeline get --application $sourceApp --name \"$line\"
    > \"$line.json\"\n            if [ \"$?\" != \"0\" ]; then\n                echo
    \"ERROR: spin spin pipeline get --application $sourceApp  --name $line\"\n                return
    1\n            fi\n\n         done < pipelines_in_application.list\n     fi\n
    \    if [[ \"$pipelinecreateconf\" == \"true\" ]]; then\n        create_default_params\n
    \    fi\n     cd -\n  done\n}\n\ndownload_spin() {\n  echo \"In Download function
    that updates the spinnaker instance with the contents in git\"\n  local user_root_folder=$root_folder\n\n
    \ if [ \"$git_secret_sshkey\" != \"\" ]; then\n    git_clone_ssh_change $user_root_folder
    $git_repo $git_project\n  elif [ \"$git_secret_token\" != \"\" ]; then\n    git_clone_http
    $user_root_folder $git_repo $git_project\n  else\n    echo \"git cloning requires
    either a git_secret_sshkey to be set or git_secret_token\"\n   exit 5\n  fi\n\n
    \ projectdir=$HOME/$git_project\n  cd $projectdir\n\n  spinnaker_app=$spinnaker_applications\n
    \ IFS=',' read -r -a spinnaker_app_array <<< \"$spinnaker_app\"\n\n  spinnaker_pipe=$spinnaker_pipelines\n
    \ #IFS=',' read -r -a spinnaker_pipe_array <<< \"k8s-deploy\"\n  IFS=',' read
    -r -a spinnaker_pipe_array <<< \"$spinnaker_pipe\"\n\n\n  for (( m=0; m<${#spinnaker_app_array[@]};
    m++ )); do\n     sourceApp=${spinnaker_app_array[$m]}\n     echo -e \"Processing
    application $sourceApp\\n\"\n     cd $sourceApp              # Get into the correct
    directory\n     if [ \"$?\" != \"0\" ]; then\n         echo \"ERROR: Unable to
    change to application directory: $sourceApp\"\n         return 1\n     fi\n\n
    \    #Create the application by default, we can have flag to for this later\n
    \    spin application save -f $sourceApp.json\n     retVal=$?\n     if [[ \"$retVal\"
    != \"0\" && \"$ignore_errors\" == \"false\" ]]; then\n         echo \"ERROR: spin
    application save $sourceApp\"\n         return 1\n     elif [[ \"$retVal\" !=
    \"0\" && \"$ignore_errors\" == \"true\" ]]; then\n         echo \"ERROR: spin
    application save $sourceApp, continuing\"\n         cd ..\n         continue\n
    \    fi\n     sleep 30 # Give a few seconds after application creation\n\n     if
    [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then\n         for (( p=0; p<${#spinnaker_pipe_array[@]};
    p++ )); do\n            pipeLine=${spinnaker_pipe_array[$p]}\n            echo
    -e \"    Processing pipeline $pipeLine\\n\"\n            # Check if pipeline file
    \ exists\n            if [ -f \"$pipeLine.json\" ]; then\n                #Update
    parameterConfig\n                if [[ \"$pipelineconfig\" == \"true\" ]]; then\n
    \                   mkdir -p temp\n                    update_params \"$pipeLine.json\"\n
    \                   rm -rf temp\n                fi\n               spin pipeline
    save --file \"$pipeLine.json\"\n               retVal=$?\n               if [[
    \"$retVal\" != \"0\" && \"$ignore_errors\" == \"false\" ]]; then\n                   echo
    \"ERROR: spin pipeline save --file $pipeLine.json\"\n                   return
    1\n               elif [[ \"$retVal\" != \"0\" && \"$ignore_errors\" == \"true\"
    ]]; then\n                   echo \"ERROR: spin pipeline save --file $pipeLine.json,
    continuing\"\n                   continue\n               fi\n            else\n
    \              echo \"WARNING: pipeline=${pipeLine} not found in application=$sourceApp
    ... skipping\"\n            fi\n         done\n     else # No pipelines defined,
    get all the pipelines\n         while read -r line; do\n            [[ -f \"$line.json\"
    ]] || continue\n            pipeLine=$line\n            echo -e \"    Processing
    pipeline $pipeLine\\n\"\n\n            #Update parameterConfig\n            if
    [[ \"$pipelineconfig\" == \"true\" ]]; then\n                mkdir -p temp\n                update_params
    \"$pipeLine.json\"\n                #rm -rf temp\n            fi\n            spin
    pipeline save --file \"$pipeLine.json\"\n            retVal=$?\n            if
    [[ \"$retVal\" != \"0\" && \"$ignore_errors\" == \"false\"  ]]; then\n                echo
    \"ERROR: spin pipeline save --file $pipeLine.json\"\n                return 1\n
    \           elif [[ \"$retVal\" != \"0\" && \"$ignore_errors\" == \"true\" ]];
    then\n                echo \"ERROR: spin pipeline save --file $pipeLine.json,
    continuing\"\n                continue\n            fi\n            sleep 10 #
    Slow it down\n         done < pipelines_in_application.list\n     fi\n     cd
    ..\n  done\n\n}\n\nupdate_params() {\n    confDir=${pipelineconfigdir}\n    if
    [ ! -d \"$confDir\" ] ; then\n      echo \"Directory specified for configuratio
    ($confDir) not found in application directory\"\n      return\n    fi\n    if
    [ ! -f \"$confDir/$json\" ] ; then\n      echo \"INFO: No configuration found
    for $json in $confDir\"\n      return\n    fi\n    json=\"$1\"\n    echo \"Processing
    pipeline ($json) and updating pipelines as per configuration in $confDir\"\n    #Extract
    .parameterConfig\n    cat \"$json\" | jq '.parameterConfig' > temp/\"config-$json\"\n
    \   #Replace parameters\n    cat temp/\"config-$json\" | jq -f /home/opsmx/scripts/replace-params.jq
    --argfile pp $confDir/\"$json\" > temp/\"updated-config-$json\"\n\n    #Replace
    .parameterConfig\n    cat \"$json\" | jq  '.parameterConfig=$uc' --argfile uc
    temp/\"updated-config-$json\" > temp/\"$json\"\n\n    ########################################################################\n
    \   #Extract 1st trigger\n    cat  temp/\"$json\"| jq '.triggers[0]' > temp/tmp-trig.json\n
    \   #Update first trigger\n    cat temp/tmp-trig.json | jq 'if $pp.triggerValues
    != null then . * $pp.triggerValues else . end'  --argfile pp $confDir/\"$json\"
    \ > temp/updated-tmp-trig.json\n    #Update pipeline-json with updated trigger\n
    \   if [[ `cat temp/updated-tmp-trig.json | wc -c` -gt 5 ]]\n    then\n      cat
    temp/\"$json\" | jq '.triggers[0]=$pp' --argfile pp temp/updated-tmp-trig.json
    > temp/final-replaced.json\n      cp temp/final-replaced.json \"$json\"\n    else\n
    \     cp  temp/\"$json\" \"$json\"\n    fi\n    ########################################################################\n}\n"
  stash.sh: "#!/bin/bash\n\n#this script funtions only work for self hosted bitbucketserver/stash
    central repository\n#env variables needed for this to work are as below\n#***git_url=\"example.bitbucket.com\"
    make sure you dont add http/https or / in the url\n#****git_repo=\"pipelinepromotion\"
    repo to be pushed/download pipeline json files from\n#***git_project=\"kes\" project
    key is needed to clone/push/pull merge code\n#***git_user=\"tes.user\" user is
    needed for cloning and pusing changes (stash does not support only access key)\n#git_password=\"adjoowddaw\"
    make sure your password does not include special characters like # @*/. special
    characters cause git clone command to fail with https\n#***git_branch=\"testbranch\"
    the branch to which the code should be merged with\n#***merge_branch=false if
    true then provide all the below env variables\n#   git_secret_token=\"dafjaljoahfoasjoijso\"
    needed to create pull requests should be the git_users secret token\n#   git_pr_token=\"slkdfjaljoajfopaj\"
    this is approver token to approve pull requests / you can also provide approver
    password here.\n#   git_approve_user=\"test.approver\"  username of the pull request
    approver\n#\n# repo_type=\"stash\" for selfhosted bitbucket server please use
    stash as repo type\n#***root_folder=\"path/to/pipeline-promotion/folder\" folder
    to be selected in the repo to which the pipeline jobs to be pushed\n#***command=upload
    for running specific job -\n#                                         upload -
    to upload spinnaker pipeline json files to repo\n#                                         download
    - to download pipeline json file from repo and apply on spinnaker\n#***spinnaker_applications=\"testapp,sampleapp\"
    application needed to collect the pipeline information\n#spinnaker_pipelines=\"\"
    provide pipelines to be collected, if nothing given, all the pipelines of the
    application are collected\n#git_secret_sshkey=\"sshkey\" ssh key if you want to
    clone repo with ssh protocol\n\n# note *** env variables are mandatory to work
    with the script\n\nsource scripts/git.sh\ngit_repo=$repo_name\npr_id=0\npr_version=0\napprove_pr_stash(){\n
    \ approve_req=$(curl -k -o -I -L -s -w \"%{http_code}\"  -X POST -H \"Content-Type:
    application/json\" -u $git_approve_user:$git_pr_token \\\n  https://$git_api_url/${git_project}/repos/${git_repo}/pull-requests/${pr_id}/approve)\n
    \ echo $approve_req\n  if [[ $approve_req == \"200\" ]];then\n    echo \"merge
    request approved successfully\"\n  else\n    echo \"FAIL: failed to approve the
    request \"\n    exit 1\n  fi\n}\n\nmerge_pr_stash(){\n\n  merge_req=$(curl -k
    -o -I -L -s -w \"%{http_code}\"  -X POST -H \"Content-Type: application/json\"
    -u $git_user:$git_secret_token   \\\n  https://$git_api_url/${git_project}/repos/${git_repo}/pull-requests/${pr_id}/merge?version=$pr_version)\n
    \ echo $merge_req\n  if [ $merge_req == \"200\" ]; then\n    echo \"merged pr
    successfully\"\n  else\n    echo \"FAILED: failed to merge $merge_pr\"\n    exit
    1\nfi\n}\ncreate_pr_stash(){\n\n\tlocal output=$(curl -k -X POST -H \"Content-Type:
    application/json\" -u $git_user:$git_secret_token   https://$git_api_url/${git_project}/repos/${git_repo}/pull-requests
    -d '{\n    \"title\": \"merging '\"$git_branch\"' to '\"$target_branch\"'\",\n
    \   \"description\": \"changes from spinnaker pipeline jobs are to be merged to
    master\",\n    \"state\": \"OPEN\",\n    \"open\": true,\n    \"closed\": false,\n
    \   \"fromRef\": {\n        \"id\": \"refs/heads/'\"${git_branch}\"'\",\n        \"repository\":
    {\n            \"slug\": \"'\"${git_repo}\"'\",\n            \"name\": null,\n
    \           \"project\": {\n                \"key\": \"'\"${git_project}\"'\"\n
    \           }\n        }\n    },\n    \"toRef\": {\n        \"id\": \"refs/heads/'\"$target_branch\"'\",\n
    \       \"repository\": {\n            \"slug\": \"'\"${git_repo}\"'\",\n            \"name\":
    null,\n            \"project\": {\n                \"key\": \"'\"${git_project}\"'\"\n
    \           }\n        }\n    },\n    \"locked\": false\n}')\n  echo $output\n
    \ echo $output > pr_response.json\n  grep  \"is already up-to-date with branch\"
    pr_response.json\n  if [ \"$?\" = 0 ]\n  then\n    echo \"master branch is already
    up-to-date\"\n    exit 0\n  else\n    pr_id=$(cat  pr_response.json| jq '(.id)'
    | sed 's/\\\"//g')\n    pr_version=$(cat pr_response.json | jq '(.version)' |
    sed 's/\\\"//g')\n\n    if [ $? = 0 ]; then\n      echo \"successfully created
    pull request \"\n      #rm -f pr_response.json\n    else\n      echo \"ERROR:
    failed to raise pull request $output\"\n      exit 1\n  fi\nfi\n}\n\nsync_spin_to_stash(){\n
    \ #setup git configuration using email and username\n  setup_git\n  #upload spinnaker
    configuration to git\n  sync_spin_to_git\n  #check if custom port is being used
    for repo\n  if [[ $merge_branch == \"true\" && $target_branch != \"\" && ($git_branch
    != $target_branch)  ]];then\n    if [[ $git_api_url_port != \"\" ]];then\n      git_api_url=$git_api_url:$git_api_url_port\n
    \     create_pr_stash\n      if [[ $auto_merge == \"true\" ]]; then\n        approve_pr_stash\n
    \       merge_pr_stash\n      fi\n    else\n      create_pr_stash\n      if [[
    $auto_merge == \"true\" ]]; then\n        approve_pr_stash\n        merge_pr_stash\n
    \     fi\n    fi\n  fi\n}\n"

kind: ConfigMap
metadata:
  name: pipe-promot-scripts
---
# Source: oes/charts/minio/templates/pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "10Gi"
---
# Source: oes/charts/openldap/templates/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: isd-openldap
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "5Gi"
---
# Source: oes/charts/minio/templates/post-install-prometheus-metrics-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: isd-minio-update-prometheus-secret
  labels:
    app: minio-update-prometheus-secret
    chart: minio-8.0.9
    release: isd
    heritage: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - get
      - create
      - update
      - patch
    resourceNames:
      - isd-minio-prometheus
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - create
  - apiGroups:
      - monitoring.coreos.com
    resources:
      - servicemonitors
    verbs:
      - get
    resourceNames:
      - isd-minio
---
# Source: oes/charts/spinnaker/templates/rbac/spinnaker-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: spinnaker-role
rules:
  - apiGroups: ['']
    resources:
      [
        'namespaces',
        'events',
        'replicationcontrollers',
        'serviceaccounts',
        'pods/log',
      ]
    verbs: ['get', 'list']
  - apiGroups: ['']
    resources: ['pods', 'services', 'secrets', 'configmaps']
    verbs:
      [
        'create',
        'delete',
        'deletecollection',
        'get',
        'list',
        'patch',
        'update',
        'watch',
      ]
  - apiGroups: ['autoscaling']
    resources: ['horizontalpodautoscalers']
    verbs: ['list', 'get']
  - apiGroups: ['apps']
    resources: ['controllerrevisions', 'statefulsets']
    verbs: ['list']
  - apiGroups: ['extensions', 'apps']
    resources: ['deployments', 'replicasets', 'ingresses']
    verbs:
      [
        'create',
        'delete',
        'deletecollection',
        'get',
        'list',
        'patch',
        'update',
        'watch',
      ]
  # These permissions are necessary for halyard to operate. We use this role also to deploy Spinnaker itself.
  - apiGroups: ['']
    resources: ['services/proxy', 'pods/portforward']
    verbs:
      [
        'create',
        'delete',
        'deletecollection',
        'get',
        'list',
        'patch',
        'update',
        'watch',
      ]
  # These permissions are necessary for halyard to operate. We use this role also to deploy Spinnaker itself.
  - apiGroups: ['batch']
    resources: ['jobs']
    verbs:
      [
        'create',
        'delete',
        'get',
        'list',
        'update',
        'watch',
      ]
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: create-controller-secret
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get","list","create","update","patch"]
---
# Source: oes/charts/minio/templates/post-install-prometheus-metrics-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: isd-minio-update-prometheus-secret
  labels:
    app: minio-update-prometheus-secret
    chart: minio-8.0.9
    release: isd
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: isd-minio-update-prometheus-secret
subjects:
  - kind: ServiceAccount
    name: isd-minio-update-prometheus-secret
    namespace: "opsmx-isd"
---
# Source: oes/charts/spinnaker/templates/rbac/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: isd-spinnaker-halyard
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role                 # ClusterRole, if we have access to cluster resources
  name: spinnaker-role       # edit, if we have the access
subjects:
- namespace: opsmx-isd
  kind: ServiceAccount
  name: isd-spinnaker-halyard
---
# Source: oes/charts/spinnaker/templates/rbac/spinnaker-sa.yaml
# In the case of a local cluster Spinnaker needs
# to be able to deploy to all namespaces in the cluster.
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding  # ClusterRoleBinding, if we have access accross the cluster
metadata:
  name: isd-spinnaker-spinnaker
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role             # ClusteRoleBinding if we have access accross the cluster
  name: spinnaker-role   # cluster-admin if we have the access
subjects:
- namespace: opsmx-isd
  kind: ServiceAccount
  # Clouddriver does not currently allow config of its
  # service account.
  name: default
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: create-controller-secret
subjects:
- kind: ServiceAccount
  name: create-controller-secret
roleRef:
  kind: Role
  name: create-controller-secret
  apiGroup: rbac.authorization.k8s.io
---
# Source: oes/templates/rbac/oes-init-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding # ClusterRole if you have cluster access
metadata:
  name: opsmx-isd-oes-access
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: view
subjects:
- namespace: opsmx-isd
  kind: ServiceAccount
  name: default
---
# Source: oes/charts/gitea/charts/memcached/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-memcached
  namespace: opsmx-isd
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-5.9.0
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  type: ClusterIP
  ports:
    - name: memcache
      port: 11211
      targetPort: memcache
      nodePort: null
  selector:
    app.kubernetes.io/name: memcached
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/gitea/charts/postgresql/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-postgresql-headless
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
  namespace: opsmx-isd
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/gitea/charts/postgresql/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
  annotations:
  namespace: opsmx-isd
spec:
  type: ClusterIP
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: isd
    role: primary
---
# Source: oes/charts/gitea/templates/gitea/http-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-gitea-http
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
  annotations:
    null
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: http
    port: 3000
    targetPort: 3000
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/gitea/templates/gitea/ssh-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-gitea-ssh
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
  annotations:
    null
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: ssh
    port: 22
    targetPort: 22
    protocol: TCP
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/minio/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 9000
      protocol: TCP
      targetPort: 9000
  selector:
    app: minio
    release: isd
---
# Source: oes/charts/openldap/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-openldap
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
spec:
  ports:
    - name: ldap-port
      protocol: TCP
      port: 389
      targetPort: ldap-port
    - name: ssl-ldap-port
      protocol: TCP
      port: 636
      targetPort: ssl-ldap-port
  selector:
    app: openldap
    release: isd
  type: ClusterIP
---
# Source: oes/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-redis-headless
  labels:
    app: redis
    chart: redis-10.5.3
    release: isd
    heritage: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: redis
    port: 6379
    targetPort: redis
  selector:
    app: redis
    release: isd
---
# Source: oes/charts/redis/templates/redis-master-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-redis-master
  labels:
    app: redis
    chart: redis-10.5.3
    release: isd
    heritage: Helm
spec:
  type: ClusterIP
  ports:
  - name: redis
    port: 6379
    targetPort: redis
  selector:
    app: redis
    release: isd
    role: master
---
# Source: oes/charts/spinnaker/templates/services/halyard.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-spinnaker-halyard
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
    component: halyard
spec:
  ports:
  - port: 8064
    name: daemon
  clusterIP: None
  selector:
    app: isd-spinnaker
    component: halyard
---
# Source: oes/templates/forwarder/oes-forwarder-svc-agent.yaml
apiVersion: v1
kind: Service
metadata:
  name: opsmx-controller-controller1
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
spec:
  selector:
    app: opsmx-controller-controller1
  type: ClusterIP
  ports:
  - name: service-api
    port: 9002
    targetPort: service-api
  - name: control-api
    port: 9003
    targetPort: control-api
  - name: remote-command
    port: 9004
    targetPort: remote-command
---
# Source: oes/templates/forwarder/oes-forwarder-svc-agent.yaml
apiVersion: v1
kind: Service
metadata:
  name: agent-grpc
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
spec:
  selector:
    app: opsmx-controller-controller1
  type: LoadBalancer
  ports:
  - name: agent-grpc
    port: 9001
---
# Source: oes/templates/forwarder/oes-forwarder-svc-ipc.yaml
apiVersion: v1
kind: Service
metadata:
  name: opsmx-controller-controller1-interproc
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
spec:
  selector:
    app: opsmx-controller-controller1
  type: ClusterIP
  ports:
  - name: agent-grpc
    port: 9001
    targetPort: agent-grpc
---
# Source: oes/templates/sapor-gate/sapor-gate-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spin
    component: sapor-gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: sapor-gate
spec:
  type: ClusterIP
  ports:
  - name: "sapor-gate-service"
    port: 8084
    protocol: TCP
    targetPort: 8084
  selector:
    app: oes
    component: sapor-gate
---
# Source: oes/templates/services/oes-auditclient-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: auditclient
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-audit-client
spec:
  ports:
  - name: auditclient
    port: 8098
    protocol: TCP
    targetPort: 8098
  selector:
    app: oes
    component: auditclient
  type: ClusterIP
---
# Source: oes/templates/services/oes-auditservice-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: auditservice
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-audit-service
spec:
  ports:
  - name: auditservice
    port: 8097
    protocol: TCP
    targetPort: 8097
  selector:
    app: oes
    component: auditservice
  type: ClusterIP
---
# Source: oes/templates/services/oes-autopilot-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: autopilot
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-autopilot
spec:
  type: ClusterIP
  ports:
  - name: "cas-service"
    port: 8090
    targetPort: 8090
  - name: "monitoring-service"
    port: 9090
    targetPort: 9090
  selector:
    app: oes
    component: autopilot
---
# Source: oes/templates/services/oes-dashboard-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: dashboard
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-dashboard
spec:
  type: ClusterIP
  ports:
  - name: dashboard
    protocol: TCP
    port: 8094
    targetPort: 8094
  selector:
    app: oes
    component: dashboard
---
# Source: oes/templates/services/oes-datascience-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: datascience
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-datascience
spec:
  ports:
  - name: datascience
    port: 5005
    protocol: TCP
    targetPort: 5005
  selector:
    app: oes
    component: datascience
  type: ClusterIP
---
# Source: oes/templates/services/oes-db-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: db
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-db
spec:
  type: ClusterIP
  ports:
  - name: db
    protocol: TCP
    port: 5432
    targetPort: 5432
  selector:
    app: oes
    component: db
---
# Source: oes/templates/services/oes-gate-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-gate
spec:
  type: ClusterIP
  ports:
  - name: "https"
    port: 443
    targetPort: 8084
  - name: "oes-gate-service"
    port: 8084
    protocol: TCP
    targetPort: 8084
  - name: "http"
    port: 80
    targetPort: 8084
  selector:
    app: oes
    component: gate
---
# Source: oes/templates/services/oes-platform-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: platform
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-platform
spec:
  type: ClusterIP
  ports:
  - name: oes-platform
    protocol: TCP
    port: 8095
    targetPort: 8095
  selector:
    app: oes
    component: platform
---
# Source: oes/templates/services/oes-rabbitmq-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: rabbitmq
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: rabbitmq-service
spec:
  ports:
  - name: rabbitmq
    port: 5672
    protocol: TCP
    targetPort: 5672
  - name: rabbitmq-mgmt
    port: 15672
    protocol: TCP
    targetPort: 15672
  selector:
    app: oes
    component: rabbitmq
  type: ClusterIP
---
# Source: oes/templates/services/oes-sapor-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: sapor
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-sapor
spec:
  type: ClusterIP
  ports:
  - name: "sapor"
    port: 8085
    targetPort: 8085
  selector:
    app: oes
    component: sapor
---
# Source: oes/templates/services/oes-ui-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-ui
spec:
  type: ClusterIP
  ports:
  - name: "https"
    port: 443
    targetPort: 8080
  - name: "http"
    port: 8080
    targetPort: 8080
  selector:
    app: oes
    component: ui
---
# Source: oes/templates/services/oes-visibility-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: visibility 
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-visibility
spec:
  type: ClusterIP
  ports:
  - name: visibility 
    protocol: TCP
    port: 8096
    targetPort: 8096
  selector:
    app: oes
    component: visibility
---
# Source: oes/templates/services/opa-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: opa
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
spec:
  selector:
    app: opa
  ports:
  - protocol: TCP
    port: 8181
    targetPort: 8181
  type: ClusterIP
---
# Source: oes/templates/spinnaker-extra/spinsvcs.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spin
    stack: deck
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: spin-deck-lb
spec:
  type: ClusterIP
  ports:
   - name: "https"
     port: 443
     targetPort: 9000
   - name: "http"
     port: 80
     protocol: TCP
     targetPort: 9000
  selector:
    cluster: spin-deck
---
# Source: oes/templates/spinnaker-extra/spinsvcs.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spin
    stack: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: spin-gate-lb
spec:
  type: ClusterIP
  ports:
   - name: https
     port: 443
     targetPort: 8084
   - name: "http"
     port: 80
     protocol: TCP
     targetPort: 8084
  selector:
    cluster: spin-gate
---
# Source: oes/charts/gitea/charts/memcached/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: isd-memcached
  namespace: opsmx-isd
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-5.9.0
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: memcached
      app.kubernetes.io/instance: isd
  replicas: 1
  template:
    metadata:
      labels:
        app.kubernetes.io/name: memcached
        helm.sh/chart: memcached-5.9.0
        app.kubernetes.io/instance: isd
        app.kubernetes.io/managed-by: Helm
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: memcached
                    app.kubernetes.io/instance: isd
                namespaces:
                  - "opsmx-isd"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
      serviceAccountName: isd-memcached
      containers:
        - name: memcached
          image: docker.io/bitnami/memcached:1.6.9-debian-10-r114
          imagePullPolicy: "IfNotPresent"
          args:
            - /run.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
          ports:
            - name: memcache
              containerPort: 11211
          livenessProbe:
            tcpSocket:
              port: memcache
            initialDelaySeconds: 30
            timeoutSeconds: 5
            failureThreshold: 6
          readinessProbe:
            tcpSocket:
              port: memcache
            initialDelaySeconds: 5
            timeoutSeconds: 3
            periodSeconds: 5
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: tmp
              mountPath: /tmp
          securityContext:
            readOnlyRootFilesystem: false
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: oes/charts/minio/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
  selector:
    matchLabels:
      app: minio
      release: isd
  template:
    metadata:
      name: isd-minio
      labels:
        app: minio
        release: isd
      annotations:
        checksum/secrets: 0e7fab1c3058994997feaa92931063f8fc4c7f719d54fd3ef3459505a6a61533
        checksum/config: 7a7ac5513fcd53ca17fde80ebf50780809224b63001a3969ca32fcaf1caf5999
    spec:
      serviceAccountName: "isd-minio"
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: minio
          image: "minio/minio:RELEASE.2020-12-03T05-49-24Z"
          imagePullPolicy: IfNotPresent
          command:
            - "/bin/sh"
            - "-ce"
            - "/usr/bin/docker-entrypoint.sh minio -S /etc/minio/certs/ server /export"
          volumeMounts:
            - name: export
              mountPath: /export            
          ports:
            - name: http
              containerPort: 9000
          env:
            - name: MINIO_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: isd-minio
                  key: accesskey
            - name: MINIO_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: isd-minio
                  key: secretkey
          resources:
            requests:
              memory: 4Gi      
      volumes:
        - name: export
          persistentVolumeClaim:
            claimName: isd-minio
        - name: minio-user
          secret:
            secretName: isd-minio
---
# Source: oes/charts/openldap/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  name:  isd-openldap
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: openldap
      release: isd
  template:
    metadata:
      annotations:
        checksum/configmap-env: da8e0c8da82ff9254423b65018fe528f67823beb164b9f81ba49b04afd696558
        checksum/configmap-customldif: 3bf9905ca1d307472278add416a8fff6618651f0ef01b0dcaab0009017d48376
        moniker.spinnaker.io/application: spin
      labels:
        app: openldap
        release: isd
    spec:
      initContainers:
      - name: openldap-init-ldif
        image: quay.io/opsmxpublic/busybox:1.28
        command: ['sh', '-c', 'cp /customldif/* /ldifworkingdir']
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - name: customldif
          mountPath: /customldif
        - name: ldifworkingdir
          mountPath: /ldifworkingdir
        resources:
          {}
      containers:
        - name: openldap
          image: "osixia/openldap:1.2.4"
          lifecycle:
            postStart:
              exec:
                command:
                - /bin/sh
                - -c
                - until service slapd status; do sleep 10 ;done
          imagePullPolicy: IfNotPresent
          args: [--copy-service]
          ports:
            - name: ldap-port
              containerPort: 389
            - name: ssl-ldap-port
              containerPort: 636
          envFrom:
            - configMapRef:
                name: isd-openldap-env
            - secretRef:
                name: isd-openldap
          volumeMounts:
            - name: data
              mountPath: /var/lib/ldap
              subPath: data
            - name: data
              mountPath: /etc/ldap/slapd.d
              subPath: config-data
            - name: ldifworkingdir
              mountPath: /container/service/slapd/assets/config/bootstrap/ldif/custom
          env:
          livenessProbe:
            tcpSocket:
              port: ldap-port
            initialDelaySeconds: 20
            periodSeconds: 10
            failureThreshold: 10
          readinessProbe:
            tcpSocket:
              port: ldap-port
            initialDelaySeconds: 20
            periodSeconds: 10
            failureThreshold: 10
          resources:
            {}
      volumes:
        - name: customldif
          configMap:
            name: isd-openldap-customldif
        - name: ldifworkingdir
          emptyDir: {}
        - name: certs
          emptyDir:
            medium: Memory
        - name: data
          persistentVolumeClaim:
            claimName: isd-openldap
---
# Source: oes/templates/deployments/oes-audit-client.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: auditclient
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-audit-client
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: auditclient
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8098"
      labels:
        app: oes
        component: auditclient
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-audit-client:v3.12.5 
        imagePullPolicy: IfNotPresent
        name: oes-audit-client
        ports:
        - containerPort: 8098
          name: backend
          protocol: TCP
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /mgmt/health
            port: 8098
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 1
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 8098
        volumeMounts:
        - mountPath: /opsmx/conf/audit-client-local.yml
          name: audit-config-volume
          subPath: audit-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
      volumes:
      - secret:
          items:
          - key: audit-local.yml
            path: audit-local.yml
          secretName: oes-audit-client-config
        name: audit-config-volume
      - name: bootstrap-config-volume
        secret:
          defaultMode: 420
          secretName: bootstrap
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-audit-service.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: auditservice
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-audit-service
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: auditservice
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "false"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8097"
      labels:
        app: oes
        component: auditservice
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-audit-service:v3.12.5
        imagePullPolicy: IfNotPresent
        name: oes-audit
        ports:
        - containerPort: 8097
          name: backend
          protocol: TCP
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /mgmt/health
            port: 8097
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 1
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 8097
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /opsmx/conf/audit-service-local.yml
          name: audit-config-volume
          subPath: audit-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
      volumes:
      volumes:
      - secret:
          items:
          - key: audit-local.yml
            path: audit-local.yml
          secretName: oes-audit-service-config
        name: audit-config-volume
      - name: bootstrap-config-volume
        secret:
          defaultMode: 420
          secretName: bootstrap
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-autopilot-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  name: oes-autopilot
  labels:
    app: oes
    component: autopilot
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: autopilot
  template:
    metadata:
      labels:
        app: oes
        component: autopilot
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8090"
    spec:
      volumes:
        - name: autopilot-config-volume
          secret:
            secretName: oes-autopilot-config
        - secret:
            items:
            - key: bootstrap.yml
              path: bootstrap.yml
            secretName: bootstrap
          name: bootstrap-config-volume
        - configMap:
            defaultMode: 420
            items:
            - key: standard-error-codes.csv
              path: standard-error-codes.csv
            name: standard-error-codes-config
          name: standard-error-conf
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/postgres:9.6.5
        command: ['/bin/bash', '-c', "sleep 30;echo Waiting for oes-db to be up and running; pg_isready -h oes-db -p 5432 && echo PostgreSQL DB is ready to receive connections"]
      containers:
        - image: quay.io/opsmxpublic/ubi8-oes-autopilot:v3.12.5
          imagePullPolicy: IfNotPresent
          name: oes-autopilot
          resources:
            {}
          ports:
            - containerPort: 8090
              name: backend
              protocol: TCP
            - containerPort: 9090
              name: metricfetcher
              protocol: TCP
          volumeMounts:
          - name: autopilot-config-volume
            mountPath: /opsmx/conf/autopilot.properties
            subPath: autopilot.properties
          - mountPath: /opsmx/conf/bootstrap.yml
            name: bootstrap-config-volume
            subPath: bootstrap.yml
          - mountPath: /opsmx/conf/standard-error-code.csv
            name: standard-error-conf
            subPath: standard-error-codes.csv
          readinessProbe:
            tcpSocket:
              port: 8090
            initialDelaySeconds: 60
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /mgmt/health
              port: 8090
            initialDelaySeconds: 120
            periodSeconds: 60
---
# Source: oes/templates/deployments/oes-dashboard-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: dashboard
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-dashboard
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: dashboard
  strategy: {}
  template:
    metadata:
      annotations:
        configmap/checksum: bfdbbd95b11053a548502713f0ae6f99111cd8f853d814981ca6ecf1c31231be
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8094"
      labels:
        app: oes
        component: dashboard
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-dashboard:v3.12.5
        name: oes-dashboard
        ports:
        - containerPort: 8094
          protocol: TCP
        env:
        volumeMounts:
        - mountPath: /opsmx/conf/dashboard-local.yml
          name: dashboard-config
          subPath: dashboard-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8094
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8094
          initialDelaySeconds: 30
          periodSeconds: 60
      volumes:
      - name: dashboard-config
        configMap:
          name: oes-dashboard-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-datascience-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: datascience
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-datascience
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: datascience
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "false"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "5005"
      labels:
        app: oes
        component: datascience
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-datascience:v3.12.5
        imagePullPolicy: IfNotPresent
        name: oes-datascience
        ports:
        - containerPort: 5005
          name: backend
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 5005
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /home/ubuntu/.aws/credentials
          name: datascience-config-volume
          subPath: minio-credentials
        - mountPath: /home/ubuntu/datascience/app_config.yaml
          name: datascience-config-volume
          subPath: app-config.yml
      volumes:
      - secret:
          secretName: oes-datascience-config
        name: datascience-config-volume
---
# Source: oes/templates/deployments/oes-gate-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-gate
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: gate
  template:
    metadata:
      annotations:
        checksum/secret: 9e671a363b1b4c99dcd7aac8c59ca953e7557083f323b3821938abe70ce654b3
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "false"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8084"
      labels:
        app: oes
        component: gate
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-gate:v3.12.5
        name: oes-gate
        env:
        - name: spring_profiles_active
          value: vault,local
        ports:
        - containerPort: 8084
          protocol: TCP
        resources:
            {}
        volumeMounts:
        - name: gate-volume
          mountPath: /opt/spinnaker/config/gate.yml
          subPath: gate.yml
        - mountPath: /opt/spinnaker/config/bootstrap.yml
          name: bootstrap-volume
          subPath: bootstrap.yml
        readinessProbe:
          tcpSocket:
            port: 8084
          initialDelaySeconds: 60
          periodSeconds: 30
        livenessProbe:
          httpGet:
            path: /health
            port: 8084
          initialDelaySeconds: 60
          periodSeconds: 60
      volumes:
      - name: gate-volume
        secret:
          secretName: oes-gate-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-volume
---
# Source: oes/templates/deployments/oes-platform-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: platform
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-platform
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: platform
  strategy: {}
  template:
    metadata:
      annotations:
        checksum/secret: 2654b4413d32f3b8e9cbd9402644a4db1a85939f4e991bb0e65721d036ef9be9
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8095"
      labels:
        app: oes
        component: platform
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
    spec:
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/postgres:9.6.5
        command: ['/bin/bash', '-c', "sleep 30;echo Waiting for oes-db to be up and running; pg_isready -h oes-db -p 5432 && echo PostgreSQL DB is ready to receive connections"]
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-platform:v3.12.5
        name: oes-platform
        ports:
        - containerPort: 8095
          protocol: TCP
        env:
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8095
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8095
          initialDelaySeconds: 60
          periodSeconds: 60
        volumeMounts:
        - mountPath: /opsmx/conf/platform-local.yml
          name: platform-config-volume
          subPath: platform-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
      volumes:
      - name: platform-config-volume
        secret:
          secretName: oes-platform-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-rabbitmq-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: rabbitmq
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: rabbitmq
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: rabbitmq
  template:
    metadata:
      annotations:
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: rabbitmq
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
    spec:
      containers:
      - image: quay.io/opsmxpublic/rabbitmq:3-management
        imagePullPolicy: IfNotPresent
        name: rabbitmq
        ports:
        - containerPort: 5672
          protocol: TCP
        resources: {}
      restartPolicy: Always
      securityContext:
        fsGroup: 1000
---
# Source: oes/templates/deployments/oes-sapor-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: sapor
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-sapor
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: sapor
  template:
    metadata:
      annotations:
        checksum/configmap: e5bbe1062923bd0b7a269fab69a7dea06804a70ab24f6a7d14e4cd97347ecb38
        checksum/configmap: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8085"
      labels:
        app: oes
        component: sapor
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
    spec:
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/postgres:9.6.5
        command: ['/bin/bash', '-c', "sleep 30;echo Waiting for oes-db to be up and running; pg_isready -h oes-db -p 5432 && echo PostgreSQL DB is ready to receive connections"]
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-sapor:v3.12.5
        name: oes-sapor
        env:
        ports:
        - containerPort: 8085
          protocol: TCP
        volumeMounts:
        - mountPath: /opt/opsmx/controller/ca.crt	
          name: ca-certs-volume	
          subPath: tls.crt	
        - mountPath: /opt/opsmx/controller/cert/tls.crt	
          name: certs-volume	
          subPath: tls.crt	
        - mountPath: /opt/opsmx/controller/cert/tls.key	
          name: certs-volume	
          subPath: tls.key
        - name: sapor-config-volume
          mountPath: /opt/opsmx/application.yml
          subPath: application.yml
        - mountPath: /opt/opsmx/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8085
          initialDelaySeconds: 60
          periodSeconds: 10
          failureThreshold: 10
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8085
          initialDelaySeconds: 60
          periodSeconds: 10
          failureThreshold: 10
      volumes:
      - secret:
          secretName: oes-control-secret
        name: certs-volume
      - secret:
          secretName: ca-secret
        name: ca-certs-volume
      - secret:
          secretName: oes-sapor-config
        name: sapor-config-volume
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: sapor-bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-ui-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-ui
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: ui
  template:
    metadata:
      annotations:
        checksum/configmap: ec1928c046c894ea0592049ca7ba025a7b4a3760cc5ec54f4bcffe0637d0d957
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: ui
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-ui:v3.12.5
        name: oes-ui
        ports:
        - containerPort: 8080
          protocol: TCP
        volumeMounts:
        - name: config-dir
          mountPath: /var/www/html/ui/assets/config/app-config.json
          subPath: app-config.json
        - name: config-dir
          mountPath: /var/www/html/ui/assets/config/help-text.json
          subPath: help-text.json
        - mountPath: /etc/nginx/nginx.conf
          name: nginx-config
          subPath: nginx.conf
        readinessProbe:
          tcpSocket:
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /ui/indexl.html
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 5
      volumes:
      - configMap:
          defaultMode: 420
          name: oes-ui-config
        name: config-dir
      - configMap:
          defaultMode: 420
          name: oes-ui-nginxconf
        name: nginx-config
---
# Source: oes/templates/deployments/oes-visibility-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: visibility
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-visibility
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: visibility
  strategy: {}
  template:
    metadata:
      annotations:
        configmap/checksum: e8fbec5cc12a16762885462e02311900447e5ba9cf561bc9c8ab596a1facb10d
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8096"
      labels:
        app: oes
        component: visibility
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
    spec:
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/postgres:9.6.5
        command: ['/bin/bash', '-c', "sleep 30;echo Waiting for oes-db to be up and running; pg_isready -h oes-db -p 5432 && echo PostgreSQL DB is ready to receive connections"]
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-visibility:v3.12.5
        name: oes-visibility
        ports:
        - containerPort: 8096
          protocol: TCP
        env:
        env:
        volumeMounts:
        - mountPath: /opsmx/conf/visibility-local.yml
          name: visibility-config
          subPath: visibility-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8096
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8096
          initialDelaySeconds: 30
          periodSeconds: 60
      volumes:
      - name: visibility-config
        secret:
          secretName: oes-visibility-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/opa-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: opa
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: opa
spec:
  replicas: 1
  selector:
    matchLabels:
      app: opa
  template:
    metadata:
      annotations:
        moniker.spinnaker.io/application: isd
      labels:
        app: opa
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
      name: opa
    spec:
      containers:
        - name: opa
          image: openpolicyagent/opa:latest
          args:
            - "run"
            - "--server"
        - name: opa-persist
          command: 
          - /bin/bash
          - /tmp/config/opa-persist.sh
          envFrom:
          - secretRef:
              name: oes-gate-secret
          image: quay.io/opsmxpublic/customterraformstage:v1
          imagePullPolicy: IfNotPresent
          volumeMounts:
          - mountPath: /tmp/config
            name: opa-persist
      restartPolicy: Always
      volumes:
        - configMap:
            defaultMode: 420
            name: opa-persist
          name: opa-persist
---
# Source: oes/templates/forwarder/oes-forwarder-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  name: opsmx-controller-controller1
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: opsmx-controller-controller1
  template:
    metadata:
      labels:
        app: opsmx-controller-controller1
        agent.opsmx.com/name: controller1
        agent.opsmx.com/role: controller
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
      annotations:
        pullversion: "16"
        checksum/configmap: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
    spec:
      containers:
      - name: opsmx-controller-controller1
        image: quay.io/opsmxpublic/forwarder-controller:v3.12.0
        ports:
          - containerPort: 9001
            name: agent-grpc
          - containerPort: 9002
            name: service-api
          - containerPort: 9003
            name: control-api
          - containerPort: 9004
            name: remote-command
          - containerPort: 9102
            name: metrics
        env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
        volumeMounts:
        - name: config
          mountPath: /app/config
          readOnly: true
        - name: ca-secret
          mountPath: /app/secrets/ca
          readOnly: true
        - name: jwt-secret
          mountPath: /app/secrets/serviceAuth
          readOnly: true
        resources:
          requests:
            memory: "64Mi"
            cpu: "100m"
          limits:
            memory: "128Mi"
            cpu: "250m"
      volumes:
      - name: ca-secret
        secret:
          secretName: ca-secret
      - name: jwt-secret
        secret:
          secretName: jwt-secret
      - name: config
        configMap:
          name: opsmx-controller-controller1
          items:
          - key: "configFile"
            path: "config.yaml"
---
# Source: oes/templates/sapor-gate/sapor-gate-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: sapor-gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: sapor-gate
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: sapor-gate
  template:
    metadata:
      annotations:
        checksum/secret: 68f74bcf539b143147ec93182922a9856aa8eeeaa1a0bf334cdb6b52608f954b
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: sapor-gate
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-spin-gate:v3.12.0-saporgate
        name: sapor-gate
        env:
        - name: JAVA_OPTS
          value: -XX:MaxRAMPercentage=100.0
        - name: SPRING_PROFILES_ACTIVE
          value: overrides,local
        ports:
        - containerPort: 8084
          protocol: TCP
        resources:
            {}
        volumeMounts:
        - mountPath: /opt/spinnaker/config
          name: sapor-gate-files
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: 8084
            scheme: HTTP
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
      volumes:
      - name: sapor-gate-files
        secret:
          secretName: sapor-gate-files
---
# Source: oes/charts/gitea/charts/postgresql/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: isd-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
  namespace: opsmx-isd
spec:
  serviceName: isd-postgresql-headless
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: isd
      role: primary
  template:
    metadata:
      name: isd-postgresql
      labels:
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-10.3.17
        app.kubernetes.io/instance: isd
        app.kubernetes.io/managed-by: Helm
        role: primary
        app.kubernetes.io/component: primary
    spec:      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/instance: isd
                    app.kubernetes.io/component: primary
                namespaces:
                  - "opsmx-isd"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      containers:
        - name: isd-postgresql
          image: docker.io/bitnami/postgresql:11.11.0-debian-10-r62
          imagePullPolicy: "IfNotPresent"
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: isd-postgresql
                  key: postgresql-postgres-password
            - name: POSTGRES_USER
              value: "gitea"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: isd-postgresql
                  key: postgresql-password
            - name: POSTGRES_DB
              value: "gitea"
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "gitea" -d "dbname=gitea" -h 127.0.0.1 -p 5432
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "gitea" -d "dbname=gitea" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
              subPath: 
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 1Gi
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "10Gi"
---
# Source: oes/charts/gitea/templates/gitea/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: isd-gitea
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: gitea
      app.kubernetes.io/instance: isd
  serviceName: isd-gitea
  template:
    metadata:
      annotations:
        checksum/config: 9d002fd7ae2d1eb91f8238f5d0f2896011847d3d71b8dc12d45add370e19de9c
      labels:
        helm.sh/chart: gitea-5.0.1
        app: gitea
        app.kubernetes.io/name: gitea
        app.kubernetes.io/instance: isd
        app.kubernetes.io/version: "1.15.10"
        version: "1.15.10"
        app.kubernetes.io/managed-by: Helm
    spec:
      securityContext:
        fsGroup: 1000
      initContainers:
        - name: init-directories
          image: "gitea/gitea:1.15.10"
          command: ["/usr/sbin/init_directory_structure.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
          securityContext:
            {}
        - name: init-app-ini
          image: "gitea/gitea:1.15.10"
          command: ["/usr/sbin/config_environment.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
          volumeMounts:
            - name: config
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
            - name: inline-config-sources
              mountPath: /env-to-ini-mounts/inlines/
          securityContext:
            {}
        - name: configure-gitea
          image: "gitea/gitea:1.15.10"
          command: ["/usr/sbin/configure_gitea.sh"]
          securityContext:
            runAsUser: 1000
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: GITEA_ADMIN_USERNAME
              valueFrom:
                secretKeyRef:
                  key:  username
                  name: gitea-secret
            - name: GITEA_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  key:  password
                  name: gitea-secret
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
      terminationGracePeriodSeconds: 60
      containers:
        - name: gitea
          image: "gitea/gitea:1.15.10"
          imagePullPolicy: Always
          env:
            # SSH Port values have to be set here as well for openssh configuration
            - name: SSH_LISTEN_PORT
              value: "22"
            - name: SSH_PORT
              value: "22"
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: TMPDIR
              value: /tmp/gitea
          ports:
            - name: ssh
              containerPort: 22
            - name: http
              containerPort: 3000
          livenessProbe:
            failureThreshold: 10
            initialDelaySeconds: 200
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: http
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: http
            timeoutSeconds: 1
          resources:
            {}
          securityContext:
            {}
          volumeMounts:
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
      volumes:
        - name: init
          secret:
            secretName: isd-gitea-init
            defaultMode: 110
        - name: config
          secret:
            secretName: isd-gitea
            defaultMode: 110
        - name: inline-config-sources
          secret:
            secretName: isd-gitea-inline-config
        - name: temp
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
            - "ReadWriteOnce"
        resources:
          requests:
            storage: "10Gi"
---
# Source: oes/charts/redis/templates/redis-master-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  name: isd-redis-master
  labels:
    app: redis
    chart: redis-10.5.3
    release: isd
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: redis
      release: isd
      role: master
  serviceName: isd-redis-headless
  template:
    metadata:
      labels:
        app: redis
        chart: redis-10.5.3
        release: isd
        role: master
      annotations:
        checksum/health: 36567aac6587929dc97be63c28c0aa1ec58d167572f3e5f191536195dc588d15
        checksum/configmap: 42a460f87c190197092321f0ae70720d271a2f6738150858f02b13ca057dae95
        checksum/secret: 92c3542fca96bee16e081be3a51ac49fa2ad66360cd283b768155ca7bae80c9e
        moniker.spinnaker.io/application: spin
    spec:      
      securityContext:
        fsGroup: 1001
      serviceAccountName: "default"
      containers:
      - name: isd-redis
        image: "quay.io/opsmxpublic/bitnami-redis:5.0.7-debian-10-r0"
        imagePullPolicy: "IfNotPresent"
        securityContext:
          runAsUser: 1001
        command:
        - /bin/bash
        - -c
        - |
          if [[ -n $REDIS_PASSWORD_FILE ]]; then
            password_aux=`cat ${REDIS_PASSWORD_FILE}`
            export REDIS_PASSWORD=$password_aux
          fi
          if [[ ! -f /opt/bitnami/redis/etc/master.conf ]];then
            cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
          fi
          if [[ ! -f /opt/bitnami/redis/etc/redis.conf ]];then
            cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
          fi
          ARGS=("--port" "${REDIS_PORT}")
          ARGS+=("--requirepass" "${REDIS_PASSWORD}")
          ARGS+=("--masterauth" "${REDIS_PASSWORD}")
          ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
          ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
          /run.sh ${ARGS[@]}
        env:
        - name: REDIS_REPLICATION_MODE
          value: master
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: isd-redis
              key: redis-password
        - name: REDIS_PORT
          value: "6379"
        ports:
        - name: redis
          containerPort: 6379
        livenessProbe:
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
            - sh
            - -c
            - /health/ping_liveness_local.sh 5
        readinessProbe:
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 1
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
            - sh
            - -c
            - /health/ping_readiness_local.sh 5
        resources:
          null
        volumeMounts:
        - name: health
          mountPath: /health
        - name: redis-data
          mountPath: /data
          subPath: 
        - name: config
          mountPath: /opt/bitnami/redis/mounted-etc
        - name: redis-tmp-conf
          mountPath: /opt/bitnami/redis/etc/
      volumes:
      - name: health
        configMap:
          name: isd-redis-health
          defaultMode: 0755
      - name: config
        configMap:
          name: isd-redis
      - name: redis-tmp-conf
        emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: redis-data
        labels:
          app: redis
          release: isd
          heritage: Helm
          component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
        
        selector:
  updateStrategy:
    type: RollingUpdate
---
# Source: oes/charts/spinnaker/templates/statefulsets/halyard.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    moniker.spinnaker.io/application: spin
  name: isd-spinnaker-halyard
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
spec:
  serviceName: isd-spinnaker-halyard
  replicas: 1
  selector:
    matchLabels:
      app: "isd-spinnaker"
      release: "isd"
      component: halyard
  template:
    metadata:
      annotations:
        checksum/configmap: 8d8af67c165826aa840708957b6378f55db6f782fb7ed3dfaf1ddf9bd2580f0d
        moniker.spinnaker.io/application: spin
      labels:
        app: "isd-spinnaker"
        heritage: "Helm"
        release: "isd"
        chart: "spinnaker-2.2.3"
        component: halyard
    spec:
      serviceAccountName: isd-spinnaker-halyard
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      initContainers:
      - name: "create-halyard-local"
        image: quay.io/opsmxpublic/awsgit:v2-openssh-javalibs
        command:
        - sh
        - /tmp/initscript/init.sh
        env:
        - name: SPINNAKER_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: GITEA_USER
          valueFrom:
            secretKeyRef:
              name: gitea-secret
              key: username
        - name: GITEA_PASS
          valueFrom:
            secretKeyRef:
              name: gitea-secret
              key: password
        volumeMounts:
        - name: halyard-config
          mountPath: /tmp/config
        - name: service-settings
          mountPath: /tmp/service-settings
        - name: halyard-home
          mountPath: /tmp/spinnaker
        - name: additional-profile-config-maps
          mountPath: /tmp/additionalProfileConfigMaps
        - name: halyard-initscript
          mountPath: /tmp/initscript
      - name: "halyardconfig-update"
        command:
        - sh
        - /tmp/akv2k8s/run.sh
        image: quay.io/opsmxpublic/k8s-decoder:hal
        imagePullPolicy: IfNotPresent
        resources: {}
        volumeMounts:
        - name: halyard-home
          mountPath: /tmp/spinnaker
        - name: secret-decoder
          mountPath: /tmp/akv2k8s
      - name: "halyard-overrideurl"
        command:
        - sh
        - /tmp/autoconfig/call_overrides.sh
        env:
        - name: NODE_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.hostIP
        image: quay.io/opsmxpublic/bitnami-kubectl:1.18.5
        imagePullPolicy: IfNotPresent
        resources: {}
        volumeMounts:
        - name: halyard-config
          mountPath: /tmp/config
        - name: service-settings
          mountPath: /tmp/service-settings
        - name: halyard-home
          mountPath: /tmp/spinnaker
        - name: additional-profile-config-maps
          mountPath: /tmp/additionalProfileConfigMaps
        - name: halyard-initscript
          mountPath: /tmp/initscript
        - mountPath: /tmp/autoconfig
          name: halyard-overrideurl
      volumes:
      - name: halyard-home
        emptyDir: {}
      - name: halyard-overrideurl
        configMap:
          name: isd-spinnaker-halyard-overrideurl
      - name: secret-decoder
        configMap:
          name: isd-spinnaker-spin-secret-decoder
      - name: reg-secrets
        secret:
          secretName: isd-spinnaker-registry
      - name: additional-profile-config-maps
        configMap:
          name: isd-spinnaker-additional-profile-config-maps
      - name: halyard-config
        emptyDir: {}
      - name: service-settings
        configMap:
          name: isd-spinnaker-service-settings
      - name: halyard-initscript
        configMap:
          name: isd-spinnaker-halyard-init-script
      containers:
      - name: halyard
        image: quay.io/opsmxpublic/ubi8-spin-halyard:opsmx-1.40.0
        lifecycle:
          postStart:
            exec:
              command: ["/bin/sh", "-c", "until hal --ready; do sleep 10 ;done;hal deploy apply"]
        ports:
        - containerPort: 8064
          name: daemon
        volumeMounts:
        - name: halyard-home
          mountPath: /home/spinnaker
        - name: halyard-config
          mountPath: /opt/halyard/config
        - name: reg-secrets
          mountPath: /opt/registry/passwords
---
# Source: oes/templates/statefulsets/oes-db-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: db
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-db
spec:
  podManagementPolicy: OrderedReady
  replicas: 1
  serviceName: oes-db
  selector:
    matchLabels:
      app: oes
      component: db
  template:
    metadata:
      annotations:
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: db
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-db:v3.0.0
        imagePullPolicy: IfNotPresent
        name: oes-db
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - /opt/opsmx/bin/stop.sh
        ports:
        - containerPort: 5432
          protocol: TCP
        volumeMounts:
        - mountPath: "/var/lib/pgsql-pv"
          name: oes-db-postgresql
        readinessProbe:
          tcpSocket:
            port: 5432
          initialDelaySeconds: 10
          periodSeconds: 5
      securityContext:
        fsGroup: 1000
  volumeClaimTemplates:
  - metadata:
      creationTimestamp: null
      labels:
        app: oes
        component: db
      name: oes-db-postgresql
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 8Gi
      volumeMode: Filesystem
---
# Source: oes/charts/spinnaker/templates/deployments/create-sample-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: isd-create-sample-app
spec:
  template:
    spec:
      serviceAccountName: isd-spinnaker-halyard
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      restartPolicy: OnFailure
      volumes:
      - secret:
          secretName: isd-spinnaker-spin-config
        name: spin-config
      - configMap:
          defaultMode: 420
          name: isd-spinnaker-spin-pipeline-import
        name: spin-pipeline-import
      - name: spin-pipeline-config
        emptyDir: {}
      containers:
      - command:  
        - bash
        - /tmp/config/spin-pipeline-import.sh
        name: sample-pipeline-install
        image: quay.io/opsmxpublic/spin-sample-pipeline:1.0
        volumeMounts:         
        - name: spin-pipeline-config
          mountPath: /tmp/config/git
        - mountPath: /tmp/config
          name: spin-pipeline-import
        - mountPath: /tmp/config/spin
          name: spin-config
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: create-controller-secret
spec:
 template:
    spec:
       containers:
       - name: create-secret-container
         image: quay.io/opsmxpublic/create-secret:v20211127T140816
         env:
         - name: NAMESPACE
           valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
         args: 
         - "$(NAMESPACE)" 
       restartPolicy: Never
       serviceAccount: create-controller-secret
---
# Source: oes/charts/minio/templates/post-install-create-bucket-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: isd-minio-make-bucket-job
  labels:
    app: minio-make-bucket-job
    chart: minio-8.0.9
    release: isd
    heritage: Helm
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  template:
    metadata:
      labels:
        app: minio-job
        release: isd
    spec:
      restartPolicy: OnFailure      
      volumes:
        - name: minio-configuration
          projected:
            sources:
            - configMap:
                name: isd-minio
            - secret:
                name: isd-minio
      serviceAccountName: "isd-minio"
      containers:
      - name: minio-mc
        image: "minio/mc:RELEASE.2020-11-25T23-04-07Z"
        imagePullPolicy: IfNotPresent
        command: ["/bin/sh", "/config/initialize"]
        env:
          - name: MINIO_ENDPOINT
            value: isd-minio
          - name: MINIO_PORT
            value: "9000"
        volumeMounts:
          - name: minio-configuration
            mountPath: /config
        resources:
          requests:
            memory: 128Mi
---
# Source: oes/charts/spinnaker/templates/hooks/install-using-hal.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "isd-install-using-hal"
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
  annotations:
    "helm.sh/hook": "post-install,post-upgrade"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "0"
spec:
  template:
    metadata:
      annotations:
        checksum/config: 2a98b46fe11260d3a3825a88d99252ea746c3fef7dbbedef2a475165c81f0b5c
        moniker.spinnaker.io/application: spin
      labels:
        app: "isd-spinnaker"
        heritage: "Helm"
        release: "isd"
        chart: "spinnaker-2.2.3"
    spec:
      serviceAccountName: isd-spinnaker-halyard
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      restartPolicy: OnFailure
      volumes:
      - name: halyard-config
        configMap:
          name: isd-spinnaker-halyard-config
      containers:
      - name: halyard-install
        image: quay.io/opsmxpublic/ubi8-spin-halyard:opsmx-1.40.0
        volumeMounts:
        - name: halyard-config
          mountPath: /opt/halyard/scripts
        command:
        - bash
        - -xe
        - "/opt/halyard/scripts/install.sh"
        env:
        - name: NODE_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.hostIP
---
# Source: oes/templates/hooks/oes-config-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
    "helm.sh/hook": "post-install,post-upgrade"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "5"
  labels:
    app: oes
    component: oes-config
    heritage: "Helm"
    release: "isd"
    chart: "oes-3.12.9"
  name: oes-config
spec:
  template:
    metadata:
      annotations:
        checksum/configmap: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: oes-config
        heritage: "Helm"
        release: "isd"
        chart: "oes-3.12.9"
    spec:
      containers:
      - command: ["bash", "/tmp/config/datasource-api.sh" ]
        name: datasource-creation-api
        image: quay.io/opsmxpublic/oes-pre-configure:v2
        volumeMounts:
        - mountPath: /tmp/config
          name: datasource-creation
      restartPolicy: OnFailure
      volumes:
      - configMap:
          defaultMode: 420
          name: isd-oes-datasource-creation
        name: datasource-creation
